{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'E:/Coding/Projects/Titanic survive prediction/Data file/'\n",
    "train = pd.read_csv(file_path+'train.csv')\n",
    "test = pd.read_csv(file_path+'test.csv')\n",
    "data = pd.concat([train,test]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   index        1309 non-null   int64  \n",
      " 1   PassengerId  1309 non-null   int64  \n",
      " 2   Survived     891 non-null    float64\n",
      " 3   Pclass       1309 non-null   int64  \n",
      " 4   Name         1309 non-null   object \n",
      " 5   Sex          1309 non-null   object \n",
      " 6   Age          1046 non-null   float64\n",
      " 7   SibSp        1309 non-null   int64  \n",
      " 8   Parch        1309 non-null   int64  \n",
      " 9   Ticket       1309 non-null   object \n",
      " 10  Fare         1308 non-null   float64\n",
      " 11  Cabin        295 non-null    object \n",
      " 12  Embarked     1307 non-null   object \n",
      "dtypes: float64(3), int64(5), object(5)\n",
      "memory usage: 133.1+ KB\n"
     ]
    }
   ],
   "source": [
    "## there are NaN values in ['Age','Cabin','Embarked', 'Fare']\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x14d6dacef08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALkAAABICAYAAACqY1TgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAABiUlEQVR4nO3YIU5DQRSG0TsNqkkdaASWYOgCWM3bB9tgGawDiUGBRNQQFJjBYEiaNk06eeXPOe5lRtybfGLyWu+9INli7gFgNJETT+TEEznxRE48kRPvbN+F1tpUVVNVVS2Wt7W8Gj3TfFZfc08w1up77gnGed9U//hs247aIf/J2+qm1/rxaHOdnLu3uScYK3m/6b76y+vWyD1XiCdy4omceCInnsiJJ3LiiZx4IieeyIkncuKJnHgiJ57IiSdy4omceCInnsiJJ3LiiZx4IieeyIkncuKJnHgiJ57IiSdy4omceCInnsiJJ3LiiZx4IieeyIkncuKJnHgiJ57IiSdy4omceCInnsiJJ3LiiZx4IieeyIkncuKJnHgiJ57IiSdy4omceCInXuu9777Q2lRV0+/ndVU9jx5qRudVtZl7iEGSd6uquuy9X2w72Bv5n8utPfXe10cb68Qk75e82z6eK8QTOfEOjfxhyBSnI3m/5N12OuhNDv+R5wrxRE48kRNP5MQTOfF+AGLnNE1Bxrr2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 216x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 402.375x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visualize the relation between sex, Pclass and suvival rate\n",
    "\n",
    "current_palette = sns.color_palette('winter',3)\n",
    "sns.palplot(current_palette)\n",
    "sns.catplot(x='Sex',y='Survived',hue='Pclass',kind='bar',data=data, palette=current_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x14d6d9a5ec8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 915.875x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visualize the distribution of the Age data\n",
    "\n",
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade=True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19d707a95c0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visualize the portions of survived and dead people according to Age and Fare \n",
    "\n",
    "fig=plt.figure(figsize=(15,15))\n",
    "plt.style.use('ggplot')\n",
    "plt.subplot(221)\n",
    "pic=plt.hist([data[data['Survived'] == 1]['Age'],  data[data['Survived'] == 0]['Age']], \n",
    "             stacked=True,bins =40, label=['Survived','Dead'], \n",
    "             edgecolor='white',color = ['b','r'])\n",
    "\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist([data[data['Survived'] == 1]['Fare'],data[data['Survived'] == 0]['Fare']], \n",
    "         stacked=True, color = ['b','r'],bins = 40,\n",
    "         label = ['Survived','Dead'],edgecolor='white')\n",
    "\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=10>Feature engineering</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine Parch and SibSp data \n",
    "\n",
    "data['family_size'] = data['Parch'] + data['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14d7065f048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## it seems that family_size dosen't have infulence on survival rate\n",
    "\n",
    "sns.countplot(data['family_size'],hue=data['Survived'], palette=current_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19d70bd7198>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## S has the highest survival rate \n",
    "\n",
    "sns.countplot(data['Embarked'],hue=data['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer', 'Dona'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## expand: expand the splitted strings into separate columns.\n",
    "\n",
    "data['Title_temp'] = data['Name'].str.split(', ',expand=True)[1]\n",
    "data['Title_temp'] = data['Title_temp'].str.split('.',expand=True)[0]\n",
    "data['Title_temp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a crosstab to see the number of survived people for each title\n",
    "\n",
    "title_survived=pd.crosstab(data['Title_temp'],data['Sex']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col0 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col1 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col2 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col3 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col4 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col5 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col6 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col7 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col8 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col9 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col10 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col11 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col12 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col13 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col14 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col15 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col16 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col17 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col0 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col1 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col2 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col3 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col4 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col5 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col6 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col7 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col8 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col9 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col10 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col11 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col12 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col13 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col14 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col15 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col16 {\n",
       "            background-color:  #0000ff;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col17 {\n",
       "            background-color:  #e5e5ff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05\" ><thead>    <tr>        <th class=\"index_name level0\" >Title_temp</th>        <th class=\"col_heading level0 col0\" >Capt</th>        <th class=\"col_heading level0 col1\" >Col</th>        <th class=\"col_heading level0 col2\" >Don</th>        <th class=\"col_heading level0 col3\" >Dona</th>        <th class=\"col_heading level0 col4\" >Dr</th>        <th class=\"col_heading level0 col5\" >Jonkheer</th>        <th class=\"col_heading level0 col6\" >Lady</th>        <th class=\"col_heading level0 col7\" >Major</th>        <th class=\"col_heading level0 col8\" >Master</th>        <th class=\"col_heading level0 col9\" >Miss</th>        <th class=\"col_heading level0 col10\" >Mlle</th>        <th class=\"col_heading level0 col11\" >Mme</th>        <th class=\"col_heading level0 col12\" >Mr</th>        <th class=\"col_heading level0 col13\" >Mrs</th>        <th class=\"col_heading level0 col14\" >Ms</th>        <th class=\"col_heading level0 col15\" >Rev</th>        <th class=\"col_heading level0 col16\" >Sir</th>        <th class=\"col_heading level0 col17\" >the Countess</th>    </tr>    <tr>        <th class=\"index_name level0\" >Sex</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05level0_row0\" class=\"row_heading level0 row0\" >female</th>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col6\" class=\"data row0 col6\" >1</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col9\" class=\"data row0 col9\" >260</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col10\" class=\"data row0 col10\" >2</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col11\" class=\"data row0 col11\" >1</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col13\" class=\"data row0 col13\" >197</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col14\" class=\"data row0 col14\" >2</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row0_col17\" class=\"data row0 col17\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05level0_row1\" class=\"row_heading level0 row1\" >male</th>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col1\" class=\"data row1 col1\" >4</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col4\" class=\"data row1 col4\" >7</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col5\" class=\"data row1 col5\" >1</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col7\" class=\"data row1 col7\" >2</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col8\" class=\"data row1 col8\" >61</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col9\" class=\"data row1 col9\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col10\" class=\"data row1 col10\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col11\" class=\"data row1 col11\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col12\" class=\"data row1 col12\" >757</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col13\" class=\"data row1 col13\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col14\" class=\"data row1 col14\" >0</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col15\" class=\"data row1 col15\" >8</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col16\" class=\"data row1 col16\" >1</td>\n",
       "                        <td id=\"T_76b81100_5a29_11ea_9bcc_4074e077fa05row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14d6f9ebf08>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm=sns.light_palette('blue',as_cmap=True)\n",
    "title_survived.style.background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title_temp\n",
       "Capt            70.000000\n",
       "Col             54.000000\n",
       "Don             40.000000\n",
       "Dona            39.000000\n",
       "Dr              43.571429\n",
       "Jonkheer        38.000000\n",
       "Lady            48.000000\n",
       "Major           48.500000\n",
       "Master           5.482642\n",
       "Miss            21.774238\n",
       "Mlle            24.000000\n",
       "Mme             24.000000\n",
       "Mr              32.252151\n",
       "Mrs             36.994118\n",
       "Ms              28.000000\n",
       "Rev             41.250000\n",
       "Sir             49.000000\n",
       "the Countess    33.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the average age for each title\n",
    "\n",
    "data.groupby(['Title_temp'])['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace the unfrequent title with ['Mr','Mrs','Miss']\n",
    "\n",
    "data['Title'] = data['Title_temp'].replace(['Capt','Col','Don','Dr','Jonkheer','Major','Rev','Sir','Dona'\n",
    "                                     ,'Lady','Mlle','Mme','Ms','the Countess'],\n",
    "                                    ['Mr','Mr','Mr','Mr','Mr','Mr','Mr','Mr','Mrs','Mrs','Miss','Miss','Miss','Mrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill NaN value of Embarked with 'S'\n",
    "\n",
    "data['Embarked'] = data['Embarked'].fillna(train['Embarked'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill NaN values of Fare with mean\n",
    "\n",
    "data['Fare'] = data['Fare'].fillna(data['Fare'][:891].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I tried to fill NaN values of Age with the mean value according to each Title, but get worse acc\n",
    "\n",
    "# age_median = data['Age'][:891].groupby(data['Title'][:891]).median()\n",
    "# data.loc[(data['Age'].isna()) & (data['Title'] == 'Master'),'Age']=data.loc[(data['Age'].isna())&(data['Title'] == 'Master'),'Age'].fillna(age_median['Master'])\n",
    "# data.loc[(data['Age'].isna()) & (data['Title'] == 'Mr'),'Age']=data.loc[(data['Age'].isna())& (data['Title'] == 'Mr'),'Age'].fillna(age_median['Mr'])\n",
    "# data.loc[(data['Age'].isna()) & (data['Title'] == 'Mrs'),'Age']=data.loc[(data['Age'].isna())& (data['Title'] == 'Mrs'),'Age'].fillna(age_median['Mrs'])\n",
    "# data.loc[(data['Age'].isna()) & (data['Title'] == 'Miss'),'Age']=data.loc[(data['Age'].isna())& (data['Title'] == 'Miss'),'Age'].fillna(age_median['Miss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Y.Liu\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Y.Liu\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## fill NaN values of Age with the mean according to the groups of title and Pclass\n",
    "\n",
    "obj = data['Age'][:891].groupby([data['Title'],data['Pclass']])\n",
    "data['Age'][:891] = obj.transform(lambda x: x.fillna(x.mean()))\n",
    "obj_1 = data['Age'][891:].groupby([data['Title'],data['Pclass']])\n",
    "data['Age'][891:] = obj_1.transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Cabin=data.Cabin.fillna('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the first character of Cabin to present Cabin info\n",
    "\n",
    "data.Cabin=data.Cabin.map(lambda cabin:cabin[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter the people who have the same ticket number\n",
    "\n",
    "same_tickets=[]\n",
    "for ticket in data.Ticket.unique():\n",
    "    same_ticket=data.loc[data.Ticket == ticket,'Fare']\n",
    "    if same_ticket.count() > 1:\n",
    "        same_tickets.append(data.loc[data.Ticket == ticket, ['Ticket','Name','Fare','family_size','Cabin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_same_tickets=pd.concat(same_tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Name</th>\n",
       "      <th>Fare</th>\n",
       "      <th>family_size</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC 17599</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>PC 17599</td>\n",
       "      <td>Cumings, Mr. John Bradley</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113803</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>113803</td>\n",
       "      <td>Futrelle, Mr. Jacques Heath</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17463</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>17463</td>\n",
       "      <td>Hilliard, Mr. Herbert Henry</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>349909</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>5</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>349909</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>5</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>349909</td>\n",
       "      <td>Palsson, Miss. Stina Viola</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>5</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>349909</td>\n",
       "      <td>Palsson, Mrs. Nils (Alma Cornelia Berglund)</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>5</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>349909</td>\n",
       "      <td>Palsson, Master. Paul Folke</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>5</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>347742</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>347742</td>\n",
       "      <td>Johnson, Miss. Eleanor Ileen</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>347742</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>237736</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>237736</td>\n",
       "      <td>Nasser, Mr. Nicholas</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PP 9549</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>PP 9549</td>\n",
       "      <td>Sandstrom, Mrs. Hjalmar (Agnes Charlotta Bengt...</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>PP 9549</td>\n",
       "      <td>Sandstrom, Miss. Beatrice Irene</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>3</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>347082</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>7</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ticket                                               Name     Fare  \\\n",
       "1     PC 17599  Cumings, Mrs. John Bradley (Florence Briggs Th...  71.2833   \n",
       "1125  PC 17599                          Cumings, Mr. John Bradley  71.2833   \n",
       "3       113803       Futrelle, Mrs. Jacques Heath (Lily May Peel)  53.1000   \n",
       "137     113803                        Futrelle, Mr. Jacques Heath  53.1000   \n",
       "6        17463                            McCarthy, Mr. Timothy J  51.8625   \n",
       "1037     17463                        Hilliard, Mr. Herbert Henry  51.8625   \n",
       "7       349909                     Palsson, Master. Gosta Leonard  21.0750   \n",
       "24      349909                      Palsson, Miss. Torborg Danira  21.0750   \n",
       "374     349909                         Palsson, Miss. Stina Viola  21.0750   \n",
       "567     349909        Palsson, Mrs. Nils (Alma Cornelia Berglund)  21.0750   \n",
       "1280    349909                        Palsson, Master. Paul Folke  21.0750   \n",
       "8       347742  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  11.1333   \n",
       "172     347742                       Johnson, Miss. Eleanor Ileen  11.1333   \n",
       "869     347742                    Johnson, Master. Harold Theodor  11.1333   \n",
       "9       237736                Nasser, Mrs. Nicholas (Adele Achem)  30.0708   \n",
       "122     237736                               Nasser, Mr. Nicholas  30.0708   \n",
       "10     PP 9549                    Sandstrom, Miss. Marguerite Rut  16.7000   \n",
       "394    PP 9549  Sandstrom, Mrs. Hjalmar (Agnes Charlotta Bengt...  16.7000   \n",
       "1008   PP 9549                    Sandstrom, Miss. Beatrice Irene  16.7000   \n",
       "13      347082                        Andersson, Mr. Anders Johan  31.2750   \n",
       "\n",
       "      family_size Cabin  \n",
       "1               2     C  \n",
       "1125            2     C  \n",
       "3               2     C  \n",
       "137             2     C  \n",
       "6               1     E  \n",
       "1037            1     E  \n",
       "7               5     U  \n",
       "24              5     U  \n",
       "374             5     U  \n",
       "567             5     U  \n",
       "1280            5     U  \n",
       "8               3     U  \n",
       "172             3     U  \n",
       "869             3     U  \n",
       "9               2     U  \n",
       "122             2     U  \n",
       "10              3     G  \n",
       "394             3     G  \n",
       "1008            3     G  \n",
       "13              7     U  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_same_tickets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people who have relation : 496\n"
     ]
    }
   ],
   "source": [
    "## create a new feature 'relative_survived' based on the people who have the same ticket number\n",
    "## relative_survived = 0.5 : people who have no relation with others\n",
    "## relative_survived = 0 or 1 : people who have relation with others\n",
    "\n",
    "df_ticket=data.groupby('Ticket')\n",
    "data['relative_survived']=0.5\n",
    "for _,tk in df_ticket:\n",
    "    if len(tk)>1:\n",
    "        for ind, row in tk.iterrows():\n",
    "            smax = tk.drop(ind)['Survived'].max()\n",
    "            smin = tk.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'relative_survived'] = 1\n",
    "            elif (smin==0.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'relative_survived'] = 0\n",
    "                \n",
    "                \n",
    "print(\"people who have relation : %.0f\" %(data[data['relative_survived']!=0.5].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get dummy variables for Embarked, Sex, Title and Pclass \n",
    "\n",
    "embarked_dummy = pd.get_dummies(data['Embarked'],prefix='Embarked')\n",
    "data = pd.concat([data,embarked_dummy],axis=1)\n",
    "\n",
    "data.Sex = data['Sex'].map({'male':0,'female':1})\n",
    "\n",
    "title_dummy = pd.get_dummies(data['Title'],prefix='Title')\n",
    "data = pd.concat([data,title_dummy],axis=1)\n",
    "\n",
    "Pclass_dummy = pd.get_dummies(data['Pclass'],prefix='Pclass')\n",
    "data = pd.concat([data,Pclass_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization\n",
    "\n",
    "norm = StandardScaler()\n",
    "data['Fare'] = norm.fit_transform(data['Fare'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the log value of Age\n",
    "\n",
    "data['Age'] = np.log(data['Age'])\n",
    "#data['Age'] = norm.fit_transform(data['Age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the useless feature\n",
    "\n",
    "df = data.drop(columns=['family_size','PassengerId','Name','Parch','Survived','index','Embarked','Pclass','SibSp','Ticket','Cabin','Title_temp','Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "      <th>relative_survived</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.091042</td>\n",
       "      <td>-0.503579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.637586</td>\n",
       "      <td>0.734519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.258097</td>\n",
       "      <td>-0.490527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.555348</td>\n",
       "      <td>0.382941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.555348</td>\n",
       "      <td>-0.488110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3.303173</td>\n",
       "      <td>-0.488110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3.663562</td>\n",
       "      <td>1.461845</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3.650658</td>\n",
       "      <td>-0.503579</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3.303173</td>\n",
       "      <td>-0.488110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>2.008833</td>\n",
       "      <td>-0.211457</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age      Fare  Sex  relative_survived  Embarked_C  Embarked_Q  \\\n",
       "0     3.091042 -0.503579    0                0.5           0           0   \n",
       "1     3.637586  0.734519    1                0.5           1           0   \n",
       "2     3.258097 -0.490527    1                0.5           0           0   \n",
       "3     3.555348  0.382941    1                0.0           0           0   \n",
       "4     3.555348 -0.488110    0                0.5           0           0   \n",
       "...        ...       ...  ...                ...         ...         ...   \n",
       "1304  3.303173 -0.488110    0                0.5           0           0   \n",
       "1305  3.663562  1.461845    1                1.0           1           0   \n",
       "1306  3.650658 -0.503579    0                0.5           0           0   \n",
       "1307  3.303173 -0.488110    0                0.5           0           0   \n",
       "1308  2.008833 -0.211457    0                1.0           1           0   \n",
       "\n",
       "      Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Pclass_1  \\\n",
       "0              1             0           0         1          0         0   \n",
       "1              0             0           0         0          1         1   \n",
       "2              1             0           1         0          0         0   \n",
       "3              1             0           0         0          1         1   \n",
       "4              1             0           0         1          0         0   \n",
       "...          ...           ...         ...       ...        ...       ...   \n",
       "1304           1             0           0         1          0         0   \n",
       "1305           0             0           0         0          1         1   \n",
       "1306           1             0           0         1          0         0   \n",
       "1307           1             0           0         1          0         0   \n",
       "1308           0             1           0         0          0         0   \n",
       "\n",
       "      Pclass_2  Pclass_3  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         1  \n",
       "3            0         0  \n",
       "4            0         1  \n",
       "...        ...       ...  \n",
       "1304         0         1  \n",
       "1305         0         0  \n",
       "1306         0         1  \n",
       "1307         0         1  \n",
       "1308         0         1  \n",
       "\n",
       "[1309 rows x 14 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data \n",
    "\n",
    "X = df[:891]\n",
    "y = data['Survived'][:891]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30,random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the model: I use the ANN with batch normalization \n",
    "\n",
    "def build_model(X_train = X_train,neurons=4,optimizer='Adam',layer=1):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(Dense(X_train.shape[1], kernel_regularizer=regularizers.l2(0.001), \n",
    "                           activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    for i in range(layer):\n",
    "        model.add(layers.Dense(neurons,  kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 854us/step - loss: 0.6076 - accuracy: 0.7189 - val_loss: 0.6254 - val_accuracy: 0.6642\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.5746 - accuracy: 0.7510 - val_loss: 0.6161 - val_accuracy: 0.6754\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5591 - accuracy: 0.7671 - val_loss: 0.6077 - val_accuracy: 0.7313\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5395 - accuracy: 0.7530 - val_loss: 0.6000 - val_accuracy: 0.7388\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5230 - accuracy: 0.7470 - val_loss: 0.5922 - val_accuracy: 0.7463\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5014 - accuracy: 0.7610 - val_loss: 0.5848 - val_accuracy: 0.7612\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4949 - accuracy: 0.7811 - val_loss: 0.5778 - val_accuracy: 0.7649\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4860 - accuracy: 0.7791 - val_loss: 0.5715 - val_accuracy: 0.7761\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4700 - accuracy: 0.7952 - val_loss: 0.5658 - val_accuracy: 0.7836\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4666 - accuracy: 0.8052 - val_loss: 0.5606 - val_accuracy: 0.7799\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4556 - accuracy: 0.8072 - val_loss: 0.5560 - val_accuracy: 0.7873\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4473 - accuracy: 0.8173 - val_loss: 0.5518 - val_accuracy: 0.7873\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4438 - accuracy: 0.8293 - val_loss: 0.5479 - val_accuracy: 0.7836\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4371 - accuracy: 0.8193 - val_loss: 0.5446 - val_accuracy: 0.7761\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4392 - accuracy: 0.8293 - val_loss: 0.5415 - val_accuracy: 0.7799\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4346 - accuracy: 0.8253 - val_loss: 0.5389 - val_accuracy: 0.7836\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4332 - accuracy: 0.8253 - val_loss: 0.5366 - val_accuracy: 0.7836\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4205 - accuracy: 0.8273 - val_loss: 0.5345 - val_accuracy: 0.7873\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4148 - accuracy: 0.8474 - val_loss: 0.5323 - val_accuracy: 0.7910\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4097 - accuracy: 0.8373 - val_loss: 0.5301 - val_accuracy: 0.7910\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4096 - accuracy: 0.8333 - val_loss: 0.5282 - val_accuracy: 0.7948\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4121 - accuracy: 0.8273 - val_loss: 0.5264 - val_accuracy: 0.7948\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4017 - accuracy: 0.8313 - val_loss: 0.5246 - val_accuracy: 0.7948\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4004 - accuracy: 0.8534 - val_loss: 0.5231 - val_accuracy: 0.7948\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4032 - accuracy: 0.8454 - val_loss: 0.5217 - val_accuracy: 0.7948\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3850 - accuracy: 0.8614 - val_loss: 0.5205 - val_accuracy: 0.8022\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3885 - accuracy: 0.8534 - val_loss: 0.5199 - val_accuracy: 0.7985\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3919 - accuracy: 0.8474 - val_loss: 0.5193 - val_accuracy: 0.7985\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3969 - accuracy: 0.8554 - val_loss: 0.5191 - val_accuracy: 0.7985\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3873 - accuracy: 0.8494 - val_loss: 0.5186 - val_accuracy: 0.7985\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3847 - accuracy: 0.8474 - val_loss: 0.5178 - val_accuracy: 0.8022\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3743 - accuracy: 0.8675 - val_loss: 0.5171 - val_accuracy: 0.8022\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3833 - accuracy: 0.8614 - val_loss: 0.5164 - val_accuracy: 0.8022\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3726 - accuracy: 0.8594 - val_loss: 0.5155 - val_accuracy: 0.7985\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3771 - accuracy: 0.8675 - val_loss: 0.5148 - val_accuracy: 0.7985\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3812 - accuracy: 0.8635 - val_loss: 0.5146 - val_accuracy: 0.8022\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3714 - accuracy: 0.8635 - val_loss: 0.5142 - val_accuracy: 0.8022\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3647 - accuracy: 0.8655 - val_loss: 0.5136 - val_accuracy: 0.7985\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3649 - accuracy: 0.8635 - val_loss: 0.5131 - val_accuracy: 0.7910\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3657 - accuracy: 0.8635 - val_loss: 0.5126 - val_accuracy: 0.7948\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3624 - accuracy: 0.8635 - val_loss: 0.5116 - val_accuracy: 0.7985\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3602 - accuracy: 0.8715 - val_loss: 0.5107 - val_accuracy: 0.7985\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3575 - accuracy: 0.8695 - val_loss: 0.5104 - val_accuracy: 0.7985\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3547 - accuracy: 0.8655 - val_loss: 0.5101 - val_accuracy: 0.7985\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3592 - accuracy: 0.8675 - val_loss: 0.5087 - val_accuracy: 0.7985\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3644 - accuracy: 0.8655 - val_loss: 0.5077 - val_accuracy: 0.7910\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3656 - accuracy: 0.8655 - val_loss: 0.5068 - val_accuracy: 0.7948\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3545 - accuracy: 0.8655 - val_loss: 0.5050 - val_accuracy: 0.7985\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3588 - accuracy: 0.8594 - val_loss: 0.5032 - val_accuracy: 0.8060\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3520 - accuracy: 0.8675 - val_loss: 0.5013 - val_accuracy: 0.8060\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3555 - accuracy: 0.8695 - val_loss: 0.4994 - val_accuracy: 0.8060\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3531 - accuracy: 0.8554 - val_loss: 0.4969 - val_accuracy: 0.8097\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3563 - accuracy: 0.8655 - val_loss: 0.4945 - val_accuracy: 0.8060\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3556 - accuracy: 0.8695 - val_loss: 0.4922 - val_accuracy: 0.8022\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3535 - accuracy: 0.8695 - val_loss: 0.4907 - val_accuracy: 0.8022\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3475 - accuracy: 0.8675 - val_loss: 0.4892 - val_accuracy: 0.8022\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3459 - accuracy: 0.8735 - val_loss: 0.4881 - val_accuracy: 0.8022\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3457 - accuracy: 0.8675 - val_loss: 0.4870 - val_accuracy: 0.8022\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3436 - accuracy: 0.8715 - val_loss: 0.4859 - val_accuracy: 0.8022\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3438 - accuracy: 0.8695 - val_loss: 0.4839 - val_accuracy: 0.8022\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3401 - accuracy: 0.8655 - val_loss: 0.4829 - val_accuracy: 0.8022\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3508 - accuracy: 0.8715 - val_loss: 0.4812 - val_accuracy: 0.8022\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3443 - accuracy: 0.8735 - val_loss: 0.4793 - val_accuracy: 0.8022\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3424 - accuracy: 0.8775 - val_loss: 0.4780 - val_accuracy: 0.8022\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3447 - accuracy: 0.8755 - val_loss: 0.4767 - val_accuracy: 0.8060\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3440 - accuracy: 0.8655 - val_loss: 0.4747 - val_accuracy: 0.8060\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3394 - accuracy: 0.8775 - val_loss: 0.4731 - val_accuracy: 0.8060\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3427 - accuracy: 0.8655 - val_loss: 0.4722 - val_accuracy: 0.8022\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3440 - accuracy: 0.8775 - val_loss: 0.4711 - val_accuracy: 0.8060\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3379 - accuracy: 0.8815 - val_loss: 0.4692 - val_accuracy: 0.8097\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3349 - accuracy: 0.8795 - val_loss: 0.4683 - val_accuracy: 0.8134\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3308 - accuracy: 0.8795 - val_loss: 0.4663 - val_accuracy: 0.8172\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3316 - accuracy: 0.8815 - val_loss: 0.4642 - val_accuracy: 0.8172\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3359 - accuracy: 0.8835 - val_loss: 0.4616 - val_accuracy: 0.8209\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3324 - accuracy: 0.8675 - val_loss: 0.4594 - val_accuracy: 0.8246\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3303 - accuracy: 0.8775 - val_loss: 0.4570 - val_accuracy: 0.8321\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3393 - accuracy: 0.8775 - val_loss: 0.4556 - val_accuracy: 0.8284\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3309 - accuracy: 0.8755 - val_loss: 0.4547 - val_accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3348 - accuracy: 0.8755 - val_loss: 0.4542 - val_accuracy: 0.8246\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3301 - accuracy: 0.8755 - val_loss: 0.4535 - val_accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3250 - accuracy: 0.8815 - val_loss: 0.4532 - val_accuracy: 0.8284\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3309 - accuracy: 0.8815 - val_loss: 0.4517 - val_accuracy: 0.8246\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3358 - accuracy: 0.8755 - val_loss: 0.4506 - val_accuracy: 0.8246\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3305 - accuracy: 0.8795 - val_loss: 0.4487 - val_accuracy: 0.8321\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3248 - accuracy: 0.8795 - val_loss: 0.4472 - val_accuracy: 0.8321\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3238 - accuracy: 0.8835 - val_loss: 0.4459 - val_accuracy: 0.8284\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3340 - accuracy: 0.8815 - val_loss: 0.4455 - val_accuracy: 0.8284\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3313 - accuracy: 0.8775 - val_loss: 0.4452 - val_accuracy: 0.8284\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3212 - accuracy: 0.8876 - val_loss: 0.4448 - val_accuracy: 0.8284\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3271 - accuracy: 0.8755 - val_loss: 0.4445 - val_accuracy: 0.8284\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3245 - accuracy: 0.8876 - val_loss: 0.4435 - val_accuracy: 0.8396\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3179 - accuracy: 0.8896 - val_loss: 0.4424 - val_accuracy: 0.8470\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3218 - accuracy: 0.8775 - val_loss: 0.4411 - val_accuracy: 0.8433\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3195 - accuracy: 0.8916 - val_loss: 0.4403 - val_accuracy: 0.8433\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3257 - accuracy: 0.8715 - val_loss: 0.4393 - val_accuracy: 0.8433\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3215 - accuracy: 0.8735 - val_loss: 0.4392 - val_accuracy: 0.8470\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3234 - accuracy: 0.8815 - val_loss: 0.4391 - val_accuracy: 0.8470\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3283 - accuracy: 0.8795 - val_loss: 0.4388 - val_accuracy: 0.8470\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3234 - accuracy: 0.8735 - val_loss: 0.4383 - val_accuracy: 0.8507\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3231 - accuracy: 0.8795 - val_loss: 0.4387 - val_accuracy: 0.8470\n",
      "125/125 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 862us/step - loss: 0.7120 - accuracy: 0.6325 - val_loss: 0.7116 - val_accuracy: 0.6269\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6973 - accuracy: 0.6687 - val_loss: 0.7082 - val_accuracy: 0.6679\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6779 - accuracy: 0.6948 - val_loss: 0.7050 - val_accuracy: 0.6791\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6626 - accuracy: 0.7169 - val_loss: 0.7021 - val_accuracy: 0.6716\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6459 - accuracy: 0.7369 - val_loss: 0.6986 - val_accuracy: 0.6455\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6398 - accuracy: 0.7309 - val_loss: 0.6958 - val_accuracy: 0.6493\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6238 - accuracy: 0.7490 - val_loss: 0.6931 - val_accuracy: 0.6567\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.6128 - accuracy: 0.7530 - val_loss: 0.6899 - val_accuracy: 0.6567\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6045 - accuracy: 0.7550 - val_loss: 0.6865 - val_accuracy: 0.6642\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5932 - accuracy: 0.7751 - val_loss: 0.6828 - val_accuracy: 0.6679\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5846 - accuracy: 0.7651 - val_loss: 0.6788 - val_accuracy: 0.6791\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5814 - accuracy: 0.7671 - val_loss: 0.6748 - val_accuracy: 0.6791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5713 - accuracy: 0.7811 - val_loss: 0.6712 - val_accuracy: 0.6866\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5605 - accuracy: 0.7912 - val_loss: 0.6671 - val_accuracy: 0.6866\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5503 - accuracy: 0.7791 - val_loss: 0.6626 - val_accuracy: 0.6940\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5453 - accuracy: 0.7851 - val_loss: 0.6582 - val_accuracy: 0.6940\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5397 - accuracy: 0.7992 - val_loss: 0.6536 - val_accuracy: 0.7015\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5342 - accuracy: 0.7992 - val_loss: 0.6486 - val_accuracy: 0.6978\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5224 - accuracy: 0.8153 - val_loss: 0.6434 - val_accuracy: 0.6940\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 84us/step - loss: 0.5105 - accuracy: 0.8193 - val_loss: 0.6381 - val_accuracy: 0.6903\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5035 - accuracy: 0.8112 - val_loss: 0.6327 - val_accuracy: 0.7015\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4973 - accuracy: 0.8193 - val_loss: 0.6270 - val_accuracy: 0.7052\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4911 - accuracy: 0.8253 - val_loss: 0.6210 - val_accuracy: 0.7276\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4854 - accuracy: 0.8293 - val_loss: 0.6151 - val_accuracy: 0.7313\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4802 - accuracy: 0.8253 - val_loss: 0.6096 - val_accuracy: 0.7276\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4714 - accuracy: 0.8333 - val_loss: 0.6042 - val_accuracy: 0.7351\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4645 - accuracy: 0.8394 - val_loss: 0.5986 - val_accuracy: 0.7425\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4554 - accuracy: 0.8333 - val_loss: 0.5932 - val_accuracy: 0.7537\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.4498 - accuracy: 0.8474 - val_loss: 0.5881 - val_accuracy: 0.7612\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4499 - accuracy: 0.8414 - val_loss: 0.5830 - val_accuracy: 0.7687\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4391 - accuracy: 0.8534 - val_loss: 0.5785 - val_accuracy: 0.7687\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4362 - accuracy: 0.8474 - val_loss: 0.5741 - val_accuracy: 0.7799\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4295 - accuracy: 0.8554 - val_loss: 0.5699 - val_accuracy: 0.7799\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4317 - accuracy: 0.8514 - val_loss: 0.5660 - val_accuracy: 0.7836\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4249 - accuracy: 0.8434 - val_loss: 0.5622 - val_accuracy: 0.7836\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4202 - accuracy: 0.8454 - val_loss: 0.5588 - val_accuracy: 0.7910\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4143 - accuracy: 0.8534 - val_loss: 0.5554 - val_accuracy: 0.8022\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4152 - accuracy: 0.8534 - val_loss: 0.5521 - val_accuracy: 0.8022\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4076 - accuracy: 0.8494 - val_loss: 0.5491 - val_accuracy: 0.7910\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4075 - accuracy: 0.8534 - val_loss: 0.5462 - val_accuracy: 0.7948\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3975 - accuracy: 0.8514 - val_loss: 0.5432 - val_accuracy: 0.8022\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3957 - accuracy: 0.8514 - val_loss: 0.5405 - val_accuracy: 0.8134\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3978 - accuracy: 0.8514 - val_loss: 0.5378 - val_accuracy: 0.8134\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3922 - accuracy: 0.8494 - val_loss: 0.5350 - val_accuracy: 0.8060\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3917 - accuracy: 0.8554 - val_loss: 0.5323 - val_accuracy: 0.8097\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3896 - accuracy: 0.8494 - val_loss: 0.5297 - val_accuracy: 0.8097\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3869 - accuracy: 0.8494 - val_loss: 0.5272 - val_accuracy: 0.8134\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3869 - accuracy: 0.8534 - val_loss: 0.5250 - val_accuracy: 0.8134\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3819 - accuracy: 0.8474 - val_loss: 0.5228 - val_accuracy: 0.8172\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3788 - accuracy: 0.8594 - val_loss: 0.5205 - val_accuracy: 0.8134\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3781 - accuracy: 0.8554 - val_loss: 0.5185 - val_accuracy: 0.8172\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3730 - accuracy: 0.8594 - val_loss: 0.5164 - val_accuracy: 0.8172\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3772 - accuracy: 0.8534 - val_loss: 0.5146 - val_accuracy: 0.8246\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3710 - accuracy: 0.8554 - val_loss: 0.5128 - val_accuracy: 0.8246\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3641 - accuracy: 0.8594 - val_loss: 0.5109 - val_accuracy: 0.8246\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3632 - accuracy: 0.8574 - val_loss: 0.5094 - val_accuracy: 0.8246\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3624 - accuracy: 0.8534 - val_loss: 0.5079 - val_accuracy: 0.8246\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3642 - accuracy: 0.8554 - val_loss: 0.5065 - val_accuracy: 0.8246\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3673 - accuracy: 0.8534 - val_loss: 0.5051 - val_accuracy: 0.8246\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3599 - accuracy: 0.8574 - val_loss: 0.5036 - val_accuracy: 0.8209\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3618 - accuracy: 0.8514 - val_loss: 0.5022 - val_accuracy: 0.8209\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3603 - accuracy: 0.8635 - val_loss: 0.5008 - val_accuracy: 0.8209\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3559 - accuracy: 0.8594 - val_loss: 0.4992 - val_accuracy: 0.8209\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3555 - accuracy: 0.8594 - val_loss: 0.4979 - val_accuracy: 0.8209\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3478 - accuracy: 0.8554 - val_loss: 0.4968 - val_accuracy: 0.8209\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3504 - accuracy: 0.8614 - val_loss: 0.4956 - val_accuracy: 0.8209\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3511 - accuracy: 0.8494 - val_loss: 0.4946 - val_accuracy: 0.8209\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3502 - accuracy: 0.8534 - val_loss: 0.4935 - val_accuracy: 0.8209\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3516 - accuracy: 0.8675 - val_loss: 0.4927 - val_accuracy: 0.8209\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3479 - accuracy: 0.8594 - val_loss: 0.4919 - val_accuracy: 0.8246\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3460 - accuracy: 0.8594 - val_loss: 0.4910 - val_accuracy: 0.8246\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3460 - accuracy: 0.8534 - val_loss: 0.4901 - val_accuracy: 0.8209\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3474 - accuracy: 0.8534 - val_loss: 0.4892 - val_accuracy: 0.8172\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3471 - accuracy: 0.8614 - val_loss: 0.4884 - val_accuracy: 0.8172\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3435 - accuracy: 0.8514 - val_loss: 0.4877 - val_accuracy: 0.8134\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3507 - accuracy: 0.8635 - val_loss: 0.4869 - val_accuracy: 0.8097\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3457 - accuracy: 0.8594 - val_loss: 0.4863 - val_accuracy: 0.8060\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3407 - accuracy: 0.8514 - val_loss: 0.4853 - val_accuracy: 0.8097\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3377 - accuracy: 0.8594 - val_loss: 0.4845 - val_accuracy: 0.8134\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3373 - accuracy: 0.8594 - val_loss: 0.4838 - val_accuracy: 0.8134\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3347 - accuracy: 0.8635 - val_loss: 0.4830 - val_accuracy: 0.8097\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3428 - accuracy: 0.8494 - val_loss: 0.4822 - val_accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3426 - accuracy: 0.8594 - val_loss: 0.4816 - val_accuracy: 0.8172\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3379 - accuracy: 0.8675 - val_loss: 0.4809 - val_accuracy: 0.8134\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3383 - accuracy: 0.8574 - val_loss: 0.4805 - val_accuracy: 0.8172\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3327 - accuracy: 0.8594 - val_loss: 0.4801 - val_accuracy: 0.8172\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3329 - accuracy: 0.8614 - val_loss: 0.4797 - val_accuracy: 0.8172\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3304 - accuracy: 0.8675 - val_loss: 0.4791 - val_accuracy: 0.8209\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3314 - accuracy: 0.8655 - val_loss: 0.4789 - val_accuracy: 0.8246\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3378 - accuracy: 0.8574 - val_loss: 0.4789 - val_accuracy: 0.8246\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3415 - accuracy: 0.8554 - val_loss: 0.4790 - val_accuracy: 0.8284\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3349 - accuracy: 0.8614 - val_loss: 0.4793 - val_accuracy: 0.8284\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3395 - accuracy: 0.8635 - val_loss: 0.4794 - val_accuracy: 0.8284\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3305 - accuracy: 0.8594 - val_loss: 0.4794 - val_accuracy: 0.8246\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3340 - accuracy: 0.8635 - val_loss: 0.4803 - val_accuracy: 0.8246\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3332 - accuracy: 0.8574 - val_loss: 0.4798 - val_accuracy: 0.8246\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3307 - accuracy: 0.8735 - val_loss: 0.4793 - val_accuracy: 0.8246\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3318 - accuracy: 0.8574 - val_loss: 0.4789 - val_accuracy: 0.8246\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3296 - accuracy: 0.8614 - val_loss: 0.4800 - val_accuracy: 0.8246\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3280 - accuracy: 0.8635 - val_loss: 0.4811 - val_accuracy: 0.8209\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 858us/step - loss: 0.6526 - accuracy: 0.6486 - val_loss: 0.9959 - val_accuracy: 0.3881\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.6246 - accuracy: 0.6747 - val_loss: 0.9771 - val_accuracy: 0.3881\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.6080 - accuracy: 0.7269 - val_loss: 0.9592 - val_accuracy: 0.3881\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5932 - accuracy: 0.7088 - val_loss: 0.9404 - val_accuracy: 0.3881\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5815 - accuracy: 0.7329 - val_loss: 0.9177 - val_accuracy: 0.3881\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5663 - accuracy: 0.7410 - val_loss: 0.8919 - val_accuracy: 0.3843\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5514 - accuracy: 0.7490 - val_loss: 0.8690 - val_accuracy: 0.3881\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5448 - accuracy: 0.7289 - val_loss: 0.8477 - val_accuracy: 0.3881\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5369 - accuracy: 0.7570 - val_loss: 0.8280 - val_accuracy: 0.3881\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5367 - accuracy: 0.7450 - val_loss: 0.8087 - val_accuracy: 0.3843\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5286 - accuracy: 0.7651 - val_loss: 0.7910 - val_accuracy: 0.3881\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5243 - accuracy: 0.7570 - val_loss: 0.7743 - val_accuracy: 0.4067\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5216 - accuracy: 0.7731 - val_loss: 0.7587 - val_accuracy: 0.4291\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.5129 - accuracy: 0.7912 - val_loss: 0.7436 - val_accuracy: 0.4664\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4993 - accuracy: 0.7851 - val_loss: 0.7293 - val_accuracy: 0.5261\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4991 - accuracy: 0.7871 - val_loss: 0.7121 - val_accuracy: 0.5970\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4925 - accuracy: 0.7992 - val_loss: 0.6975 - val_accuracy: 0.6343\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4860 - accuracy: 0.7851 - val_loss: 0.6825 - val_accuracy: 0.6604\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4929 - accuracy: 0.7831 - val_loss: 0.6695 - val_accuracy: 0.6679\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4730 - accuracy: 0.7932 - val_loss: 0.6577 - val_accuracy: 0.6754\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4735 - accuracy: 0.7912 - val_loss: 0.6470 - val_accuracy: 0.6903\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4684 - accuracy: 0.7952 - val_loss: 0.6347 - val_accuracy: 0.7090\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4595 - accuracy: 0.8052 - val_loss: 0.6246 - val_accuracy: 0.7127\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4667 - accuracy: 0.7972 - val_loss: 0.6148 - val_accuracy: 0.7127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4531 - accuracy: 0.8133 - val_loss: 0.6063 - val_accuracy: 0.7015\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4553 - accuracy: 0.8092 - val_loss: 0.5976 - val_accuracy: 0.7090\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4418 - accuracy: 0.8112 - val_loss: 0.5904 - val_accuracy: 0.7239\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4399 - accuracy: 0.8112 - val_loss: 0.5831 - val_accuracy: 0.7276\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4368 - accuracy: 0.8173 - val_loss: 0.5763 - val_accuracy: 0.7388\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4372 - accuracy: 0.8153 - val_loss: 0.5708 - val_accuracy: 0.7612\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4341 - accuracy: 0.8213 - val_loss: 0.5649 - val_accuracy: 0.7724\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4325 - accuracy: 0.8293 - val_loss: 0.5589 - val_accuracy: 0.7761\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4303 - accuracy: 0.7992 - val_loss: 0.5525 - val_accuracy: 0.7799\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4224 - accuracy: 0.8293 - val_loss: 0.5470 - val_accuracy: 0.7799\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4187 - accuracy: 0.8233 - val_loss: 0.5421 - val_accuracy: 0.7873\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4140 - accuracy: 0.8273 - val_loss: 0.5379 - val_accuracy: 0.7873\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4122 - accuracy: 0.8333 - val_loss: 0.5334 - val_accuracy: 0.7873\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4091 - accuracy: 0.8333 - val_loss: 0.5291 - val_accuracy: 0.7873\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4061 - accuracy: 0.8213 - val_loss: 0.5252 - val_accuracy: 0.7985\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4063 - accuracy: 0.8353 - val_loss: 0.5211 - val_accuracy: 0.8022\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4036 - accuracy: 0.8353 - val_loss: 0.5178 - val_accuracy: 0.8022\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4023 - accuracy: 0.8394 - val_loss: 0.5143 - val_accuracy: 0.8060\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3968 - accuracy: 0.8414 - val_loss: 0.5114 - val_accuracy: 0.8060\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3904 - accuracy: 0.8414 - val_loss: 0.5083 - val_accuracy: 0.8060\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3915 - accuracy: 0.8494 - val_loss: 0.5050 - val_accuracy: 0.8097\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3916 - accuracy: 0.8434 - val_loss: 0.5019 - val_accuracy: 0.8097\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3914 - accuracy: 0.8394 - val_loss: 0.4993 - val_accuracy: 0.8097\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3890 - accuracy: 0.8454 - val_loss: 0.4968 - val_accuracy: 0.8134\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3878 - accuracy: 0.8414 - val_loss: 0.4944 - val_accuracy: 0.8172\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3864 - accuracy: 0.8414 - val_loss: 0.4916 - val_accuracy: 0.8172\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3870 - accuracy: 0.8353 - val_loss: 0.4890 - val_accuracy: 0.8172\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3754 - accuracy: 0.8434 - val_loss: 0.4872 - val_accuracy: 0.8172\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3795 - accuracy: 0.8454 - val_loss: 0.4854 - val_accuracy: 0.8209\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3975 - accuracy: 0.8454 - val_loss: 0.4834 - val_accuracy: 0.8246\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3781 - accuracy: 0.8534 - val_loss: 0.4818 - val_accuracy: 0.8246\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3828 - accuracy: 0.8454 - val_loss: 0.4801 - val_accuracy: 0.8246\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3825 - accuracy: 0.8454 - val_loss: 0.4785 - val_accuracy: 0.8284\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3744 - accuracy: 0.8494 - val_loss: 0.4770 - val_accuracy: 0.8284\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3776 - accuracy: 0.8494 - val_loss: 0.4756 - val_accuracy: 0.8209\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3806 - accuracy: 0.8454 - val_loss: 0.4744 - val_accuracy: 0.8209\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3744 - accuracy: 0.8494 - val_loss: 0.4736 - val_accuracy: 0.8284\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3791 - accuracy: 0.8514 - val_loss: 0.4726 - val_accuracy: 0.8321\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3760 - accuracy: 0.8554 - val_loss: 0.4715 - val_accuracy: 0.8396\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3756 - accuracy: 0.8494 - val_loss: 0.4704 - val_accuracy: 0.8470\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3677 - accuracy: 0.8514 - val_loss: 0.4691 - val_accuracy: 0.8470\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3730 - accuracy: 0.8534 - val_loss: 0.4679 - val_accuracy: 0.8470\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3731 - accuracy: 0.8554 - val_loss: 0.4675 - val_accuracy: 0.8470\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3661 - accuracy: 0.8514 - val_loss: 0.4669 - val_accuracy: 0.8433\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3695 - accuracy: 0.8514 - val_loss: 0.4659 - val_accuracy: 0.8358\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3667 - accuracy: 0.8554 - val_loss: 0.4651 - val_accuracy: 0.8284\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3673 - accuracy: 0.8574 - val_loss: 0.4648 - val_accuracy: 0.8284\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3723 - accuracy: 0.8494 - val_loss: 0.4652 - val_accuracy: 0.8246\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3650 - accuracy: 0.8574 - val_loss: 0.4661 - val_accuracy: 0.8246\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3641 - accuracy: 0.8554 - val_loss: 0.4664 - val_accuracy: 0.8284\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3643 - accuracy: 0.8534 - val_loss: 0.4655 - val_accuracy: 0.8284\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3658 - accuracy: 0.8494 - val_loss: 0.4650 - val_accuracy: 0.8246\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3585 - accuracy: 0.8534 - val_loss: 0.4646 - val_accuracy: 0.8246\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3643 - accuracy: 0.8554 - val_loss: 0.4640 - val_accuracy: 0.8246\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3700 - accuracy: 0.8514 - val_loss: 0.4635 - val_accuracy: 0.8209\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3623 - accuracy: 0.8614 - val_loss: 0.4636 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3647 - accuracy: 0.8494 - val_loss: 0.4633 - val_accuracy: 0.8246\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3586 - accuracy: 0.8574 - val_loss: 0.4632 - val_accuracy: 0.8284\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3733 - accuracy: 0.8554 - val_loss: 0.4634 - val_accuracy: 0.8246\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3715 - accuracy: 0.8514 - val_loss: 0.4633 - val_accuracy: 0.8209\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3633 - accuracy: 0.8434 - val_loss: 0.4636 - val_accuracy: 0.8209\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3566 - accuracy: 0.8494 - val_loss: 0.4638 - val_accuracy: 0.8321\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3604 - accuracy: 0.8534 - val_loss: 0.4639 - val_accuracy: 0.8284\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3615 - accuracy: 0.8534 - val_loss: 0.4636 - val_accuracy: 0.8246\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3580 - accuracy: 0.8594 - val_loss: 0.4639 - val_accuracy: 0.8321\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3656 - accuracy: 0.8574 - val_loss: 0.4646 - val_accuracy: 0.8321\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3683 - accuracy: 0.8454 - val_loss: 0.4645 - val_accuracy: 0.8321\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3607 - accuracy: 0.8594 - val_loss: 0.4651 - val_accuracy: 0.8321\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3709 - accuracy: 0.8474 - val_loss: 0.4648 - val_accuracy: 0.8358\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3687 - accuracy: 0.8474 - val_loss: 0.4640 - val_accuracy: 0.8358\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3601 - accuracy: 0.8655 - val_loss: 0.4632 - val_accuracy: 0.8358\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3548 - accuracy: 0.8574 - val_loss: 0.4633 - val_accuracy: 0.8321\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3633 - accuracy: 0.8594 - val_loss: 0.4637 - val_accuracy: 0.8246\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3553 - accuracy: 0.8534 - val_loss: 0.4641 - val_accuracy: 0.8246\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3553 - accuracy: 0.8534 - val_loss: 0.4648 - val_accuracy: 0.8284\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3430 - accuracy: 0.8574 - val_loss: 0.4650 - val_accuracy: 0.8284\n",
      "125/125 [==============================] - 0s 16us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 0s 878us/step - loss: 0.9652 - accuracy: 0.3407 - val_loss: 0.7259 - val_accuracy: 0.6269\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.9039 - accuracy: 0.3527 - val_loss: 0.7233 - val_accuracy: 0.6306\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.8629 - accuracy: 0.3627 - val_loss: 0.7207 - val_accuracy: 0.6194\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.8293 - accuracy: 0.3848 - val_loss: 0.7179 - val_accuracy: 0.6194\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.7830 - accuracy: 0.4068 - val_loss: 0.7151 - val_accuracy: 0.6194\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.7519 - accuracy: 0.4389 - val_loss: 0.7126 - val_accuracy: 0.6194\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.7484 - accuracy: 0.4850 - val_loss: 0.7103 - val_accuracy: 0.6231\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.7229 - accuracy: 0.5832 - val_loss: 0.7082 - val_accuracy: 0.6231\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6942 - accuracy: 0.6673 - val_loss: 0.7061 - val_accuracy: 0.6231\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6912 - accuracy: 0.6954 - val_loss: 0.7041 - val_accuracy: 0.6231\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.6696 - accuracy: 0.6934 - val_loss: 0.7021 - val_accuracy: 0.6231\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6588 - accuracy: 0.7034 - val_loss: 0.7000 - val_accuracy: 0.6231\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6480 - accuracy: 0.7375 - val_loss: 0.6979 - val_accuracy: 0.6269\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6469 - accuracy: 0.7214 - val_loss: 0.6958 - val_accuracy: 0.6269\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.6199 - accuracy: 0.7375 - val_loss: 0.6934 - val_accuracy: 0.6269\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6276 - accuracy: 0.7375 - val_loss: 0.6909 - val_accuracy: 0.6269\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.6026 - accuracy: 0.7495 - val_loss: 0.6884 - val_accuracy: 0.6269\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5991 - accuracy: 0.7575 - val_loss: 0.6860 - val_accuracy: 0.6269\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5932 - accuracy: 0.7595 - val_loss: 0.6834 - val_accuracy: 0.6269\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5689 - accuracy: 0.7615 - val_loss: 0.6805 - val_accuracy: 0.6269\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.5553 - accuracy: 0.7715 - val_loss: 0.6771 - val_accuracy: 0.6306\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5537 - accuracy: 0.7856 - val_loss: 0.6735 - val_accuracy: 0.6306\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5444 - accuracy: 0.7715 - val_loss: 0.6699 - val_accuracy: 0.6418\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5386 - accuracy: 0.7816 - val_loss: 0.6662 - val_accuracy: 0.6530\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5291 - accuracy: 0.7936 - val_loss: 0.6620 - val_accuracy: 0.6530\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5259 - accuracy: 0.7856 - val_loss: 0.6576 - val_accuracy: 0.6567\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5101 - accuracy: 0.7936 - val_loss: 0.6531 - val_accuracy: 0.6567\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5031 - accuracy: 0.7976 - val_loss: 0.6477 - val_accuracy: 0.6642\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5012 - accuracy: 0.7976 - val_loss: 0.6417 - val_accuracy: 0.6716\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4977 - accuracy: 0.8056 - val_loss: 0.6351 - val_accuracy: 0.6716\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4808 - accuracy: 0.8096 - val_loss: 0.6287 - val_accuracy: 0.6791\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4784 - accuracy: 0.8156 - val_loss: 0.6217 - val_accuracy: 0.6940\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4737 - accuracy: 0.8317 - val_loss: 0.6147 - val_accuracy: 0.7052\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4630 - accuracy: 0.8236 - val_loss: 0.6076 - val_accuracy: 0.7052\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4612 - accuracy: 0.8317 - val_loss: 0.6009 - val_accuracy: 0.7127\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4481 - accuracy: 0.8196 - val_loss: 0.5948 - val_accuracy: 0.7127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4468 - accuracy: 0.8337 - val_loss: 0.5888 - val_accuracy: 0.7239\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4417 - accuracy: 0.8297 - val_loss: 0.5828 - val_accuracy: 0.7313\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4450 - accuracy: 0.8377 - val_loss: 0.5770 - val_accuracy: 0.7276\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4327 - accuracy: 0.8257 - val_loss: 0.5713 - val_accuracy: 0.7388\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4297 - accuracy: 0.8337 - val_loss: 0.5657 - val_accuracy: 0.7388\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4268 - accuracy: 0.8437 - val_loss: 0.5603 - val_accuracy: 0.7463\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4254 - accuracy: 0.8317 - val_loss: 0.5545 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4179 - accuracy: 0.8397 - val_loss: 0.5492 - val_accuracy: 0.7537\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4109 - accuracy: 0.8477 - val_loss: 0.5439 - val_accuracy: 0.7537\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4163 - accuracy: 0.8357 - val_loss: 0.5390 - val_accuracy: 0.7687\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4047 - accuracy: 0.8457 - val_loss: 0.5339 - val_accuracy: 0.7724\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4033 - accuracy: 0.8457 - val_loss: 0.5288 - val_accuracy: 0.7687\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3984 - accuracy: 0.8457 - val_loss: 0.5236 - val_accuracy: 0.7724\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3978 - accuracy: 0.8377 - val_loss: 0.5186 - val_accuracy: 0.7761\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3917 - accuracy: 0.8517 - val_loss: 0.5141 - val_accuracy: 0.7873\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 86us/step - loss: 0.3910 - accuracy: 0.8437 - val_loss: 0.5099 - val_accuracy: 0.7910\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3897 - accuracy: 0.8517 - val_loss: 0.5065 - val_accuracy: 0.8022\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3824 - accuracy: 0.8477 - val_loss: 0.5028 - val_accuracy: 0.8022\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3784 - accuracy: 0.8577 - val_loss: 0.4997 - val_accuracy: 0.7948\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3770 - accuracy: 0.8537 - val_loss: 0.4966 - val_accuracy: 0.7948\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3723 - accuracy: 0.8577 - val_loss: 0.4938 - val_accuracy: 0.7948\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3700 - accuracy: 0.8517 - val_loss: 0.4914 - val_accuracy: 0.7985\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3697 - accuracy: 0.8557 - val_loss: 0.4894 - val_accuracy: 0.8097\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3677 - accuracy: 0.8537 - val_loss: 0.4872 - val_accuracy: 0.8060\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3624 - accuracy: 0.8637 - val_loss: 0.4855 - val_accuracy: 0.8097\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3639 - accuracy: 0.8597 - val_loss: 0.4835 - val_accuracy: 0.8097\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3688 - accuracy: 0.8677 - val_loss: 0.4818 - val_accuracy: 0.8060\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3665 - accuracy: 0.8577 - val_loss: 0.4802 - val_accuracy: 0.8097\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3663 - accuracy: 0.8637 - val_loss: 0.4785 - val_accuracy: 0.8172\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3608 - accuracy: 0.8637 - val_loss: 0.4770 - val_accuracy: 0.8172\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3630 - accuracy: 0.8637 - val_loss: 0.4758 - val_accuracy: 0.8172\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3550 - accuracy: 0.8697 - val_loss: 0.4744 - val_accuracy: 0.8209\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3562 - accuracy: 0.8617 - val_loss: 0.4735 - val_accuracy: 0.8209\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3513 - accuracy: 0.8677 - val_loss: 0.4725 - val_accuracy: 0.8209\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3544 - accuracy: 0.8597 - val_loss: 0.4715 - val_accuracy: 0.8321\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3541 - accuracy: 0.8677 - val_loss: 0.4708 - val_accuracy: 0.8246\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3522 - accuracy: 0.8657 - val_loss: 0.4702 - val_accuracy: 0.8321\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3534 - accuracy: 0.8737 - val_loss: 0.4698 - val_accuracy: 0.8321\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3478 - accuracy: 0.8697 - val_loss: 0.4693 - val_accuracy: 0.8321\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3492 - accuracy: 0.8737 - val_loss: 0.4689 - val_accuracy: 0.8321\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3460 - accuracy: 0.8737 - val_loss: 0.4687 - val_accuracy: 0.8321\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3478 - accuracy: 0.8677 - val_loss: 0.4681 - val_accuracy: 0.8321\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3437 - accuracy: 0.8758 - val_loss: 0.4672 - val_accuracy: 0.8358\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3493 - accuracy: 0.8717 - val_loss: 0.4667 - val_accuracy: 0.8321\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3445 - accuracy: 0.8697 - val_loss: 0.4666 - val_accuracy: 0.8321\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3389 - accuracy: 0.8717 - val_loss: 0.4667 - val_accuracy: 0.8358\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3447 - accuracy: 0.8717 - val_loss: 0.4669 - val_accuracy: 0.8321\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3447 - accuracy: 0.8778 - val_loss: 0.4672 - val_accuracy: 0.8358\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3386 - accuracy: 0.8798 - val_loss: 0.4669 - val_accuracy: 0.8321\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3357 - accuracy: 0.8737 - val_loss: 0.4670 - val_accuracy: 0.8321\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3363 - accuracy: 0.8697 - val_loss: 0.4668 - val_accuracy: 0.8321\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3316 - accuracy: 0.8758 - val_loss: 0.4665 - val_accuracy: 0.8321\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3289 - accuracy: 0.8758 - val_loss: 0.4664 - val_accuracy: 0.8321\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3478 - accuracy: 0.8637 - val_loss: 0.4666 - val_accuracy: 0.8321\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3317 - accuracy: 0.8778 - val_loss: 0.4663 - val_accuracy: 0.8321\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3348 - accuracy: 0.8758 - val_loss: 0.4656 - val_accuracy: 0.8321\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3355 - accuracy: 0.8778 - val_loss: 0.4655 - val_accuracy: 0.8321\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3325 - accuracy: 0.8818 - val_loss: 0.4657 - val_accuracy: 0.8321\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3343 - accuracy: 0.8758 - val_loss: 0.4661 - val_accuracy: 0.8321\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3308 - accuracy: 0.8798 - val_loss: 0.4661 - val_accuracy: 0.8321\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3311 - accuracy: 0.8737 - val_loss: 0.4663 - val_accuracy: 0.8321\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3455 - accuracy: 0.8758 - val_loss: 0.4669 - val_accuracy: 0.8321\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3304 - accuracy: 0.8758 - val_loss: 0.4674 - val_accuracy: 0.8321\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3368 - accuracy: 0.8758 - val_loss: 0.4675 - val_accuracy: 0.8284\n",
      "124/124 [==============================] - 0s 16us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 0s 942us/step - loss: 0.8497 - accuracy: 0.6112 - val_loss: 0.7568 - val_accuracy: 0.3731\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.8183 - accuracy: 0.6212 - val_loss: 0.7508 - val_accuracy: 0.3806\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.7763 - accuracy: 0.6373 - val_loss: 0.7440 - val_accuracy: 0.3843\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.7510 - accuracy: 0.6533 - val_loss: 0.7373 - val_accuracy: 0.3881\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.7008 - accuracy: 0.6693 - val_loss: 0.7315 - val_accuracy: 0.3955\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.6895 - accuracy: 0.6633 - val_loss: 0.7258 - val_accuracy: 0.4142\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.6615 - accuracy: 0.7134 - val_loss: 0.7194 - val_accuracy: 0.4627\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.6394 - accuracy: 0.7234 - val_loss: 0.7136 - val_accuracy: 0.5709\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.6238 - accuracy: 0.7395 - val_loss: 0.7086 - val_accuracy: 0.5858\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5965 - accuracy: 0.7255 - val_loss: 0.7038 - val_accuracy: 0.5821\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5809 - accuracy: 0.7455 - val_loss: 0.6991 - val_accuracy: 0.5821\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5647 - accuracy: 0.7756 - val_loss: 0.6937 - val_accuracy: 0.5821\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5417 - accuracy: 0.7796 - val_loss: 0.6884 - val_accuracy: 0.5896\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5378 - accuracy: 0.7896 - val_loss: 0.6825 - val_accuracy: 0.5933\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.5191 - accuracy: 0.7976 - val_loss: 0.6765 - val_accuracy: 0.6007\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5175 - accuracy: 0.7956 - val_loss: 0.6703 - val_accuracy: 0.5970\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 84us/step - loss: 0.5012 - accuracy: 0.8056 - val_loss: 0.6619 - val_accuracy: 0.6418\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5078 - accuracy: 0.7916 - val_loss: 0.6545 - val_accuracy: 0.6642\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4885 - accuracy: 0.7996 - val_loss: 0.6466 - val_accuracy: 0.6754\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4831 - accuracy: 0.7996 - val_loss: 0.6389 - val_accuracy: 0.6791\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4672 - accuracy: 0.8176 - val_loss: 0.6313 - val_accuracy: 0.6940\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4748 - accuracy: 0.8176 - val_loss: 0.6242 - val_accuracy: 0.7052\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4688 - accuracy: 0.8156 - val_loss: 0.6177 - val_accuracy: 0.7052\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4518 - accuracy: 0.8216 - val_loss: 0.6110 - val_accuracy: 0.7052\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4607 - accuracy: 0.8196 - val_loss: 0.6047 - val_accuracy: 0.7090\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4468 - accuracy: 0.8136 - val_loss: 0.5994 - val_accuracy: 0.7052\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4420 - accuracy: 0.8277 - val_loss: 0.5937 - val_accuracy: 0.7052\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4392 - accuracy: 0.8297 - val_loss: 0.5881 - val_accuracy: 0.7090\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4304 - accuracy: 0.8096 - val_loss: 0.5827 - val_accuracy: 0.7127\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4377 - accuracy: 0.8257 - val_loss: 0.5779 - val_accuracy: 0.7127\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4340 - accuracy: 0.8156 - val_loss: 0.5735 - val_accuracy: 0.7127\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.4252 - accuracy: 0.8236 - val_loss: 0.5688 - val_accuracy: 0.7201\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4209 - accuracy: 0.8297 - val_loss: 0.5645 - val_accuracy: 0.7201\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4222 - accuracy: 0.8357 - val_loss: 0.5597 - val_accuracy: 0.7201\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4126 - accuracy: 0.8377 - val_loss: 0.5566 - val_accuracy: 0.7201\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4187 - accuracy: 0.8297 - val_loss: 0.5535 - val_accuracy: 0.7201\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4164 - accuracy: 0.8377 - val_loss: 0.5503 - val_accuracy: 0.7351\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4081 - accuracy: 0.8417 - val_loss: 0.5473 - val_accuracy: 0.7351\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4108 - accuracy: 0.8397 - val_loss: 0.5444 - val_accuracy: 0.7313\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4083 - accuracy: 0.8537 - val_loss: 0.5419 - val_accuracy: 0.7388\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4055 - accuracy: 0.8477 - val_loss: 0.5395 - val_accuracy: 0.7388\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4011 - accuracy: 0.8437 - val_loss: 0.5369 - val_accuracy: 0.7463\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3978 - accuracy: 0.8497 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3971 - accuracy: 0.8377 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3984 - accuracy: 0.8517 - val_loss: 0.5306 - val_accuracy: 0.7537\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3906 - accuracy: 0.8457 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3915 - accuracy: 0.8477 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3879 - accuracy: 0.8597 - val_loss: 0.5258 - val_accuracy: 0.7463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3866 - accuracy: 0.8637 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3830 - accuracy: 0.8537 - val_loss: 0.5227 - val_accuracy: 0.7575\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3874 - accuracy: 0.8437 - val_loss: 0.5204 - val_accuracy: 0.7612\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3971 - accuracy: 0.8397 - val_loss: 0.5198 - val_accuracy: 0.7649\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3783 - accuracy: 0.8537 - val_loss: 0.5169 - val_accuracy: 0.7649\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3924 - accuracy: 0.8537 - val_loss: 0.5150 - val_accuracy: 0.7649\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3822 - accuracy: 0.8557 - val_loss: 0.5147 - val_accuracy: 0.7649\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3804 - accuracy: 0.8457 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3787 - accuracy: 0.8497 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3825 - accuracy: 0.8617 - val_loss: 0.5113 - val_accuracy: 0.7724\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3783 - accuracy: 0.8637 - val_loss: 0.5099 - val_accuracy: 0.7761\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3727 - accuracy: 0.8597 - val_loss: 0.5085 - val_accuracy: 0.7799\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3656 - accuracy: 0.8617 - val_loss: 0.5084 - val_accuracy: 0.7836\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3654 - accuracy: 0.8517 - val_loss: 0.5070 - val_accuracy: 0.7799\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3673 - accuracy: 0.8637 - val_loss: 0.5070 - val_accuracy: 0.7799\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3623 - accuracy: 0.8677 - val_loss: 0.5055 - val_accuracy: 0.7836\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3559 - accuracy: 0.8697 - val_loss: 0.5063 - val_accuracy: 0.7836\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3630 - accuracy: 0.8497 - val_loss: 0.5067 - val_accuracy: 0.7836\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3630 - accuracy: 0.8577 - val_loss: 0.5059 - val_accuracy: 0.7836\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3664 - accuracy: 0.8637 - val_loss: 0.5049 - val_accuracy: 0.7985\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3645 - accuracy: 0.8617 - val_loss: 0.5036 - val_accuracy: 0.8022\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3711 - accuracy: 0.8457 - val_loss: 0.5012 - val_accuracy: 0.8022\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3654 - accuracy: 0.8677 - val_loss: 0.4980 - val_accuracy: 0.8022\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3602 - accuracy: 0.8657 - val_loss: 0.4970 - val_accuracy: 0.8060\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3618 - accuracy: 0.8597 - val_loss: 0.4992 - val_accuracy: 0.8060\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3668 - accuracy: 0.8637 - val_loss: 0.5006 - val_accuracy: 0.8060\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.3601 - accuracy: 0.8677 - val_loss: 0.5012 - val_accuracy: 0.8060\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3622 - accuracy: 0.8657 - val_loss: 0.5022 - val_accuracy: 0.7985\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3560 - accuracy: 0.8637 - val_loss: 0.5014 - val_accuracy: 0.7948\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3491 - accuracy: 0.8758 - val_loss: 0.4987 - val_accuracy: 0.7948\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3535 - accuracy: 0.8697 - val_loss: 0.4979 - val_accuracy: 0.7948\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3581 - accuracy: 0.8657 - val_loss: 0.4967 - val_accuracy: 0.7948\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3548 - accuracy: 0.8697 - val_loss: 0.4954 - val_accuracy: 0.8060\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.3516 - accuracy: 0.8637 - val_loss: 0.4944 - val_accuracy: 0.8172\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3504 - accuracy: 0.8597 - val_loss: 0.4970 - val_accuracy: 0.8209\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3542 - accuracy: 0.8677 - val_loss: 0.4958 - val_accuracy: 0.8134\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3507 - accuracy: 0.8657 - val_loss: 0.4960 - val_accuracy: 0.8134\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3638 - accuracy: 0.8677 - val_loss: 0.4969 - val_accuracy: 0.8022\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3547 - accuracy: 0.8677 - val_loss: 0.4947 - val_accuracy: 0.8060\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3500 - accuracy: 0.8657 - val_loss: 0.4940 - val_accuracy: 0.8060\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3534 - accuracy: 0.8617 - val_loss: 0.4938 - val_accuracy: 0.8060\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3489 - accuracy: 0.8697 - val_loss: 0.4930 - val_accuracy: 0.8060\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3482 - accuracy: 0.8637 - val_loss: 0.4924 - val_accuracy: 0.8060\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3515 - accuracy: 0.8637 - val_loss: 0.4911 - val_accuracy: 0.8060\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3530 - accuracy: 0.8717 - val_loss: 0.4903 - val_accuracy: 0.8060\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3536 - accuracy: 0.8758 - val_loss: 0.4892 - val_accuracy: 0.8134\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3461 - accuracy: 0.8677 - val_loss: 0.4905 - val_accuracy: 0.8134\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3422 - accuracy: 0.8677 - val_loss: 0.4916 - val_accuracy: 0.8134\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3473 - accuracy: 0.8677 - val_loss: 0.4908 - val_accuracy: 0.8134\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3533 - accuracy: 0.8617 - val_loss: 0.4905 - val_accuracy: 0.8134\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3526 - accuracy: 0.8677 - val_loss: 0.4891 - val_accuracy: 0.8097\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3434 - accuracy: 0.8657 - val_loss: 0.4911 - val_accuracy: 0.8134\n",
      "124/124 [==============================] - 0s 20us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 860us/step - loss: 1.1950 - accuracy: 0.3454 - val_loss: 0.8817 - val_accuracy: 0.2985\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 1.1277 - accuracy: 0.3976 - val_loss: 0.8754 - val_accuracy: 0.2985\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 1.0717 - accuracy: 0.4197 - val_loss: 0.8692 - val_accuracy: 0.2873\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 1.0140 - accuracy: 0.4538 - val_loss: 0.8619 - val_accuracy: 0.2910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.9670 - accuracy: 0.4799 - val_loss: 0.8541 - val_accuracy: 0.2910\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.9214 - accuracy: 0.5040 - val_loss: 0.8466 - val_accuracy: 0.2910\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.8778 - accuracy: 0.5281 - val_loss: 0.8381 - val_accuracy: 0.2910\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.8340 - accuracy: 0.5361 - val_loss: 0.8284 - val_accuracy: 0.2910\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.7918 - accuracy: 0.5663 - val_loss: 0.8168 - val_accuracy: 0.3060\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.7505 - accuracy: 0.5783 - val_loss: 0.8049 - val_accuracy: 0.3321\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.7209 - accuracy: 0.5803 - val_loss: 0.7925 - val_accuracy: 0.3993\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.7005 - accuracy: 0.5964 - val_loss: 0.7812 - val_accuracy: 0.4515\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.6675 - accuracy: 0.6165 - val_loss: 0.7706 - val_accuracy: 0.4963\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6491 - accuracy: 0.6265 - val_loss: 0.7607 - val_accuracy: 0.5187\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.6348 - accuracy: 0.6305 - val_loss: 0.7522 - val_accuracy: 0.5224\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.6085 - accuracy: 0.6667 - val_loss: 0.7444 - val_accuracy: 0.5336\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.6031 - accuracy: 0.6647 - val_loss: 0.7375 - val_accuracy: 0.5299\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5856 - accuracy: 0.7028 - val_loss: 0.7312 - val_accuracy: 0.5299\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.5803 - accuracy: 0.7229 - val_loss: 0.7250 - val_accuracy: 0.5448\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5685 - accuracy: 0.7369 - val_loss: 0.7193 - val_accuracy: 0.5597\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5565 - accuracy: 0.7470 - val_loss: 0.7135 - val_accuracy: 0.5784\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5572 - accuracy: 0.7550 - val_loss: 0.7076 - val_accuracy: 0.5896\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5434 - accuracy: 0.7811 - val_loss: 0.7016 - val_accuracy: 0.6007\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5381 - accuracy: 0.7892 - val_loss: 0.6961 - val_accuracy: 0.6194\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5298 - accuracy: 0.7771 - val_loss: 0.6912 - val_accuracy: 0.6493\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5189 - accuracy: 0.7932 - val_loss: 0.6864 - val_accuracy: 0.6604\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5181 - accuracy: 0.7952 - val_loss: 0.6816 - val_accuracy: 0.6754\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5126 - accuracy: 0.7892 - val_loss: 0.6770 - val_accuracy: 0.6791\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5114 - accuracy: 0.8032 - val_loss: 0.6721 - val_accuracy: 0.6754\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5054 - accuracy: 0.8052 - val_loss: 0.6676 - val_accuracy: 0.6791\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4953 - accuracy: 0.8092 - val_loss: 0.6635 - val_accuracy: 0.6716\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4912 - accuracy: 0.8112 - val_loss: 0.6595 - val_accuracy: 0.6642\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4868 - accuracy: 0.8112 - val_loss: 0.6558 - val_accuracy: 0.6716\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4861 - accuracy: 0.8133 - val_loss: 0.6520 - val_accuracy: 0.6754\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4842 - accuracy: 0.8112 - val_loss: 0.6475 - val_accuracy: 0.6828\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4710 - accuracy: 0.8072 - val_loss: 0.6433 - val_accuracy: 0.7015\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4705 - accuracy: 0.8193 - val_loss: 0.6391 - val_accuracy: 0.7052\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4656 - accuracy: 0.8253 - val_loss: 0.6351 - val_accuracy: 0.7052\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4678 - accuracy: 0.8213 - val_loss: 0.6312 - val_accuracy: 0.7090\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4576 - accuracy: 0.8213 - val_loss: 0.6264 - val_accuracy: 0.7164\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4575 - accuracy: 0.8193 - val_loss: 0.6225 - val_accuracy: 0.7164\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4572 - accuracy: 0.8193 - val_loss: 0.6183 - val_accuracy: 0.7201\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4506 - accuracy: 0.8233 - val_loss: 0.6139 - val_accuracy: 0.7201\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4457 - accuracy: 0.8313 - val_loss: 0.6105 - val_accuracy: 0.7239\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4416 - accuracy: 0.8293 - val_loss: 0.6070 - val_accuracy: 0.7351\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4510 - accuracy: 0.8153 - val_loss: 0.6031 - val_accuracy: 0.7351\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4351 - accuracy: 0.8233 - val_loss: 0.6000 - val_accuracy: 0.7388\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4340 - accuracy: 0.8373 - val_loss: 0.5968 - val_accuracy: 0.7388\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4336 - accuracy: 0.8373 - val_loss: 0.5933 - val_accuracy: 0.7537\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4336 - accuracy: 0.8394 - val_loss: 0.5897 - val_accuracy: 0.7537\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4379 - accuracy: 0.8333 - val_loss: 0.5865 - val_accuracy: 0.7463\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.4343 - accuracy: 0.8394 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4214 - accuracy: 0.8293 - val_loss: 0.5807 - val_accuracy: 0.7463\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4213 - accuracy: 0.8454 - val_loss: 0.5777 - val_accuracy: 0.7537\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4175 - accuracy: 0.8373 - val_loss: 0.5753 - val_accuracy: 0.7537\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4170 - accuracy: 0.8373 - val_loss: 0.5732 - val_accuracy: 0.7537\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4224 - accuracy: 0.8353 - val_loss: 0.5705 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.4203 - accuracy: 0.8434 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4138 - accuracy: 0.8414 - val_loss: 0.5629 - val_accuracy: 0.7537\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4092 - accuracy: 0.8514 - val_loss: 0.5605 - val_accuracy: 0.7537\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4080 - accuracy: 0.8494 - val_loss: 0.5571 - val_accuracy: 0.7575\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4041 - accuracy: 0.8494 - val_loss: 0.5544 - val_accuracy: 0.7649\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4054 - accuracy: 0.8514 - val_loss: 0.5519 - val_accuracy: 0.7612\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4028 - accuracy: 0.8514 - val_loss: 0.5489 - val_accuracy: 0.7649\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3999 - accuracy: 0.8554 - val_loss: 0.5458 - val_accuracy: 0.7724\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4030 - accuracy: 0.8494 - val_loss: 0.5433 - val_accuracy: 0.7687\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3928 - accuracy: 0.8514 - val_loss: 0.5407 - val_accuracy: 0.7687\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3947 - accuracy: 0.8514 - val_loss: 0.5377 - val_accuracy: 0.7799\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3980 - accuracy: 0.8574 - val_loss: 0.5354 - val_accuracy: 0.7910\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3934 - accuracy: 0.8494 - val_loss: 0.5332 - val_accuracy: 0.7910\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3920 - accuracy: 0.8554 - val_loss: 0.5308 - val_accuracy: 0.7910\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3924 - accuracy: 0.8554 - val_loss: 0.5292 - val_accuracy: 0.7948\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 84us/step - loss: 0.3897 - accuracy: 0.8594 - val_loss: 0.5265 - val_accuracy: 0.7948\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3878 - accuracy: 0.8534 - val_loss: 0.5250 - val_accuracy: 0.7910\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3827 - accuracy: 0.8514 - val_loss: 0.5242 - val_accuracy: 0.7910\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 83us/step - loss: 0.3814 - accuracy: 0.8554 - val_loss: 0.5233 - val_accuracy: 0.7910\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3816 - accuracy: 0.8574 - val_loss: 0.5215 - val_accuracy: 0.7910\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3797 - accuracy: 0.8534 - val_loss: 0.5197 - val_accuracy: 0.7910\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3860 - accuracy: 0.8574 - val_loss: 0.5167 - val_accuracy: 0.7910\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3852 - accuracy: 0.8474 - val_loss: 0.5141 - val_accuracy: 0.7910\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3764 - accuracy: 0.8574 - val_loss: 0.5123 - val_accuracy: 0.7910\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3747 - accuracy: 0.8574 - val_loss: 0.5103 - val_accuracy: 0.7910\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3783 - accuracy: 0.8534 - val_loss: 0.5081 - val_accuracy: 0.7910\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3692 - accuracy: 0.8594 - val_loss: 0.5083 - val_accuracy: 0.7910\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3733 - accuracy: 0.8534 - val_loss: 0.5075 - val_accuracy: 0.7948\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3675 - accuracy: 0.8614 - val_loss: 0.5060 - val_accuracy: 0.7910\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3784 - accuracy: 0.8574 - val_loss: 0.5043 - val_accuracy: 0.7910\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 86us/step - loss: 0.3656 - accuracy: 0.8675 - val_loss: 0.5039 - val_accuracy: 0.7910\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3671 - accuracy: 0.8635 - val_loss: 0.5039 - val_accuracy: 0.7910\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 81us/step - loss: 0.3629 - accuracy: 0.8635 - val_loss: 0.5040 - val_accuracy: 0.7910\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3666 - accuracy: 0.8574 - val_loss: 0.5025 - val_accuracy: 0.7910\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3626 - accuracy: 0.8614 - val_loss: 0.5011 - val_accuracy: 0.7910\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3592 - accuracy: 0.8675 - val_loss: 0.4992 - val_accuracy: 0.7948\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3587 - accuracy: 0.8614 - val_loss: 0.4991 - val_accuracy: 0.7873\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3564 - accuracy: 0.8675 - val_loss: 0.4979 - val_accuracy: 0.7910\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3565 - accuracy: 0.8614 - val_loss: 0.4975 - val_accuracy: 0.7910\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3594 - accuracy: 0.8715 - val_loss: 0.4965 - val_accuracy: 0.7910\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3641 - accuracy: 0.8614 - val_loss: 0.4958 - val_accuracy: 0.7948\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3587 - accuracy: 0.8635 - val_loss: 0.4956 - val_accuracy: 0.7910\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3507 - accuracy: 0.8715 - val_loss: 0.4966 - val_accuracy: 0.7910\n",
      "125/125 [==============================] - 0s 20us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 859us/step - loss: 0.8763 - accuracy: 0.4478 - val_loss: 0.7487 - val_accuracy: 0.4179\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.8233 - accuracy: 0.4659 - val_loss: 0.7417 - val_accuracy: 0.4291\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.7949 - accuracy: 0.4639 - val_loss: 0.7340 - val_accuracy: 0.4664\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.7494 - accuracy: 0.5120 - val_loss: 0.7259 - val_accuracy: 0.4701\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.7049 - accuracy: 0.6145 - val_loss: 0.7176 - val_accuracy: 0.4963\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.6621 - accuracy: 0.6727 - val_loss: 0.7097 - val_accuracy: 0.6119\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.6315 - accuracy: 0.6968 - val_loss: 0.7022 - val_accuracy: 0.6493\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.6058 - accuracy: 0.7410 - val_loss: 0.6949 - val_accuracy: 0.6493\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.6150 - accuracy: 0.7390 - val_loss: 0.6881 - val_accuracy: 0.6679\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5753 - accuracy: 0.7590 - val_loss: 0.6815 - val_accuracy: 0.6754\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.5637 - accuracy: 0.7490 - val_loss: 0.6752 - val_accuracy: 0.6828\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.5520 - accuracy: 0.7731 - val_loss: 0.6696 - val_accuracy: 0.6978\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5299 - accuracy: 0.7731 - val_loss: 0.6642 - val_accuracy: 0.6978\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.5139 - accuracy: 0.7791 - val_loss: 0.6587 - val_accuracy: 0.6978\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.5041 - accuracy: 0.7972 - val_loss: 0.6536 - val_accuracy: 0.6978\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4965 - accuracy: 0.7932 - val_loss: 0.6485 - val_accuracy: 0.7015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4879 - accuracy: 0.8072 - val_loss: 0.6432 - val_accuracy: 0.7015\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4734 - accuracy: 0.8092 - val_loss: 0.6378 - val_accuracy: 0.7052\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.4778 - accuracy: 0.7871 - val_loss: 0.6325 - val_accuracy: 0.7090\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4586 - accuracy: 0.7992 - val_loss: 0.6274 - val_accuracy: 0.7015\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.4614 - accuracy: 0.8052 - val_loss: 0.6222 - val_accuracy: 0.7015\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.4415 - accuracy: 0.8072 - val_loss: 0.6173 - val_accuracy: 0.7015\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4397 - accuracy: 0.8092 - val_loss: 0.6126 - val_accuracy: 0.7090\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4322 - accuracy: 0.8092 - val_loss: 0.6076 - val_accuracy: 0.7127\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4238 - accuracy: 0.8092 - val_loss: 0.6028 - val_accuracy: 0.7127\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4304 - accuracy: 0.7992 - val_loss: 0.5982 - val_accuracy: 0.7201\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.4134 - accuracy: 0.8173 - val_loss: 0.5936 - val_accuracy: 0.7201\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4095 - accuracy: 0.8233 - val_loss: 0.5895 - val_accuracy: 0.7201\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4001 - accuracy: 0.8233 - val_loss: 0.5855 - val_accuracy: 0.7239\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4009 - accuracy: 0.8112 - val_loss: 0.5818 - val_accuracy: 0.7239\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3931 - accuracy: 0.8213 - val_loss: 0.5783 - val_accuracy: 0.7276\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3933 - accuracy: 0.8233 - val_loss: 0.5750 - val_accuracy: 0.7351\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3958 - accuracy: 0.8293 - val_loss: 0.5720 - val_accuracy: 0.7351\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3844 - accuracy: 0.8434 - val_loss: 0.5683 - val_accuracy: 0.7388\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3795 - accuracy: 0.8373 - val_loss: 0.5650 - val_accuracy: 0.7351\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3911 - accuracy: 0.8333 - val_loss: 0.5618 - val_accuracy: 0.7351\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.3747 - accuracy: 0.8414 - val_loss: 0.5583 - val_accuracy: 0.7351\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3761 - accuracy: 0.8514 - val_loss: 0.5550 - val_accuracy: 0.7388\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.3752 - accuracy: 0.8494 - val_loss: 0.5522 - val_accuracy: 0.7388\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3704 - accuracy: 0.8494 - val_loss: 0.5496 - val_accuracy: 0.7463\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3740 - accuracy: 0.8494 - val_loss: 0.5468 - val_accuracy: 0.7463\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3678 - accuracy: 0.8574 - val_loss: 0.5443 - val_accuracy: 0.7463\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.3705 - accuracy: 0.8574 - val_loss: 0.5421 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3612 - accuracy: 0.8614 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3659 - accuracy: 0.8534 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3632 - accuracy: 0.8534 - val_loss: 0.5357 - val_accuracy: 0.7537\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3647 - accuracy: 0.8474 - val_loss: 0.5342 - val_accuracy: 0.7537\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.3569 - accuracy: 0.8434 - val_loss: 0.5319 - val_accuracy: 0.7649\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3609 - accuracy: 0.8514 - val_loss: 0.5292 - val_accuracy: 0.7799\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3574 - accuracy: 0.8554 - val_loss: 0.5275 - val_accuracy: 0.7799\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3557 - accuracy: 0.8534 - val_loss: 0.5259 - val_accuracy: 0.7761\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3535 - accuracy: 0.8635 - val_loss: 0.5241 - val_accuracy: 0.7761\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3521 - accuracy: 0.8514 - val_loss: 0.5230 - val_accuracy: 0.7910\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3536 - accuracy: 0.8594 - val_loss: 0.5208 - val_accuracy: 0.7910\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3561 - accuracy: 0.8534 - val_loss: 0.5196 - val_accuracy: 0.7948\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3451 - accuracy: 0.8594 - val_loss: 0.5179 - val_accuracy: 0.7948\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3547 - accuracy: 0.8675 - val_loss: 0.5162 - val_accuracy: 0.7910\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3445 - accuracy: 0.8655 - val_loss: 0.5145 - val_accuracy: 0.8134\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3572 - accuracy: 0.8534 - val_loss: 0.5131 - val_accuracy: 0.8060\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3478 - accuracy: 0.8574 - val_loss: 0.5113 - val_accuracy: 0.8134\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3449 - accuracy: 0.8655 - val_loss: 0.5104 - val_accuracy: 0.8172\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3431 - accuracy: 0.8594 - val_loss: 0.5090 - val_accuracy: 0.8172\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 84us/step - loss: 0.3462 - accuracy: 0.8594 - val_loss: 0.5072 - val_accuracy: 0.8172\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3397 - accuracy: 0.8594 - val_loss: 0.5054 - val_accuracy: 0.8172\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 84us/step - loss: 0.3456 - accuracy: 0.8675 - val_loss: 0.5036 - val_accuracy: 0.8172\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 81us/step - loss: 0.3412 - accuracy: 0.8655 - val_loss: 0.5027 - val_accuracy: 0.8209\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3452 - accuracy: 0.8554 - val_loss: 0.5014 - val_accuracy: 0.8209\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 83us/step - loss: 0.3441 - accuracy: 0.8554 - val_loss: 0.5012 - val_accuracy: 0.8209\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3351 - accuracy: 0.8695 - val_loss: 0.5002 - val_accuracy: 0.8209\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 83us/step - loss: 0.3388 - accuracy: 0.8635 - val_loss: 0.4987 - val_accuracy: 0.8246\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3413 - accuracy: 0.8635 - val_loss: 0.4984 - val_accuracy: 0.8246\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3425 - accuracy: 0.8614 - val_loss: 0.4974 - val_accuracy: 0.8209\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3381 - accuracy: 0.8554 - val_loss: 0.4963 - val_accuracy: 0.8209\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3370 - accuracy: 0.8675 - val_loss: 0.4969 - val_accuracy: 0.8209\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 81us/step - loss: 0.3312 - accuracy: 0.8775 - val_loss: 0.4962 - val_accuracy: 0.8209\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.3332 - accuracy: 0.8614 - val_loss: 0.4954 - val_accuracy: 0.8209\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3319 - accuracy: 0.8635 - val_loss: 0.4945 - val_accuracy: 0.8209\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3279 - accuracy: 0.8775 - val_loss: 0.4933 - val_accuracy: 0.8209\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3323 - accuracy: 0.8655 - val_loss: 0.4927 - val_accuracy: 0.8209\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3349 - accuracy: 0.8675 - val_loss: 0.4926 - val_accuracy: 0.8246\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3353 - accuracy: 0.8635 - val_loss: 0.4918 - val_accuracy: 0.8246\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3294 - accuracy: 0.8675 - val_loss: 0.4917 - val_accuracy: 0.8246\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3339 - accuracy: 0.8655 - val_loss: 0.4917 - val_accuracy: 0.8246\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3328 - accuracy: 0.8675 - val_loss: 0.4919 - val_accuracy: 0.8246\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3305 - accuracy: 0.8675 - val_loss: 0.4908 - val_accuracy: 0.8246\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3259 - accuracy: 0.8695 - val_loss: 0.4904 - val_accuracy: 0.8246\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3338 - accuracy: 0.8675 - val_loss: 0.4897 - val_accuracy: 0.8209\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3316 - accuracy: 0.8715 - val_loss: 0.4901 - val_accuracy: 0.8246\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3213 - accuracy: 0.8675 - val_loss: 0.4894 - val_accuracy: 0.8246\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3310 - accuracy: 0.8655 - val_loss: 0.4886 - val_accuracy: 0.8284\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3305 - accuracy: 0.8675 - val_loss: 0.4882 - val_accuracy: 0.8284\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3248 - accuracy: 0.8695 - val_loss: 0.4868 - val_accuracy: 0.8246\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3290 - accuracy: 0.8695 - val_loss: 0.4869 - val_accuracy: 0.8246\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3287 - accuracy: 0.8675 - val_loss: 0.4863 - val_accuracy: 0.8209\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3214 - accuracy: 0.8735 - val_loss: 0.4871 - val_accuracy: 0.8246\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3271 - accuracy: 0.8695 - val_loss: 0.4869 - val_accuracy: 0.8246\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.3303 - accuracy: 0.8635 - val_loss: 0.4854 - val_accuracy: 0.8209\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 73us/step - loss: 0.3263 - accuracy: 0.8715 - val_loss: 0.4856 - val_accuracy: 0.8209\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.3246 - accuracy: 0.8755 - val_loss: 0.4868 - val_accuracy: 0.8209\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3242 - accuracy: 0.8735 - val_loss: 0.4869 - val_accuracy: 0.8209\n",
      "125/125 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 864us/step - loss: 0.9343 - accuracy: 0.3715 - val_loss: 0.7102 - val_accuracy: 0.5746\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.8843 - accuracy: 0.3996 - val_loss: 0.7078 - val_accuracy: 0.5672\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.8617 - accuracy: 0.4116 - val_loss: 0.7053 - val_accuracy: 0.5821\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.8172 - accuracy: 0.4920 - val_loss: 0.7029 - val_accuracy: 0.6119\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.7700 - accuracy: 0.5763 - val_loss: 0.7004 - val_accuracy: 0.6119\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.7470 - accuracy: 0.6305 - val_loss: 0.6981 - val_accuracy: 0.6157\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.7199 - accuracy: 0.6747 - val_loss: 0.6960 - val_accuracy: 0.6306\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6966 - accuracy: 0.6908 - val_loss: 0.6938 - val_accuracy: 0.6343\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.6768 - accuracy: 0.7249 - val_loss: 0.6915 - val_accuracy: 0.6381\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.6605 - accuracy: 0.7329 - val_loss: 0.6890 - val_accuracy: 0.6381\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 83us/step - loss: 0.6329 - accuracy: 0.7550 - val_loss: 0.6859 - val_accuracy: 0.6455\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.6211 - accuracy: 0.7490 - val_loss: 0.6821 - val_accuracy: 0.6493\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.6043 - accuracy: 0.7711 - val_loss: 0.6780 - val_accuracy: 0.6455\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.5915 - accuracy: 0.7711 - val_loss: 0.6738 - val_accuracy: 0.6381\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5765 - accuracy: 0.7871 - val_loss: 0.6695 - val_accuracy: 0.6493\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.5627 - accuracy: 0.7851 - val_loss: 0.6650 - val_accuracy: 0.6567\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.5558 - accuracy: 0.7972 - val_loss: 0.6602 - val_accuracy: 0.6604\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 81us/step - loss: 0.5439 - accuracy: 0.7932 - val_loss: 0.6551 - val_accuracy: 0.6642\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.5326 - accuracy: 0.8012 - val_loss: 0.6500 - val_accuracy: 0.6679\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.5196 - accuracy: 0.8153 - val_loss: 0.6445 - val_accuracy: 0.6791\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.5114 - accuracy: 0.8193 - val_loss: 0.6391 - val_accuracy: 0.6791\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.5055 - accuracy: 0.8092 - val_loss: 0.6331 - val_accuracy: 0.6940\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4929 - accuracy: 0.8173 - val_loss: 0.6271 - val_accuracy: 0.7015\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4864 - accuracy: 0.8133 - val_loss: 0.6210 - val_accuracy: 0.7090\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.4763 - accuracy: 0.8414 - val_loss: 0.6154 - val_accuracy: 0.7313\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4763 - accuracy: 0.8293 - val_loss: 0.6097 - val_accuracy: 0.7351\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4686 - accuracy: 0.8394 - val_loss: 0.6039 - val_accuracy: 0.7463\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4638 - accuracy: 0.8353 - val_loss: 0.5983 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.4520 - accuracy: 0.8373 - val_loss: 0.5924 - val_accuracy: 0.7687\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4557 - accuracy: 0.8293 - val_loss: 0.5870 - val_accuracy: 0.7761\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 79us/step - loss: 0.4482 - accuracy: 0.8253 - val_loss: 0.5813 - val_accuracy: 0.7836\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4418 - accuracy: 0.8293 - val_loss: 0.5765 - val_accuracy: 0.7910\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4397 - accuracy: 0.8273 - val_loss: 0.5717 - val_accuracy: 0.7948\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4312 - accuracy: 0.8333 - val_loss: 0.5671 - val_accuracy: 0.8060\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4238 - accuracy: 0.8373 - val_loss: 0.5629 - val_accuracy: 0.8172\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4278 - accuracy: 0.8333 - val_loss: 0.5583 - val_accuracy: 0.8172\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.4202 - accuracy: 0.8454 - val_loss: 0.5536 - val_accuracy: 0.8246\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.4171 - accuracy: 0.8434 - val_loss: 0.5488 - val_accuracy: 0.8284\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4146 - accuracy: 0.8333 - val_loss: 0.5442 - val_accuracy: 0.8284\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4117 - accuracy: 0.8373 - val_loss: 0.5397 - val_accuracy: 0.8284\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4095 - accuracy: 0.8514 - val_loss: 0.5357 - val_accuracy: 0.8321\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 75us/step - loss: 0.4087 - accuracy: 0.8373 - val_loss: 0.5316 - val_accuracy: 0.8321\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.4047 - accuracy: 0.8353 - val_loss: 0.5281 - val_accuracy: 0.8321\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 77us/step - loss: 0.4018 - accuracy: 0.8474 - val_loss: 0.5246 - val_accuracy: 0.8321\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3959 - accuracy: 0.8454 - val_loss: 0.5211 - val_accuracy: 0.8321\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3936 - accuracy: 0.8514 - val_loss: 0.5176 - val_accuracy: 0.8358\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3910 - accuracy: 0.8434 - val_loss: 0.5144 - val_accuracy: 0.8358\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3924 - accuracy: 0.8434 - val_loss: 0.5115 - val_accuracy: 0.8358\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3837 - accuracy: 0.8594 - val_loss: 0.5088 - val_accuracy: 0.8358\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3908 - accuracy: 0.8474 - val_loss: 0.5060 - val_accuracy: 0.8358\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3870 - accuracy: 0.8594 - val_loss: 0.5032 - val_accuracy: 0.8358\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3869 - accuracy: 0.8434 - val_loss: 0.5004 - val_accuracy: 0.8321\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3827 - accuracy: 0.8474 - val_loss: 0.4978 - val_accuracy: 0.8321\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3860 - accuracy: 0.8414 - val_loss: 0.4959 - val_accuracy: 0.8358\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3822 - accuracy: 0.8514 - val_loss: 0.4944 - val_accuracy: 0.8396\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3800 - accuracy: 0.8454 - val_loss: 0.4932 - val_accuracy: 0.8358\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3765 - accuracy: 0.8534 - val_loss: 0.4914 - val_accuracy: 0.8284\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3782 - accuracy: 0.8474 - val_loss: 0.4900 - val_accuracy: 0.8284\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3705 - accuracy: 0.8635 - val_loss: 0.4883 - val_accuracy: 0.8284\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3770 - accuracy: 0.8574 - val_loss: 0.4870 - val_accuracy: 0.8246\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3745 - accuracy: 0.8514 - val_loss: 0.4860 - val_accuracy: 0.8246\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3716 - accuracy: 0.8454 - val_loss: 0.4847 - val_accuracy: 0.8321\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3777 - accuracy: 0.8534 - val_loss: 0.4836 - val_accuracy: 0.8284\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3735 - accuracy: 0.8494 - val_loss: 0.4826 - val_accuracy: 0.8321\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3731 - accuracy: 0.8494 - val_loss: 0.4818 - val_accuracy: 0.8321\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3662 - accuracy: 0.8514 - val_loss: 0.4810 - val_accuracy: 0.8321\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3674 - accuracy: 0.8554 - val_loss: 0.4803 - val_accuracy: 0.8321\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3702 - accuracy: 0.8514 - val_loss: 0.4798 - val_accuracy: 0.8321\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3680 - accuracy: 0.8434 - val_loss: 0.4790 - val_accuracy: 0.8321\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3658 - accuracy: 0.8474 - val_loss: 0.4787 - val_accuracy: 0.8321\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3627 - accuracy: 0.8635 - val_loss: 0.4783 - val_accuracy: 0.8321\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3644 - accuracy: 0.8494 - val_loss: 0.4776 - val_accuracy: 0.8321\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3638 - accuracy: 0.8514 - val_loss: 0.4772 - val_accuracy: 0.8358\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3631 - accuracy: 0.8614 - val_loss: 0.4769 - val_accuracy: 0.8358\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3606 - accuracy: 0.8594 - val_loss: 0.4767 - val_accuracy: 0.8321\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3641 - accuracy: 0.8574 - val_loss: 0.4764 - val_accuracy: 0.8284\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3588 - accuracy: 0.8594 - val_loss: 0.4759 - val_accuracy: 0.8284\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3658 - accuracy: 0.8494 - val_loss: 0.4759 - val_accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3556 - accuracy: 0.8514 - val_loss: 0.4756 - val_accuracy: 0.8284\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3645 - accuracy: 0.8514 - val_loss: 0.4751 - val_accuracy: 0.8246\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 82us/step - loss: 0.3624 - accuracy: 0.8574 - val_loss: 0.4749 - val_accuracy: 0.8284\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3579 - accuracy: 0.8574 - val_loss: 0.4742 - val_accuracy: 0.8284\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3607 - accuracy: 0.8554 - val_loss: 0.4739 - val_accuracy: 0.8246\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3636 - accuracy: 0.8514 - val_loss: 0.4741 - val_accuracy: 0.8246\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3639 - accuracy: 0.8514 - val_loss: 0.4740 - val_accuracy: 0.8284\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3565 - accuracy: 0.8594 - val_loss: 0.4742 - val_accuracy: 0.8246\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3573 - accuracy: 0.8574 - val_loss: 0.4744 - val_accuracy: 0.8284\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3555 - accuracy: 0.8675 - val_loss: 0.4744 - val_accuracy: 0.8358\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3579 - accuracy: 0.8554 - val_loss: 0.4741 - val_accuracy: 0.8321\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3603 - accuracy: 0.8635 - val_loss: 0.4741 - val_accuracy: 0.8246\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3463 - accuracy: 0.8655 - val_loss: 0.4741 - val_accuracy: 0.8246\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3554 - accuracy: 0.8574 - val_loss: 0.4743 - val_accuracy: 0.8209\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3594 - accuracy: 0.8434 - val_loss: 0.4746 - val_accuracy: 0.8172\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3487 - accuracy: 0.8614 - val_loss: 0.4739 - val_accuracy: 0.8172\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3581 - accuracy: 0.8514 - val_loss: 0.4740 - val_accuracy: 0.8172\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 80us/step - loss: 0.3548 - accuracy: 0.8655 - val_loss: 0.4738 - val_accuracy: 0.8172\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3511 - accuracy: 0.8594 - val_loss: 0.4739 - val_accuracy: 0.8097\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3579 - accuracy: 0.8494 - val_loss: 0.4739 - val_accuracy: 0.8134\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3481 - accuracy: 0.8655 - val_loss: 0.4739 - val_accuracy: 0.8097\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3540 - accuracy: 0.8534 - val_loss: 0.4735 - val_accuracy: 0.8097\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 0s 852us/step - loss: 1.0983 - accuracy: 0.3166 - val_loss: 0.7310 - val_accuracy: 0.5709\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 1.0296 - accuracy: 0.3287 - val_loss: 0.7246 - val_accuracy: 0.5522\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.9824 - accuracy: 0.3407 - val_loss: 0.7187 - val_accuracy: 0.5522\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.9230 - accuracy: 0.3447 - val_loss: 0.7129 - val_accuracy: 0.5560\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.8732 - accuracy: 0.4409 - val_loss: 0.7059 - val_accuracy: 0.5709\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.8300 - accuracy: 0.5631 - val_loss: 0.6980 - val_accuracy: 0.5746\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.8000 - accuracy: 0.6052 - val_loss: 0.6901 - val_accuracy: 0.5709\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.7663 - accuracy: 0.6373 - val_loss: 0.6826 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.7377 - accuracy: 0.6693 - val_loss: 0.6753 - val_accuracy: 0.6269\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.7162 - accuracy: 0.6994 - val_loss: 0.6686 - val_accuracy: 0.6455\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6949 - accuracy: 0.6994 - val_loss: 0.6622 - val_accuracy: 0.6716\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.6699 - accuracy: 0.7074 - val_loss: 0.6561 - val_accuracy: 0.7015\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6527 - accuracy: 0.7214 - val_loss: 0.6502 - val_accuracy: 0.7201\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.6338 - accuracy: 0.7435 - val_loss: 0.6445 - val_accuracy: 0.7313\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.6194 - accuracy: 0.7435 - val_loss: 0.6391 - val_accuracy: 0.7351\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5935 - accuracy: 0.7796 - val_loss: 0.6340 - val_accuracy: 0.7276\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.5858 - accuracy: 0.7796 - val_loss: 0.6288 - val_accuracy: 0.7351\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.5781 - accuracy: 0.7796 - val_loss: 0.6240 - val_accuracy: 0.7575\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5659 - accuracy: 0.7735 - val_loss: 0.6192 - val_accuracy: 0.7575\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5523 - accuracy: 0.7896 - val_loss: 0.6144 - val_accuracy: 0.7575\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.5434 - accuracy: 0.7856 - val_loss: 0.6091 - val_accuracy: 0.7575\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.5378 - accuracy: 0.7856 - val_loss: 0.6041 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.5190 - accuracy: 0.8056 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5230 - accuracy: 0.7936 - val_loss: 0.5944 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.5064 - accuracy: 0.7916 - val_loss: 0.5898 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4950 - accuracy: 0.8016 - val_loss: 0.5851 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4953 - accuracy: 0.7976 - val_loss: 0.5803 - val_accuracy: 0.7537\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4754 - accuracy: 0.8116 - val_loss: 0.5750 - val_accuracy: 0.7537\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4837 - accuracy: 0.8196 - val_loss: 0.5699 - val_accuracy: 0.7575\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4695 - accuracy: 0.8136 - val_loss: 0.5649 - val_accuracy: 0.7649\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4687 - accuracy: 0.8096 - val_loss: 0.5599 - val_accuracy: 0.7724\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4518 - accuracy: 0.8156 - val_loss: 0.5550 - val_accuracy: 0.7761\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4606 - accuracy: 0.8196 - val_loss: 0.5503 - val_accuracy: 0.7761\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.4498 - accuracy: 0.8257 - val_loss: 0.5459 - val_accuracy: 0.7761\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.4494 - accuracy: 0.8196 - val_loss: 0.5417 - val_accuracy: 0.7761\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4436 - accuracy: 0.8236 - val_loss: 0.5377 - val_accuracy: 0.7799\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 86us/step - loss: 0.4428 - accuracy: 0.8176 - val_loss: 0.5340 - val_accuracy: 0.7799\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4397 - accuracy: 0.8196 - val_loss: 0.5306 - val_accuracy: 0.7761\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 84us/step - loss: 0.4296 - accuracy: 0.8337 - val_loss: 0.5271 - val_accuracy: 0.7761\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4248 - accuracy: 0.8337 - val_loss: 0.5236 - val_accuracy: 0.7761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.4331 - accuracy: 0.8176 - val_loss: 0.5208 - val_accuracy: 0.7761\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.4209 - accuracy: 0.8257 - val_loss: 0.5179 - val_accuracy: 0.7761\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 86us/step - loss: 0.4206 - accuracy: 0.8236 - val_loss: 0.5149 - val_accuracy: 0.7836\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 86us/step - loss: 0.4155 - accuracy: 0.8196 - val_loss: 0.5123 - val_accuracy: 0.7836\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 84us/step - loss: 0.4090 - accuracy: 0.8457 - val_loss: 0.5092 - val_accuracy: 0.7873\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 86us/step - loss: 0.4094 - accuracy: 0.8337 - val_loss: 0.5060 - val_accuracy: 0.7873\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 84us/step - loss: 0.4129 - accuracy: 0.8317 - val_loss: 0.5031 - val_accuracy: 0.7985\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4058 - accuracy: 0.8457 - val_loss: 0.5005 - val_accuracy: 0.7985\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 84us/step - loss: 0.4040 - accuracy: 0.8337 - val_loss: 0.4978 - val_accuracy: 0.7985\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.4019 - accuracy: 0.8457 - val_loss: 0.4952 - val_accuracy: 0.8022\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3984 - accuracy: 0.8377 - val_loss: 0.4927 - val_accuracy: 0.8022\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.4028 - accuracy: 0.8417 - val_loss: 0.4904 - val_accuracy: 0.8022\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3914 - accuracy: 0.8317 - val_loss: 0.4881 - val_accuracy: 0.8022\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 86us/step - loss: 0.3972 - accuracy: 0.8397 - val_loss: 0.4857 - val_accuracy: 0.8097\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3881 - accuracy: 0.8477 - val_loss: 0.4838 - val_accuracy: 0.8134\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3815 - accuracy: 0.8457 - val_loss: 0.4820 - val_accuracy: 0.8172\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 84us/step - loss: 0.3854 - accuracy: 0.8457 - val_loss: 0.4802 - val_accuracy: 0.8246\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3854 - accuracy: 0.8377 - val_loss: 0.4787 - val_accuracy: 0.8246\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3836 - accuracy: 0.8477 - val_loss: 0.4773 - val_accuracy: 0.8246\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3800 - accuracy: 0.8557 - val_loss: 0.4760 - val_accuracy: 0.8246\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.3775 - accuracy: 0.8537 - val_loss: 0.4745 - val_accuracy: 0.8246\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3768 - accuracy: 0.8477 - val_loss: 0.4730 - val_accuracy: 0.8284\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3769 - accuracy: 0.8497 - val_loss: 0.4722 - val_accuracy: 0.8321\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3681 - accuracy: 0.8697 - val_loss: 0.4714 - val_accuracy: 0.8321\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3669 - accuracy: 0.8537 - val_loss: 0.4709 - val_accuracy: 0.8321\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3705 - accuracy: 0.8497 - val_loss: 0.4702 - val_accuracy: 0.8321\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 80us/step - loss: 0.3681 - accuracy: 0.8577 - val_loss: 0.4696 - val_accuracy: 0.8321\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3613 - accuracy: 0.8657 - val_loss: 0.4694 - val_accuracy: 0.8321\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.3625 - accuracy: 0.8617 - val_loss: 0.4692 - val_accuracy: 0.8321\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3633 - accuracy: 0.8597 - val_loss: 0.4692 - val_accuracy: 0.8246\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3594 - accuracy: 0.8637 - val_loss: 0.4693 - val_accuracy: 0.8246\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 86us/step - loss: 0.3614 - accuracy: 0.8617 - val_loss: 0.4695 - val_accuracy: 0.8246\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.3595 - accuracy: 0.8517 - val_loss: 0.4692 - val_accuracy: 0.8246\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3575 - accuracy: 0.8537 - val_loss: 0.4691 - val_accuracy: 0.8284\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3568 - accuracy: 0.8537 - val_loss: 0.4689 - val_accuracy: 0.8246\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3568 - accuracy: 0.8617 - val_loss: 0.4685 - val_accuracy: 0.8246\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3520 - accuracy: 0.8697 - val_loss: 0.4682 - val_accuracy: 0.8246\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3509 - accuracy: 0.8778 - val_loss: 0.4680 - val_accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3490 - accuracy: 0.8737 - val_loss: 0.4676 - val_accuracy: 0.8284\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3477 - accuracy: 0.8657 - val_loss: 0.4674 - val_accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3525 - accuracy: 0.8597 - val_loss: 0.4668 - val_accuracy: 0.8284\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3486 - accuracy: 0.8737 - val_loss: 0.4665 - val_accuracy: 0.8284\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3447 - accuracy: 0.8758 - val_loss: 0.4660 - val_accuracy: 0.8284\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3495 - accuracy: 0.8737 - val_loss: 0.4655 - val_accuracy: 0.8284\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3460 - accuracy: 0.8677 - val_loss: 0.4652 - val_accuracy: 0.8246\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3477 - accuracy: 0.8717 - val_loss: 0.4653 - val_accuracy: 0.8284\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3472 - accuracy: 0.8637 - val_loss: 0.4653 - val_accuracy: 0.8284\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3489 - accuracy: 0.8677 - val_loss: 0.4654 - val_accuracy: 0.8284\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3498 - accuracy: 0.8557 - val_loss: 0.4644 - val_accuracy: 0.8284\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3450 - accuracy: 0.8657 - val_loss: 0.4641 - val_accuracy: 0.8284\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3384 - accuracy: 0.8677 - val_loss: 0.4637 - val_accuracy: 0.8284\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3420 - accuracy: 0.8697 - val_loss: 0.4640 - val_accuracy: 0.8246\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3492 - accuracy: 0.8717 - val_loss: 0.4641 - val_accuracy: 0.8284\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3412 - accuracy: 0.8778 - val_loss: 0.4640 - val_accuracy: 0.8246\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3418 - accuracy: 0.8717 - val_loss: 0.4642 - val_accuracy: 0.8284\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.3403 - accuracy: 0.8717 - val_loss: 0.4640 - val_accuracy: 0.8246\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3363 - accuracy: 0.8657 - val_loss: 0.4644 - val_accuracy: 0.8246\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3374 - accuracy: 0.8697 - val_loss: 0.4643 - val_accuracy: 0.8246\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3436 - accuracy: 0.8657 - val_loss: 0.4641 - val_accuracy: 0.8246\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3390 - accuracy: 0.8717 - val_loss: 0.4641 - val_accuracy: 0.8246\n",
      "124/124 [==============================] - 0s 24us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 0s 898us/step - loss: 0.6862 - accuracy: 0.6413 - val_loss: 0.6789 - val_accuracy: 0.6119\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.6475 - accuracy: 0.6613 - val_loss: 0.6714 - val_accuracy: 0.6642\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.6100 - accuracy: 0.6894 - val_loss: 0.6641 - val_accuracy: 0.6754\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5781 - accuracy: 0.7315 - val_loss: 0.6567 - val_accuracy: 0.6903\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5566 - accuracy: 0.7575 - val_loss: 0.6495 - val_accuracy: 0.7015\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5358 - accuracy: 0.7836 - val_loss: 0.6421 - val_accuracy: 0.7052\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5202 - accuracy: 0.7856 - val_loss: 0.6351 - val_accuracy: 0.7090\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5024 - accuracy: 0.7976 - val_loss: 0.6282 - val_accuracy: 0.7239\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4900 - accuracy: 0.8036 - val_loss: 0.6218 - val_accuracy: 0.7463\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4813 - accuracy: 0.8056 - val_loss: 0.6159 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4617 - accuracy: 0.8176 - val_loss: 0.6104 - val_accuracy: 0.7612\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4625 - accuracy: 0.8056 - val_loss: 0.6053 - val_accuracy: 0.7687\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4569 - accuracy: 0.8156 - val_loss: 0.6008 - val_accuracy: 0.7724\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.4538 - accuracy: 0.8257 - val_loss: 0.5967 - val_accuracy: 0.7761\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.4392 - accuracy: 0.8156 - val_loss: 0.5928 - val_accuracy: 0.7761\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4382 - accuracy: 0.8317 - val_loss: 0.5894 - val_accuracy: 0.7761\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4256 - accuracy: 0.8236 - val_loss: 0.5860 - val_accuracy: 0.7799\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4294 - accuracy: 0.8297 - val_loss: 0.5824 - val_accuracy: 0.7836\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4148 - accuracy: 0.8337 - val_loss: 0.5789 - val_accuracy: 0.7836\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4172 - accuracy: 0.8317 - val_loss: 0.5753 - val_accuracy: 0.7873\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4115 - accuracy: 0.8417 - val_loss: 0.5721 - val_accuracy: 0.7910\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4075 - accuracy: 0.8437 - val_loss: 0.5690 - val_accuracy: 0.7910\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.4045 - accuracy: 0.8417 - val_loss: 0.5654 - val_accuracy: 0.7985\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4028 - accuracy: 0.8517 - val_loss: 0.5621 - val_accuracy: 0.7985\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4041 - accuracy: 0.8417 - val_loss: 0.5589 - val_accuracy: 0.7910\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3981 - accuracy: 0.8437 - val_loss: 0.5560 - val_accuracy: 0.7910\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4001 - accuracy: 0.8457 - val_loss: 0.5525 - val_accuracy: 0.7910\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3933 - accuracy: 0.8537 - val_loss: 0.5496 - val_accuracy: 0.7948\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3963 - accuracy: 0.8517 - val_loss: 0.5469 - val_accuracy: 0.7948\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3847 - accuracy: 0.8537 - val_loss: 0.5439 - val_accuracy: 0.7948\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3810 - accuracy: 0.8577 - val_loss: 0.5410 - val_accuracy: 0.7948\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3854 - accuracy: 0.8557 - val_loss: 0.5378 - val_accuracy: 0.7910\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3831 - accuracy: 0.8497 - val_loss: 0.5351 - val_accuracy: 0.7873\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3847 - accuracy: 0.8617 - val_loss: 0.5323 - val_accuracy: 0.7836\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3714 - accuracy: 0.8597 - val_loss: 0.5298 - val_accuracy: 0.7836\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3887 - accuracy: 0.8517 - val_loss: 0.5262 - val_accuracy: 0.7836\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3762 - accuracy: 0.8597 - val_loss: 0.5225 - val_accuracy: 0.7836\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3728 - accuracy: 0.8637 - val_loss: 0.5188 - val_accuracy: 0.7836\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3764 - accuracy: 0.8617 - val_loss: 0.5154 - val_accuracy: 0.7873\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3757 - accuracy: 0.8637 - val_loss: 0.5117 - val_accuracy: 0.7910\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3678 - accuracy: 0.8637 - val_loss: 0.5083 - val_accuracy: 0.7985\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3716 - accuracy: 0.8597 - val_loss: 0.5053 - val_accuracy: 0.7985\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3651 - accuracy: 0.8737 - val_loss: 0.5032 - val_accuracy: 0.8060\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3698 - accuracy: 0.8597 - val_loss: 0.5009 - val_accuracy: 0.8060\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3658 - accuracy: 0.8637 - val_loss: 0.4990 - val_accuracy: 0.8060\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3641 - accuracy: 0.8657 - val_loss: 0.4979 - val_accuracy: 0.8022\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3612 - accuracy: 0.8677 - val_loss: 0.4960 - val_accuracy: 0.8060\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3642 - accuracy: 0.8637 - val_loss: 0.4949 - val_accuracy: 0.8060\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3531 - accuracy: 0.8697 - val_loss: 0.4935 - val_accuracy: 0.8060\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3619 - accuracy: 0.8637 - val_loss: 0.4917 - val_accuracy: 0.8097\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3589 - accuracy: 0.8697 - val_loss: 0.4908 - val_accuracy: 0.8060\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3581 - accuracy: 0.8657 - val_loss: 0.4896 - val_accuracy: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3594 - accuracy: 0.8617 - val_loss: 0.4888 - val_accuracy: 0.8060\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3627 - accuracy: 0.8557 - val_loss: 0.4883 - val_accuracy: 0.8097\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3577 - accuracy: 0.8597 - val_loss: 0.4864 - val_accuracy: 0.8097\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3535 - accuracy: 0.8677 - val_loss: 0.4854 - val_accuracy: 0.8060\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3482 - accuracy: 0.8737 - val_loss: 0.4841 - val_accuracy: 0.8060\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3468 - accuracy: 0.8758 - val_loss: 0.4833 - val_accuracy: 0.8022\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3470 - accuracy: 0.8737 - val_loss: 0.4822 - val_accuracy: 0.8022\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3495 - accuracy: 0.8717 - val_loss: 0.4806 - val_accuracy: 0.8022\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3528 - accuracy: 0.8697 - val_loss: 0.4792 - val_accuracy: 0.8022\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3418 - accuracy: 0.8717 - val_loss: 0.4783 - val_accuracy: 0.7985\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3453 - accuracy: 0.8677 - val_loss: 0.4774 - val_accuracy: 0.7985\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3444 - accuracy: 0.8758 - val_loss: 0.4774 - val_accuracy: 0.7985\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3559 - accuracy: 0.8617 - val_loss: 0.4764 - val_accuracy: 0.7985\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3475 - accuracy: 0.8717 - val_loss: 0.4768 - val_accuracy: 0.7985\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3435 - accuracy: 0.8758 - val_loss: 0.4766 - val_accuracy: 0.7985\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3415 - accuracy: 0.8778 - val_loss: 0.4756 - val_accuracy: 0.7985\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3400 - accuracy: 0.8778 - val_loss: 0.4748 - val_accuracy: 0.7985\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3384 - accuracy: 0.8758 - val_loss: 0.4738 - val_accuracy: 0.7985\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3483 - accuracy: 0.8758 - val_loss: 0.4737 - val_accuracy: 0.7910\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3441 - accuracy: 0.8838 - val_loss: 0.4733 - val_accuracy: 0.7910\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3416 - accuracy: 0.8798 - val_loss: 0.4734 - val_accuracy: 0.7873\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3340 - accuracy: 0.8838 - val_loss: 0.4736 - val_accuracy: 0.7910\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3437 - accuracy: 0.8758 - val_loss: 0.4742 - val_accuracy: 0.7873\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3389 - accuracy: 0.8697 - val_loss: 0.4741 - val_accuracy: 0.7873\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3434 - accuracy: 0.8737 - val_loss: 0.4746 - val_accuracy: 0.7873\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3382 - accuracy: 0.8858 - val_loss: 0.4752 - val_accuracy: 0.7873\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3336 - accuracy: 0.8758 - val_loss: 0.4753 - val_accuracy: 0.7873\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3300 - accuracy: 0.8838 - val_loss: 0.4755 - val_accuracy: 0.7873\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3257 - accuracy: 0.8818 - val_loss: 0.4754 - val_accuracy: 0.7873\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3346 - accuracy: 0.8818 - val_loss: 0.4760 - val_accuracy: 0.7910\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3327 - accuracy: 0.8798 - val_loss: 0.4765 - val_accuracy: 0.7910\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3328 - accuracy: 0.8737 - val_loss: 0.4769 - val_accuracy: 0.7948\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3299 - accuracy: 0.8778 - val_loss: 0.4766 - val_accuracy: 0.7948\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3317 - accuracy: 0.8737 - val_loss: 0.4767 - val_accuracy: 0.7910\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3305 - accuracy: 0.8858 - val_loss: 0.4771 - val_accuracy: 0.7910\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3300 - accuracy: 0.8878 - val_loss: 0.4772 - val_accuracy: 0.7873\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3435 - accuracy: 0.8818 - val_loss: 0.4777 - val_accuracy: 0.7873\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3339 - accuracy: 0.8737 - val_loss: 0.4774 - val_accuracy: 0.7873\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3262 - accuracy: 0.8798 - val_loss: 0.4767 - val_accuracy: 0.7873\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3276 - accuracy: 0.8838 - val_loss: 0.4766 - val_accuracy: 0.7910\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3229 - accuracy: 0.8838 - val_loss: 0.4771 - val_accuracy: 0.7910\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 73us/step - loss: 0.3407 - accuracy: 0.8818 - val_loss: 0.4767 - val_accuracy: 0.7948\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3267 - accuracy: 0.8898 - val_loss: 0.4762 - val_accuracy: 0.7948\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3261 - accuracy: 0.8858 - val_loss: 0.4764 - val_accuracy: 0.7910\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3285 - accuracy: 0.8798 - val_loss: 0.4763 - val_accuracy: 0.7948\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3184 - accuracy: 0.8978 - val_loss: 0.4766 - val_accuracy: 0.7948\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3217 - accuracy: 0.8878 - val_loss: 0.4766 - val_accuracy: 0.7985\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3233 - accuracy: 0.8858 - val_loss: 0.4760 - val_accuracy: 0.7985\n",
      "124/124 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 860us/step - loss: 0.9332 - accuracy: 0.3715 - val_loss: 0.7083 - val_accuracy: 0.6119\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.8713 - accuracy: 0.3996 - val_loss: 0.7038 - val_accuracy: 0.6119\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.8156 - accuracy: 0.4458 - val_loss: 0.6993 - val_accuracy: 0.6119\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.7812 - accuracy: 0.4960 - val_loss: 0.6947 - val_accuracy: 0.6119\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.7180 - accuracy: 0.5723 - val_loss: 0.6902 - val_accuracy: 0.6119\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.6844 - accuracy: 0.6064 - val_loss: 0.6857 - val_accuracy: 0.6119\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.6522 - accuracy: 0.6546 - val_loss: 0.6813 - val_accuracy: 0.6194\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.6206 - accuracy: 0.6888 - val_loss: 0.6768 - val_accuracy: 0.6231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5993 - accuracy: 0.7209 - val_loss: 0.6723 - val_accuracy: 0.6194\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.5731 - accuracy: 0.7610 - val_loss: 0.6677 - val_accuracy: 0.6231\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5490 - accuracy: 0.7871 - val_loss: 0.6626 - val_accuracy: 0.6231\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5363 - accuracy: 0.7831 - val_loss: 0.6574 - val_accuracy: 0.6343\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5139 - accuracy: 0.8133 - val_loss: 0.6523 - val_accuracy: 0.6604\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5112 - accuracy: 0.7992 - val_loss: 0.6473 - val_accuracy: 0.6791\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4877 - accuracy: 0.8233 - val_loss: 0.6422 - val_accuracy: 0.6866\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4851 - accuracy: 0.8273 - val_loss: 0.6375 - val_accuracy: 0.6940\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4713 - accuracy: 0.8353 - val_loss: 0.6332 - val_accuracy: 0.6978\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4721 - accuracy: 0.8012 - val_loss: 0.6291 - val_accuracy: 0.7164\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4520 - accuracy: 0.8414 - val_loss: 0.6250 - val_accuracy: 0.7201\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4594 - accuracy: 0.8193 - val_loss: 0.6208 - val_accuracy: 0.7239\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4351 - accuracy: 0.8594 - val_loss: 0.6171 - val_accuracy: 0.7276\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.4345 - accuracy: 0.8594 - val_loss: 0.6134 - val_accuracy: 0.7313\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4279 - accuracy: 0.8514 - val_loss: 0.6095 - val_accuracy: 0.7351\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4220 - accuracy: 0.8655 - val_loss: 0.6054 - val_accuracy: 0.7388\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.4183 - accuracy: 0.8675 - val_loss: 0.6015 - val_accuracy: 0.7388\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4149 - accuracy: 0.8695 - val_loss: 0.5979 - val_accuracy: 0.7351\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4051 - accuracy: 0.8735 - val_loss: 0.5939 - val_accuracy: 0.7313\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4101 - accuracy: 0.8514 - val_loss: 0.5903 - val_accuracy: 0.7351\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4060 - accuracy: 0.8554 - val_loss: 0.5867 - val_accuracy: 0.7388\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3896 - accuracy: 0.8735 - val_loss: 0.5834 - val_accuracy: 0.7425\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3896 - accuracy: 0.8715 - val_loss: 0.5797 - val_accuracy: 0.7425\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3971 - accuracy: 0.8554 - val_loss: 0.5759 - val_accuracy: 0.7388\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3857 - accuracy: 0.8675 - val_loss: 0.5722 - val_accuracy: 0.7388\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3774 - accuracy: 0.8695 - val_loss: 0.5682 - val_accuracy: 0.7388\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3704 - accuracy: 0.8835 - val_loss: 0.5648 - val_accuracy: 0.7388\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3723 - accuracy: 0.8735 - val_loss: 0.5616 - val_accuracy: 0.7463\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3713 - accuracy: 0.8795 - val_loss: 0.5585 - val_accuracy: 0.7463\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3720 - accuracy: 0.8614 - val_loss: 0.5553 - val_accuracy: 0.7463\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3629 - accuracy: 0.8775 - val_loss: 0.5521 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3680 - accuracy: 0.8655 - val_loss: 0.5492 - val_accuracy: 0.7537\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3718 - accuracy: 0.8755 - val_loss: 0.5458 - val_accuracy: 0.7537\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3624 - accuracy: 0.8675 - val_loss: 0.5433 - val_accuracy: 0.7575\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3604 - accuracy: 0.8775 - val_loss: 0.5406 - val_accuracy: 0.7612\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3671 - accuracy: 0.8675 - val_loss: 0.5379 - val_accuracy: 0.7612\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3623 - accuracy: 0.8755 - val_loss: 0.5349 - val_accuracy: 0.7649\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3528 - accuracy: 0.8835 - val_loss: 0.5325 - val_accuracy: 0.7761\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3578 - accuracy: 0.8795 - val_loss: 0.5296 - val_accuracy: 0.7836\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3494 - accuracy: 0.8755 - val_loss: 0.5264 - val_accuracy: 0.7910\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3560 - accuracy: 0.8735 - val_loss: 0.5233 - val_accuracy: 0.7948\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3457 - accuracy: 0.8815 - val_loss: 0.5201 - val_accuracy: 0.8097\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3485 - accuracy: 0.8735 - val_loss: 0.5169 - val_accuracy: 0.8060\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3546 - accuracy: 0.8775 - val_loss: 0.5146 - val_accuracy: 0.8097\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3474 - accuracy: 0.8695 - val_loss: 0.5123 - val_accuracy: 0.8060\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3438 - accuracy: 0.8775 - val_loss: 0.5106 - val_accuracy: 0.8097\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3435 - accuracy: 0.8795 - val_loss: 0.5086 - val_accuracy: 0.8097\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3516 - accuracy: 0.8775 - val_loss: 0.5067 - val_accuracy: 0.8209\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3478 - accuracy: 0.8775 - val_loss: 0.5053 - val_accuracy: 0.8209\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3426 - accuracy: 0.8735 - val_loss: 0.5038 - val_accuracy: 0.8209\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3394 - accuracy: 0.8795 - val_loss: 0.5022 - val_accuracy: 0.8209\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3446 - accuracy: 0.8755 - val_loss: 0.5007 - val_accuracy: 0.8209\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3473 - accuracy: 0.8735 - val_loss: 0.4992 - val_accuracy: 0.8209\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3383 - accuracy: 0.8755 - val_loss: 0.4975 - val_accuracy: 0.8246\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3408 - accuracy: 0.8675 - val_loss: 0.4962 - val_accuracy: 0.8358\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3457 - accuracy: 0.8715 - val_loss: 0.4942 - val_accuracy: 0.8358\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3381 - accuracy: 0.8815 - val_loss: 0.4927 - val_accuracy: 0.8321\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3359 - accuracy: 0.8655 - val_loss: 0.4920 - val_accuracy: 0.8321\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3326 - accuracy: 0.8896 - val_loss: 0.4916 - val_accuracy: 0.8246\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3354 - accuracy: 0.8896 - val_loss: 0.4905 - val_accuracy: 0.8246\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3442 - accuracy: 0.8655 - val_loss: 0.4896 - val_accuracy: 0.8284\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3354 - accuracy: 0.8715 - val_loss: 0.4896 - val_accuracy: 0.8284\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 78us/step - loss: 0.3383 - accuracy: 0.8675 - val_loss: 0.4888 - val_accuracy: 0.8284\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3314 - accuracy: 0.8896 - val_loss: 0.4877 - val_accuracy: 0.8246\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3274 - accuracy: 0.8916 - val_loss: 0.4867 - val_accuracy: 0.8246\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3299 - accuracy: 0.8936 - val_loss: 0.4860 - val_accuracy: 0.8246\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3271 - accuracy: 0.8876 - val_loss: 0.4851 - val_accuracy: 0.8246\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3344 - accuracy: 0.8815 - val_loss: 0.4846 - val_accuracy: 0.8284\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3378 - accuracy: 0.8675 - val_loss: 0.4840 - val_accuracy: 0.8284\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3454 - accuracy: 0.8715 - val_loss: 0.4838 - val_accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3262 - accuracy: 0.8876 - val_loss: 0.4839 - val_accuracy: 0.8284\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3343 - accuracy: 0.8795 - val_loss: 0.4834 - val_accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3364 - accuracy: 0.8735 - val_loss: 0.4825 - val_accuracy: 0.8321\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3287 - accuracy: 0.8815 - val_loss: 0.4818 - val_accuracy: 0.8321\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3333 - accuracy: 0.8775 - val_loss: 0.4808 - val_accuracy: 0.8358\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3287 - accuracy: 0.8775 - val_loss: 0.4799 - val_accuracy: 0.8358\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3270 - accuracy: 0.8896 - val_loss: 0.4794 - val_accuracy: 0.8358\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3267 - accuracy: 0.8876 - val_loss: 0.4790 - val_accuracy: 0.8321\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3225 - accuracy: 0.9016 - val_loss: 0.4786 - val_accuracy: 0.8321\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3190 - accuracy: 0.8896 - val_loss: 0.4784 - val_accuracy: 0.8321\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3281 - accuracy: 0.8795 - val_loss: 0.4774 - val_accuracy: 0.8321\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3200 - accuracy: 0.8876 - val_loss: 0.4770 - val_accuracy: 0.8321\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3207 - accuracy: 0.8936 - val_loss: 0.4765 - val_accuracy: 0.8321\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3228 - accuracy: 0.8855 - val_loss: 0.4762 - val_accuracy: 0.8396\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3215 - accuracy: 0.8916 - val_loss: 0.4759 - val_accuracy: 0.8433\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3226 - accuracy: 0.8896 - val_loss: 0.4762 - val_accuracy: 0.8433\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3107 - accuracy: 0.9016 - val_loss: 0.4768 - val_accuracy: 0.8433\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3296 - accuracy: 0.8916 - val_loss: 0.4770 - val_accuracy: 0.8433\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3156 - accuracy: 0.8835 - val_loss: 0.4774 - val_accuracy: 0.8433\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3188 - accuracy: 0.8835 - val_loss: 0.4775 - val_accuracy: 0.8433\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3216 - accuracy: 0.8835 - val_loss: 0.4779 - val_accuracy: 0.8433\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3226 - accuracy: 0.8835 - val_loss: 0.4785 - val_accuracy: 0.8358\n",
      "125/125 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 852us/step - loss: 0.8128 - accuracy: 0.4859 - val_loss: 0.6965 - val_accuracy: 0.6306\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.7870 - accuracy: 0.5321 - val_loss: 0.6924 - val_accuracy: 0.6381\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.7457 - accuracy: 0.5823 - val_loss: 0.6881 - val_accuracy: 0.6381\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.7248 - accuracy: 0.5944 - val_loss: 0.6835 - val_accuracy: 0.6343\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.6821 - accuracy: 0.6285 - val_loss: 0.6788 - val_accuracy: 0.6493\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.6566 - accuracy: 0.6707 - val_loss: 0.6741 - val_accuracy: 0.6455\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.6314 - accuracy: 0.6787 - val_loss: 0.6693 - val_accuracy: 0.6493\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.6276 - accuracy: 0.7028 - val_loss: 0.6643 - val_accuracy: 0.6493\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.6019 - accuracy: 0.7129 - val_loss: 0.6597 - val_accuracy: 0.6567\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5891 - accuracy: 0.7470 - val_loss: 0.6549 - val_accuracy: 0.6604\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5801 - accuracy: 0.7631 - val_loss: 0.6500 - val_accuracy: 0.6754\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5608 - accuracy: 0.7631 - val_loss: 0.6451 - val_accuracy: 0.6791\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5535 - accuracy: 0.7771 - val_loss: 0.6402 - val_accuracy: 0.6903\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.5346 - accuracy: 0.7651 - val_loss: 0.6352 - val_accuracy: 0.6903\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5293 - accuracy: 0.7711 - val_loss: 0.6302 - val_accuracy: 0.6940\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.5186 - accuracy: 0.7831 - val_loss: 0.6255 - val_accuracy: 0.6940\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.5131 - accuracy: 0.7871 - val_loss: 0.6211 - val_accuracy: 0.6940\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5075 - accuracy: 0.7811 - val_loss: 0.6166 - val_accuracy: 0.7015\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4968 - accuracy: 0.7932 - val_loss: 0.6120 - val_accuracy: 0.7015\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4863 - accuracy: 0.7952 - val_loss: 0.6077 - val_accuracy: 0.7052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4799 - accuracy: 0.7932 - val_loss: 0.6040 - val_accuracy: 0.7015\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4730 - accuracy: 0.8032 - val_loss: 0.6004 - val_accuracy: 0.7090\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4661 - accuracy: 0.8032 - val_loss: 0.5967 - val_accuracy: 0.7164\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4610 - accuracy: 0.8012 - val_loss: 0.5933 - val_accuracy: 0.7201\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4610 - accuracy: 0.8052 - val_loss: 0.5900 - val_accuracy: 0.7313\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4456 - accuracy: 0.8213 - val_loss: 0.5865 - val_accuracy: 0.7351\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4423 - accuracy: 0.8112 - val_loss: 0.5834 - val_accuracy: 0.7425\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4340 - accuracy: 0.8213 - val_loss: 0.5804 - val_accuracy: 0.7612\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4317 - accuracy: 0.8193 - val_loss: 0.5772 - val_accuracy: 0.7649\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4248 - accuracy: 0.8213 - val_loss: 0.5739 - val_accuracy: 0.7761\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4208 - accuracy: 0.8313 - val_loss: 0.5708 - val_accuracy: 0.7799\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4174 - accuracy: 0.8293 - val_loss: 0.5677 - val_accuracy: 0.7799\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4139 - accuracy: 0.8293 - val_loss: 0.5647 - val_accuracy: 0.7724\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4028 - accuracy: 0.8494 - val_loss: 0.5619 - val_accuracy: 0.7649\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4007 - accuracy: 0.8534 - val_loss: 0.5595 - val_accuracy: 0.7687\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3998 - accuracy: 0.8454 - val_loss: 0.5574 - val_accuracy: 0.7724\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3966 - accuracy: 0.8454 - val_loss: 0.5553 - val_accuracy: 0.7649\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3879 - accuracy: 0.8574 - val_loss: 0.5532 - val_accuracy: 0.7649\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3859 - accuracy: 0.8554 - val_loss: 0.5515 - val_accuracy: 0.7649\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3809 - accuracy: 0.8534 - val_loss: 0.5501 - val_accuracy: 0.7724\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3756 - accuracy: 0.8594 - val_loss: 0.5487 - val_accuracy: 0.7687\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3783 - accuracy: 0.8514 - val_loss: 0.5473 - val_accuracy: 0.7761\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3745 - accuracy: 0.8594 - val_loss: 0.5458 - val_accuracy: 0.7910\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3686 - accuracy: 0.8655 - val_loss: 0.5442 - val_accuracy: 0.7910\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3773 - accuracy: 0.8534 - val_loss: 0.5432 - val_accuracy: 0.7873\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3629 - accuracy: 0.8735 - val_loss: 0.5424 - val_accuracy: 0.7836\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3612 - accuracy: 0.8655 - val_loss: 0.5415 - val_accuracy: 0.7836\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3638 - accuracy: 0.8474 - val_loss: 0.5408 - val_accuracy: 0.7836\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3544 - accuracy: 0.8635 - val_loss: 0.5404 - val_accuracy: 0.7799\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3639 - accuracy: 0.8695 - val_loss: 0.5397 - val_accuracy: 0.7799\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3609 - accuracy: 0.8554 - val_loss: 0.5384 - val_accuracy: 0.7836\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3606 - accuracy: 0.8514 - val_loss: 0.5379 - val_accuracy: 0.7836\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3538 - accuracy: 0.8835 - val_loss: 0.5365 - val_accuracy: 0.7873\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3563 - accuracy: 0.8675 - val_loss: 0.5350 - val_accuracy: 0.7910\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3534 - accuracy: 0.8574 - val_loss: 0.5347 - val_accuracy: 0.7985\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3493 - accuracy: 0.8695 - val_loss: 0.5346 - val_accuracy: 0.7948\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3509 - accuracy: 0.8655 - val_loss: 0.5338 - val_accuracy: 0.7948\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3475 - accuracy: 0.8594 - val_loss: 0.5328 - val_accuracy: 0.7948\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3557 - accuracy: 0.8574 - val_loss: 0.5308 - val_accuracy: 0.7985\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3437 - accuracy: 0.8715 - val_loss: 0.5281 - val_accuracy: 0.7985\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3369 - accuracy: 0.8695 - val_loss: 0.5259 - val_accuracy: 0.7985\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3380 - accuracy: 0.8755 - val_loss: 0.5241 - val_accuracy: 0.7985\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3410 - accuracy: 0.8775 - val_loss: 0.5224 - val_accuracy: 0.7985\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3418 - accuracy: 0.8675 - val_loss: 0.5207 - val_accuracy: 0.8022\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3426 - accuracy: 0.8715 - val_loss: 0.5196 - val_accuracy: 0.8022\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3389 - accuracy: 0.8715 - val_loss: 0.5177 - val_accuracy: 0.8022\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3299 - accuracy: 0.8715 - val_loss: 0.5159 - val_accuracy: 0.8022\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3383 - accuracy: 0.8755 - val_loss: 0.5149 - val_accuracy: 0.8022\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3355 - accuracy: 0.8635 - val_loss: 0.5138 - val_accuracy: 0.7985\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3320 - accuracy: 0.8655 - val_loss: 0.5130 - val_accuracy: 0.7985\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3354 - accuracy: 0.8735 - val_loss: 0.5124 - val_accuracy: 0.7985\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3375 - accuracy: 0.8675 - val_loss: 0.5120 - val_accuracy: 0.8022\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3290 - accuracy: 0.8655 - val_loss: 0.5112 - val_accuracy: 0.8134\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3315 - accuracy: 0.8735 - val_loss: 0.5105 - val_accuracy: 0.8134\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3348 - accuracy: 0.8635 - val_loss: 0.5094 - val_accuracy: 0.8134\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3441 - accuracy: 0.8614 - val_loss: 0.5090 - val_accuracy: 0.8246\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3464 - accuracy: 0.8755 - val_loss: 0.5074 - val_accuracy: 0.8284\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3276 - accuracy: 0.8695 - val_loss: 0.5069 - val_accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3256 - accuracy: 0.8715 - val_loss: 0.5057 - val_accuracy: 0.8284\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3260 - accuracy: 0.8715 - val_loss: 0.5039 - val_accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3281 - accuracy: 0.8715 - val_loss: 0.5027 - val_accuracy: 0.8284\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3285 - accuracy: 0.8735 - val_loss: 0.5011 - val_accuracy: 0.8284\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3255 - accuracy: 0.8775 - val_loss: 0.4995 - val_accuracy: 0.8284\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3345 - accuracy: 0.8655 - val_loss: 0.4978 - val_accuracy: 0.8284\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3317 - accuracy: 0.8755 - val_loss: 0.4968 - val_accuracy: 0.8284\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3234 - accuracy: 0.8735 - val_loss: 0.4954 - val_accuracy: 0.8246\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3214 - accuracy: 0.8695 - val_loss: 0.4940 - val_accuracy: 0.8321\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3182 - accuracy: 0.8715 - val_loss: 0.4934 - val_accuracy: 0.8321\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3243 - accuracy: 0.8675 - val_loss: 0.4927 - val_accuracy: 0.8321\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3239 - accuracy: 0.8715 - val_loss: 0.4923 - val_accuracy: 0.8321\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3220 - accuracy: 0.8775 - val_loss: 0.4924 - val_accuracy: 0.8321\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3228 - accuracy: 0.8735 - val_loss: 0.4919 - val_accuracy: 0.8321\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3230 - accuracy: 0.8695 - val_loss: 0.4907 - val_accuracy: 0.8321\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3253 - accuracy: 0.8735 - val_loss: 0.4899 - val_accuracy: 0.8321\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3231 - accuracy: 0.8715 - val_loss: 0.4892 - val_accuracy: 0.8396\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3155 - accuracy: 0.8815 - val_loss: 0.4891 - val_accuracy: 0.8358\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3182 - accuracy: 0.8835 - val_loss: 0.4892 - val_accuracy: 0.8396\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3190 - accuracy: 0.8775 - val_loss: 0.4897 - val_accuracy: 0.8358\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3246 - accuracy: 0.8715 - val_loss: 0.4896 - val_accuracy: 0.8396\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3184 - accuracy: 0.8755 - val_loss: 0.4894 - val_accuracy: 0.8396\n",
      "125/125 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 0s 854us/step - loss: 0.8417 - accuracy: 0.4598 - val_loss: 0.7353 - val_accuracy: 0.3806\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.7890 - accuracy: 0.5803 - val_loss: 0.7255 - val_accuracy: 0.4142\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.7524 - accuracy: 0.6124 - val_loss: 0.7162 - val_accuracy: 0.5299\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.7044 - accuracy: 0.6566 - val_loss: 0.7068 - val_accuracy: 0.5485\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.6539 - accuracy: 0.6867 - val_loss: 0.6979 - val_accuracy: 0.5672\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.6391 - accuracy: 0.6867 - val_loss: 0.6895 - val_accuracy: 0.5858\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.6167 - accuracy: 0.7088 - val_loss: 0.6821 - val_accuracy: 0.6194\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.5853 - accuracy: 0.7410 - val_loss: 0.6764 - val_accuracy: 0.6679\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5882 - accuracy: 0.7390 - val_loss: 0.6710 - val_accuracy: 0.6866\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.5755 - accuracy: 0.7470 - val_loss: 0.6659 - val_accuracy: 0.7015\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.5319 - accuracy: 0.7550 - val_loss: 0.6609 - val_accuracy: 0.7090\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.5295 - accuracy: 0.7490 - val_loss: 0.6563 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.5304 - accuracy: 0.7631 - val_loss: 0.6516 - val_accuracy: 0.7649\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.5153 - accuracy: 0.7671 - val_loss: 0.6469 - val_accuracy: 0.7724\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5161 - accuracy: 0.7651 - val_loss: 0.6421 - val_accuracy: 0.7687\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.5125 - accuracy: 0.7711 - val_loss: 0.6374 - val_accuracy: 0.7761\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4941 - accuracy: 0.7912 - val_loss: 0.6328 - val_accuracy: 0.7761\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4888 - accuracy: 0.7831 - val_loss: 0.6279 - val_accuracy: 0.7836\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4811 - accuracy: 0.7992 - val_loss: 0.6229 - val_accuracy: 0.7836\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4727 - accuracy: 0.8153 - val_loss: 0.6179 - val_accuracy: 0.7724\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4762 - accuracy: 0.7972 - val_loss: 0.6132 - val_accuracy: 0.7799\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.4580 - accuracy: 0.8032 - val_loss: 0.6086 - val_accuracy: 0.7799\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4475 - accuracy: 0.8213 - val_loss: 0.6040 - val_accuracy: 0.7836\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4476 - accuracy: 0.8052 - val_loss: 0.5991 - val_accuracy: 0.7836\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4399 - accuracy: 0.8233 - val_loss: 0.5945 - val_accuracy: 0.7836\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4269 - accuracy: 0.8253 - val_loss: 0.5898 - val_accuracy: 0.7873\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4395 - accuracy: 0.8394 - val_loss: 0.5851 - val_accuracy: 0.7873\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4300 - accuracy: 0.8293 - val_loss: 0.5803 - val_accuracy: 0.7873\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4222 - accuracy: 0.8353 - val_loss: 0.5756 - val_accuracy: 0.7910\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4340 - accuracy: 0.8233 - val_loss: 0.5710 - val_accuracy: 0.7910\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4216 - accuracy: 0.8193 - val_loss: 0.5665 - val_accuracy: 0.7910\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4103 - accuracy: 0.8313 - val_loss: 0.5626 - val_accuracy: 0.7948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4106 - accuracy: 0.8293 - val_loss: 0.5588 - val_accuracy: 0.7948\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4042 - accuracy: 0.8373 - val_loss: 0.5552 - val_accuracy: 0.7948\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4079 - accuracy: 0.8333 - val_loss: 0.5515 - val_accuracy: 0.7948\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4130 - accuracy: 0.8353 - val_loss: 0.5483 - val_accuracy: 0.7948\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4058 - accuracy: 0.8313 - val_loss: 0.5452 - val_accuracy: 0.7948\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3981 - accuracy: 0.8333 - val_loss: 0.5421 - val_accuracy: 0.7985\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3994 - accuracy: 0.8394 - val_loss: 0.5388 - val_accuracy: 0.7985\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3956 - accuracy: 0.8353 - val_loss: 0.5353 - val_accuracy: 0.7985\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3975 - accuracy: 0.8394 - val_loss: 0.5319 - val_accuracy: 0.8022\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3966 - accuracy: 0.8394 - val_loss: 0.5288 - val_accuracy: 0.8060\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.4021 - accuracy: 0.8253 - val_loss: 0.5259 - val_accuracy: 0.8097\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.4089 - accuracy: 0.8333 - val_loss: 0.5231 - val_accuracy: 0.8097\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3923 - accuracy: 0.8454 - val_loss: 0.5200 - val_accuracy: 0.8134\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3907 - accuracy: 0.8293 - val_loss: 0.5175 - val_accuracy: 0.8134\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3899 - accuracy: 0.8353 - val_loss: 0.5150 - val_accuracy: 0.8097\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3849 - accuracy: 0.8474 - val_loss: 0.5126 - val_accuracy: 0.8097\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3784 - accuracy: 0.8534 - val_loss: 0.5105 - val_accuracy: 0.8097\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3759 - accuracy: 0.8614 - val_loss: 0.5087 - val_accuracy: 0.8097\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3878 - accuracy: 0.8454 - val_loss: 0.5067 - val_accuracy: 0.8097\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 76us/step - loss: 0.3748 - accuracy: 0.8554 - val_loss: 0.5043 - val_accuracy: 0.8097\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3772 - accuracy: 0.8494 - val_loss: 0.5017 - val_accuracy: 0.8097\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3789 - accuracy: 0.8494 - val_loss: 0.4993 - val_accuracy: 0.8097\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3925 - accuracy: 0.8373 - val_loss: 0.4977 - val_accuracy: 0.8097\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3643 - accuracy: 0.8554 - val_loss: 0.4956 - val_accuracy: 0.8097\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3703 - accuracy: 0.8514 - val_loss: 0.4943 - val_accuracy: 0.8097\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3767 - accuracy: 0.8454 - val_loss: 0.4928 - val_accuracy: 0.8097\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3697 - accuracy: 0.8454 - val_loss: 0.4913 - val_accuracy: 0.8097\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3833 - accuracy: 0.8333 - val_loss: 0.4898 - val_accuracy: 0.8097\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3704 - accuracy: 0.8574 - val_loss: 0.4890 - val_accuracy: 0.8097\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3795 - accuracy: 0.8494 - val_loss: 0.4882 - val_accuracy: 0.8097\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3768 - accuracy: 0.8373 - val_loss: 0.4873 - val_accuracy: 0.8134\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3714 - accuracy: 0.8514 - val_loss: 0.4863 - val_accuracy: 0.8172\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3727 - accuracy: 0.8554 - val_loss: 0.4850 - val_accuracy: 0.8209\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3677 - accuracy: 0.8454 - val_loss: 0.4837 - val_accuracy: 0.8097\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3633 - accuracy: 0.8554 - val_loss: 0.4827 - val_accuracy: 0.8097\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3557 - accuracy: 0.8635 - val_loss: 0.4812 - val_accuracy: 0.8134\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3711 - accuracy: 0.8614 - val_loss: 0.4804 - val_accuracy: 0.8097\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3644 - accuracy: 0.8574 - val_loss: 0.4795 - val_accuracy: 0.8097\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3668 - accuracy: 0.8554 - val_loss: 0.4791 - val_accuracy: 0.8134\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3734 - accuracy: 0.8474 - val_loss: 0.4793 - val_accuracy: 0.8134\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3620 - accuracy: 0.8574 - val_loss: 0.4787 - val_accuracy: 0.8134\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3619 - accuracy: 0.8514 - val_loss: 0.4780 - val_accuracy: 0.8172\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3636 - accuracy: 0.8554 - val_loss: 0.4771 - val_accuracy: 0.8172\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3632 - accuracy: 0.8554 - val_loss: 0.4762 - val_accuracy: 0.8172\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3631 - accuracy: 0.8534 - val_loss: 0.4754 - val_accuracy: 0.8209\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3591 - accuracy: 0.8635 - val_loss: 0.4740 - val_accuracy: 0.8209\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3598 - accuracy: 0.8554 - val_loss: 0.4721 - val_accuracy: 0.8209\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3634 - accuracy: 0.8494 - val_loss: 0.4712 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3609 - accuracy: 0.8494 - val_loss: 0.4703 - val_accuracy: 0.8209\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 70us/step - loss: 0.3540 - accuracy: 0.8614 - val_loss: 0.4700 - val_accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3579 - accuracy: 0.8554 - val_loss: 0.4694 - val_accuracy: 0.8209\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3593 - accuracy: 0.8534 - val_loss: 0.4695 - val_accuracy: 0.8172\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3567 - accuracy: 0.8554 - val_loss: 0.4706 - val_accuracy: 0.8209\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3535 - accuracy: 0.8675 - val_loss: 0.4706 - val_accuracy: 0.8209\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3517 - accuracy: 0.8735 - val_loss: 0.4696 - val_accuracy: 0.8209\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3547 - accuracy: 0.8594 - val_loss: 0.4691 - val_accuracy: 0.8209\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3637 - accuracy: 0.8514 - val_loss: 0.4689 - val_accuracy: 0.8209\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3555 - accuracy: 0.8554 - val_loss: 0.4690 - val_accuracy: 0.8209\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3545 - accuracy: 0.8655 - val_loss: 0.4686 - val_accuracy: 0.8209\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3545 - accuracy: 0.8675 - val_loss: 0.4688 - val_accuracy: 0.8209\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3564 - accuracy: 0.8554 - val_loss: 0.4685 - val_accuracy: 0.8209\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3555 - accuracy: 0.8554 - val_loss: 0.4686 - val_accuracy: 0.8209\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3524 - accuracy: 0.8594 - val_loss: 0.4698 - val_accuracy: 0.8209\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3506 - accuracy: 0.8614 - val_loss: 0.4702 - val_accuracy: 0.8172\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3528 - accuracy: 0.8635 - val_loss: 0.4710 - val_accuracy: 0.8172\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3594 - accuracy: 0.8594 - val_loss: 0.4703 - val_accuracy: 0.8172\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 72us/step - loss: 0.3485 - accuracy: 0.8675 - val_loss: 0.4695 - val_accuracy: 0.8172\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 74us/step - loss: 0.3536 - accuracy: 0.8594 - val_loss: 0.4687 - val_accuracy: 0.8172\n",
      "125/125 [==============================] - 0s 16us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 0s 856us/step - loss: 1.0806 - accuracy: 0.2345 - val_loss: 0.7389 - val_accuracy: 0.6119\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 1.0397 - accuracy: 0.2425 - val_loss: 0.7355 - val_accuracy: 0.6119\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.9926 - accuracy: 0.2725 - val_loss: 0.7316 - val_accuracy: 0.6119\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.9503 - accuracy: 0.2886 - val_loss: 0.7276 - val_accuracy: 0.6119\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.9093 - accuracy: 0.3206 - val_loss: 0.7233 - val_accuracy: 0.6119\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.8797 - accuracy: 0.4649 - val_loss: 0.7187 - val_accuracy: 0.6119\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.8183 - accuracy: 0.5772 - val_loss: 0.7140 - val_accuracy: 0.6119\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.8031 - accuracy: 0.5952 - val_loss: 0.7095 - val_accuracy: 0.6119\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.7639 - accuracy: 0.6373 - val_loss: 0.7053 - val_accuracy: 0.6231\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.7376 - accuracy: 0.6433 - val_loss: 0.7013 - val_accuracy: 0.6231\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.7221 - accuracy: 0.6653 - val_loss: 0.6974 - val_accuracy: 0.6194\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.7098 - accuracy: 0.6573 - val_loss: 0.6938 - val_accuracy: 0.6231\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.6880 - accuracy: 0.6774 - val_loss: 0.6902 - val_accuracy: 0.6269\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.6776 - accuracy: 0.6653 - val_loss: 0.6866 - val_accuracy: 0.6231\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.6610 - accuracy: 0.6854 - val_loss: 0.6827 - val_accuracy: 0.6269\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.6422 - accuracy: 0.6954 - val_loss: 0.6788 - val_accuracy: 0.6306\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.6316 - accuracy: 0.6934 - val_loss: 0.6751 - val_accuracy: 0.6269\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.6184 - accuracy: 0.6994 - val_loss: 0.6713 - val_accuracy: 0.6269\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.6174 - accuracy: 0.7214 - val_loss: 0.6673 - val_accuracy: 0.6231\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5959 - accuracy: 0.7315 - val_loss: 0.6631 - val_accuracy: 0.6343\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5912 - accuracy: 0.7194 - val_loss: 0.6587 - val_accuracy: 0.6418\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.5807 - accuracy: 0.7234 - val_loss: 0.6543 - val_accuracy: 0.6455\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5663 - accuracy: 0.7395 - val_loss: 0.6499 - val_accuracy: 0.6604\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5632 - accuracy: 0.7415 - val_loss: 0.6457 - val_accuracy: 0.6716\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.5498 - accuracy: 0.7415 - val_loss: 0.6415 - val_accuracy: 0.6903\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.5469 - accuracy: 0.7595 - val_loss: 0.6370 - val_accuracy: 0.6940\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5357 - accuracy: 0.7635 - val_loss: 0.6326 - val_accuracy: 0.7164\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5286 - accuracy: 0.7836 - val_loss: 0.6281 - val_accuracy: 0.7388\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5168 - accuracy: 0.7996 - val_loss: 0.6232 - val_accuracy: 0.7575\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5068 - accuracy: 0.8096 - val_loss: 0.6179 - val_accuracy: 0.7687\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5081 - accuracy: 0.8056 - val_loss: 0.6124 - val_accuracy: 0.7799\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4977 - accuracy: 0.8156 - val_loss: 0.6067 - val_accuracy: 0.7873\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4828 - accuracy: 0.8156 - val_loss: 0.6008 - val_accuracy: 0.7873\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4799 - accuracy: 0.8116 - val_loss: 0.5953 - val_accuracy: 0.7836\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4668 - accuracy: 0.8257 - val_loss: 0.5901 - val_accuracy: 0.7910\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4662 - accuracy: 0.8176 - val_loss: 0.5851 - val_accuracy: 0.7948\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4591 - accuracy: 0.8136 - val_loss: 0.5805 - val_accuracy: 0.7873\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 82us/step - loss: 0.4560 - accuracy: 0.8236 - val_loss: 0.5762 - val_accuracy: 0.7873\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4450 - accuracy: 0.8317 - val_loss: 0.5721 - val_accuracy: 0.7948\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 78us/step - loss: 0.4403 - accuracy: 0.8317 - val_loss: 0.5683 - val_accuracy: 0.7910\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4334 - accuracy: 0.8257 - val_loss: 0.5647 - val_accuracy: 0.7724\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.4388 - accuracy: 0.8277 - val_loss: 0.5613 - val_accuracy: 0.7761\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4374 - accuracy: 0.8216 - val_loss: 0.5581 - val_accuracy: 0.7761\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4216 - accuracy: 0.8277 - val_loss: 0.5546 - val_accuracy: 0.7799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4233 - accuracy: 0.8357 - val_loss: 0.5516 - val_accuracy: 0.7799\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4298 - accuracy: 0.8437 - val_loss: 0.5489 - val_accuracy: 0.7724\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4114 - accuracy: 0.8357 - val_loss: 0.5466 - val_accuracy: 0.7724\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4141 - accuracy: 0.8377 - val_loss: 0.5440 - val_accuracy: 0.7761\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4107 - accuracy: 0.8357 - val_loss: 0.5418 - val_accuracy: 0.7761\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4012 - accuracy: 0.8437 - val_loss: 0.5393 - val_accuracy: 0.7761\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3931 - accuracy: 0.8597 - val_loss: 0.5370 - val_accuracy: 0.7761\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3921 - accuracy: 0.8557 - val_loss: 0.5341 - val_accuracy: 0.7761\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3924 - accuracy: 0.8557 - val_loss: 0.5311 - val_accuracy: 0.7761\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3942 - accuracy: 0.8497 - val_loss: 0.5281 - val_accuracy: 0.7799\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3903 - accuracy: 0.8497 - val_loss: 0.5255 - val_accuracy: 0.7836\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - ETA: 0s - loss: 0.4010 - accuracy: 0.85 - 0s 72us/step - loss: 0.3912 - accuracy: 0.8497 - val_loss: 0.5230 - val_accuracy: 0.7910\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3833 - accuracy: 0.8457 - val_loss: 0.5207 - val_accuracy: 0.7873\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3790 - accuracy: 0.8557 - val_loss: 0.5185 - val_accuracy: 0.7910\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3742 - accuracy: 0.8577 - val_loss: 0.5167 - val_accuracy: 0.7873\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3794 - accuracy: 0.8477 - val_loss: 0.5151 - val_accuracy: 0.7836\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3845 - accuracy: 0.8517 - val_loss: 0.5140 - val_accuracy: 0.7799\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3815 - accuracy: 0.8457 - val_loss: 0.5121 - val_accuracy: 0.7836\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3800 - accuracy: 0.8457 - val_loss: 0.5101 - val_accuracy: 0.7836\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3793 - accuracy: 0.8457 - val_loss: 0.5072 - val_accuracy: 0.7836\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3651 - accuracy: 0.8617 - val_loss: 0.5050 - val_accuracy: 0.7873\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3648 - accuracy: 0.8617 - val_loss: 0.5027 - val_accuracy: 0.7873\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3706 - accuracy: 0.8537 - val_loss: 0.5007 - val_accuracy: 0.7873\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3596 - accuracy: 0.8697 - val_loss: 0.4987 - val_accuracy: 0.7873\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3577 - accuracy: 0.8697 - val_loss: 0.4970 - val_accuracy: 0.7836\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3671 - accuracy: 0.8517 - val_loss: 0.4955 - val_accuracy: 0.7836\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3536 - accuracy: 0.8657 - val_loss: 0.4944 - val_accuracy: 0.7873\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3588 - accuracy: 0.8597 - val_loss: 0.4930 - val_accuracy: 0.7948\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3592 - accuracy: 0.8497 - val_loss: 0.4916 - val_accuracy: 0.7948\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3539 - accuracy: 0.8677 - val_loss: 0.4904 - val_accuracy: 0.7948\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3527 - accuracy: 0.8717 - val_loss: 0.4891 - val_accuracy: 0.7985\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3550 - accuracy: 0.8637 - val_loss: 0.4872 - val_accuracy: 0.7985\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3460 - accuracy: 0.8717 - val_loss: 0.4854 - val_accuracy: 0.7985\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3564 - accuracy: 0.8637 - val_loss: 0.4843 - val_accuracy: 0.7985\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3455 - accuracy: 0.8737 - val_loss: 0.4838 - val_accuracy: 0.7985\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3435 - accuracy: 0.8657 - val_loss: 0.4823 - val_accuracy: 0.8022\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3477 - accuracy: 0.8697 - val_loss: 0.4801 - val_accuracy: 0.8022\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3429 - accuracy: 0.8697 - val_loss: 0.4795 - val_accuracy: 0.8022\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3386 - accuracy: 0.8778 - val_loss: 0.4794 - val_accuracy: 0.8022\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3407 - accuracy: 0.8778 - val_loss: 0.4787 - val_accuracy: 0.8022\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3455 - accuracy: 0.8657 - val_loss: 0.4776 - val_accuracy: 0.8022\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3376 - accuracy: 0.8737 - val_loss: 0.4769 - val_accuracy: 0.8022\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3427 - accuracy: 0.8657 - val_loss: 0.4765 - val_accuracy: 0.8022\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3476 - accuracy: 0.8737 - val_loss: 0.4762 - val_accuracy: 0.8022\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3321 - accuracy: 0.8778 - val_loss: 0.4762 - val_accuracy: 0.8022\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3368 - accuracy: 0.8758 - val_loss: 0.4758 - val_accuracy: 0.8022\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3424 - accuracy: 0.8657 - val_loss: 0.4757 - val_accuracy: 0.8022\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3431 - accuracy: 0.8657 - val_loss: 0.4749 - val_accuracy: 0.8097\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3379 - accuracy: 0.8717 - val_loss: 0.4744 - val_accuracy: 0.8060\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3374 - accuracy: 0.8697 - val_loss: 0.4744 - val_accuracy: 0.8060\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3353 - accuracy: 0.8737 - val_loss: 0.4738 - val_accuracy: 0.8060\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3333 - accuracy: 0.8758 - val_loss: 0.4738 - val_accuracy: 0.8060\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3399 - accuracy: 0.8778 - val_loss: 0.4743 - val_accuracy: 0.8060\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3397 - accuracy: 0.8717 - val_loss: 0.4753 - val_accuracy: 0.8022\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3312 - accuracy: 0.8758 - val_loss: 0.4748 - val_accuracy: 0.7985\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3332 - accuracy: 0.8798 - val_loss: 0.4751 - val_accuracy: 0.8022\n",
      "124/124 [==============================] - 0s 16us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 0s 860us/step - loss: 0.9565 - accuracy: 0.3828 - val_loss: 0.6747 - val_accuracy: 0.6978\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.8931 - accuracy: 0.4208 - val_loss: 0.6661 - val_accuracy: 0.7164\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.8346 - accuracy: 0.4850 - val_loss: 0.6584 - val_accuracy: 0.7127\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.7801 - accuracy: 0.5391 - val_loss: 0.6512 - val_accuracy: 0.7090\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.7354 - accuracy: 0.5952 - val_loss: 0.6438 - val_accuracy: 0.7164\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.6904 - accuracy: 0.6052 - val_loss: 0.6358 - val_accuracy: 0.7351\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.6566 - accuracy: 0.6613 - val_loss: 0.6281 - val_accuracy: 0.7351\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.6218 - accuracy: 0.6874 - val_loss: 0.6208 - val_accuracy: 0.7388\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 71us/step - loss: 0.5943 - accuracy: 0.7074 - val_loss: 0.6140 - val_accuracy: 0.7388\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5734 - accuracy: 0.7515 - val_loss: 0.6067 - val_accuracy: 0.7463\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5476 - accuracy: 0.7896 - val_loss: 0.6000 - val_accuracy: 0.7537\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.5323 - accuracy: 0.7956 - val_loss: 0.5939 - val_accuracy: 0.7537\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.5092 - accuracy: 0.8076 - val_loss: 0.5871 - val_accuracy: 0.7537\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.5004 - accuracy: 0.8176 - val_loss: 0.5809 - val_accuracy: 0.7537\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4820 - accuracy: 0.8176 - val_loss: 0.5753 - val_accuracy: 0.7537\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4781 - accuracy: 0.8236 - val_loss: 0.5703 - val_accuracy: 0.7612\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4579 - accuracy: 0.8277 - val_loss: 0.5654 - val_accuracy: 0.7649\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4532 - accuracy: 0.8176 - val_loss: 0.5603 - val_accuracy: 0.7612\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4419 - accuracy: 0.8317 - val_loss: 0.5561 - val_accuracy: 0.7724\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4339 - accuracy: 0.8337 - val_loss: 0.5521 - val_accuracy: 0.7724\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4301 - accuracy: 0.8317 - val_loss: 0.5484 - val_accuracy: 0.7724\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4240 - accuracy: 0.8277 - val_loss: 0.5451 - val_accuracy: 0.7761\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4190 - accuracy: 0.8377 - val_loss: 0.5420 - val_accuracy: 0.7761\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4158 - accuracy: 0.8317 - val_loss: 0.5394 - val_accuracy: 0.7761\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4101 - accuracy: 0.8317 - val_loss: 0.5373 - val_accuracy: 0.7761\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4064 - accuracy: 0.8377 - val_loss: 0.5351 - val_accuracy: 0.7799\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.4042 - accuracy: 0.8377 - val_loss: 0.5331 - val_accuracy: 0.7910\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.4005 - accuracy: 0.8297 - val_loss: 0.5312 - val_accuracy: 0.7985\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3979 - accuracy: 0.8357 - val_loss: 0.5297 - val_accuracy: 0.8097\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.4014 - accuracy: 0.8377 - val_loss: 0.5281 - val_accuracy: 0.8097\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3893 - accuracy: 0.8417 - val_loss: 0.5267 - val_accuracy: 0.8134\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3970 - accuracy: 0.8357 - val_loss: 0.5255 - val_accuracy: 0.8134\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3846 - accuracy: 0.8417 - val_loss: 0.5243 - val_accuracy: 0.8134\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3963 - accuracy: 0.8417 - val_loss: 0.5232 - val_accuracy: 0.8134\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3797 - accuracy: 0.8437 - val_loss: 0.5219 - val_accuracy: 0.8172\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3810 - accuracy: 0.8457 - val_loss: 0.5206 - val_accuracy: 0.8284\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3811 - accuracy: 0.8517 - val_loss: 0.5193 - val_accuracy: 0.8358\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3761 - accuracy: 0.8517 - val_loss: 0.5179 - val_accuracy: 0.8358\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3763 - accuracy: 0.8417 - val_loss: 0.5165 - val_accuracy: 0.8358\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3722 - accuracy: 0.8437 - val_loss: 0.5152 - val_accuracy: 0.8358\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3691 - accuracy: 0.8597 - val_loss: 0.5138 - val_accuracy: 0.8396\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3728 - accuracy: 0.8497 - val_loss: 0.5124 - val_accuracy: 0.8396\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3791 - accuracy: 0.8437 - val_loss: 0.5110 - val_accuracy: 0.8396\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3696 - accuracy: 0.8557 - val_loss: 0.5097 - val_accuracy: 0.8396\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3637 - accuracy: 0.8517 - val_loss: 0.5081 - val_accuracy: 0.8396\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3655 - accuracy: 0.8517 - val_loss: 0.5065 - val_accuracy: 0.8396\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3634 - accuracy: 0.8617 - val_loss: 0.5050 - val_accuracy: 0.8396\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3717 - accuracy: 0.8597 - val_loss: 0.5037 - val_accuracy: 0.8284\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3644 - accuracy: 0.8597 - val_loss: 0.5025 - val_accuracy: 0.8284\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3586 - accuracy: 0.8617 - val_loss: 0.5015 - val_accuracy: 0.8209\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3577 - accuracy: 0.8617 - val_loss: 0.5006 - val_accuracy: 0.8172\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3557 - accuracy: 0.8617 - val_loss: 0.4997 - val_accuracy: 0.8172\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3538 - accuracy: 0.8597 - val_loss: 0.4988 - val_accuracy: 0.8246\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3589 - accuracy: 0.8637 - val_loss: 0.4981 - val_accuracy: 0.8284\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3628 - accuracy: 0.8597 - val_loss: 0.4974 - val_accuracy: 0.8209\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3574 - accuracy: 0.8557 - val_loss: 0.4968 - val_accuracy: 0.8209\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3508 - accuracy: 0.8677 - val_loss: 0.4960 - val_accuracy: 0.8172\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3523 - accuracy: 0.8657 - val_loss: 0.4954 - val_accuracy: 0.8134\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3539 - accuracy: 0.8637 - val_loss: 0.4942 - val_accuracy: 0.8097\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3506 - accuracy: 0.8717 - val_loss: 0.4935 - val_accuracy: 0.8060\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3464 - accuracy: 0.8637 - val_loss: 0.4929 - val_accuracy: 0.8022\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3582 - accuracy: 0.8597 - val_loss: 0.4923 - val_accuracy: 0.8022\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3473 - accuracy: 0.8677 - val_loss: 0.4919 - val_accuracy: 0.8134\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3431 - accuracy: 0.8697 - val_loss: 0.4915 - val_accuracy: 0.8097\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3501 - accuracy: 0.8657 - val_loss: 0.4913 - val_accuracy: 0.8134\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3435 - accuracy: 0.8758 - val_loss: 0.4913 - val_accuracy: 0.8134\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3412 - accuracy: 0.8597 - val_loss: 0.4915 - val_accuracy: 0.8172\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3389 - accuracy: 0.8677 - val_loss: 0.4918 - val_accuracy: 0.8172\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3384 - accuracy: 0.8697 - val_loss: 0.4917 - val_accuracy: 0.8134\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 76us/step - loss: 0.3427 - accuracy: 0.8637 - val_loss: 0.4916 - val_accuracy: 0.8134\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3369 - accuracy: 0.8637 - val_loss: 0.4914 - val_accuracy: 0.8060\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3365 - accuracy: 0.8758 - val_loss: 0.4915 - val_accuracy: 0.8022\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3357 - accuracy: 0.8758 - val_loss: 0.4914 - val_accuracy: 0.8022\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3422 - accuracy: 0.8717 - val_loss: 0.4903 - val_accuracy: 0.8060\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3338 - accuracy: 0.8637 - val_loss: 0.4900 - val_accuracy: 0.8060\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3455 - accuracy: 0.8778 - val_loss: 0.4899 - val_accuracy: 0.7948\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3371 - accuracy: 0.8677 - val_loss: 0.4896 - val_accuracy: 0.7910\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3367 - accuracy: 0.8637 - val_loss: 0.4896 - val_accuracy: 0.7910\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3337 - accuracy: 0.8778 - val_loss: 0.4898 - val_accuracy: 0.7873\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3300 - accuracy: 0.8697 - val_loss: 0.4900 - val_accuracy: 0.7873\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3330 - accuracy: 0.8697 - val_loss: 0.4898 - val_accuracy: 0.7873\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3387 - accuracy: 0.8737 - val_loss: 0.4901 - val_accuracy: 0.7910\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3362 - accuracy: 0.8677 - val_loss: 0.4903 - val_accuracy: 0.7873\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3282 - accuracy: 0.8737 - val_loss: 0.4904 - val_accuracy: 0.7873\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3303 - accuracy: 0.8677 - val_loss: 0.4901 - val_accuracy: 0.7873\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3318 - accuracy: 0.8778 - val_loss: 0.4903 - val_accuracy: 0.7836\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3348 - accuracy: 0.8697 - val_loss: 0.4900 - val_accuracy: 0.7910\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3267 - accuracy: 0.8758 - val_loss: 0.4895 - val_accuracy: 0.7910\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3282 - accuracy: 0.8737 - val_loss: 0.4899 - val_accuracy: 0.7873\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3338 - accuracy: 0.8737 - val_loss: 0.4901 - val_accuracy: 0.7873\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3256 - accuracy: 0.8697 - val_loss: 0.4904 - val_accuracy: 0.7799\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3264 - accuracy: 0.8798 - val_loss: 0.4907 - val_accuracy: 0.7761\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3288 - accuracy: 0.8717 - val_loss: 0.4906 - val_accuracy: 0.7724\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3290 - accuracy: 0.8758 - val_loss: 0.4907 - val_accuracy: 0.7724\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3261 - accuracy: 0.8717 - val_loss: 0.4905 - val_accuracy: 0.7761\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3319 - accuracy: 0.8697 - val_loss: 0.4916 - val_accuracy: 0.7761\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 74us/step - loss: 0.3258 - accuracy: 0.8758 - val_loss: 0.4918 - val_accuracy: 0.7761\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 70us/step - loss: 0.3227 - accuracy: 0.8737 - val_loss: 0.4920 - val_accuracy: 0.7799\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3324 - accuracy: 0.8697 - val_loss: 0.4923 - val_accuracy: 0.7799\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 72us/step - loss: 0.3234 - accuracy: 0.8798 - val_loss: 0.4922 - val_accuracy: 0.7687\n",
      "124/124 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 0.6804 - accuracy: 0.7108 - val_loss: 0.7087 - val_accuracy: 0.6530\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.6382 - accuracy: 0.7631 - val_loss: 0.7067 - val_accuracy: 0.6679\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.6007 - accuracy: 0.7651 - val_loss: 0.7046 - val_accuracy: 0.6716\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5833 - accuracy: 0.7651 - val_loss: 0.7023 - val_accuracy: 0.6754\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.5671 - accuracy: 0.7831 - val_loss: 0.6999 - val_accuracy: 0.6828\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5411 - accuracy: 0.7932 - val_loss: 0.6976 - val_accuracy: 0.6978\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5315 - accuracy: 0.7972 - val_loss: 0.6951 - val_accuracy: 0.7090\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.5142 - accuracy: 0.7972 - val_loss: 0.6926 - val_accuracy: 0.7201\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5015 - accuracy: 0.8032 - val_loss: 0.6893 - val_accuracy: 0.7239\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4845 - accuracy: 0.7992 - val_loss: 0.6860 - val_accuracy: 0.7127\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4849 - accuracy: 0.8032 - val_loss: 0.6827 - val_accuracy: 0.7313\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4696 - accuracy: 0.8092 - val_loss: 0.6788 - val_accuracy: 0.7313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4736 - accuracy: 0.8092 - val_loss: 0.6743 - val_accuracy: 0.7313\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4619 - accuracy: 0.8112 - val_loss: 0.6690 - val_accuracy: 0.7388\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4562 - accuracy: 0.8072 - val_loss: 0.6635 - val_accuracy: 0.7463\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4600 - accuracy: 0.7992 - val_loss: 0.6576 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4447 - accuracy: 0.8153 - val_loss: 0.6517 - val_accuracy: 0.7612\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4367 - accuracy: 0.8032 - val_loss: 0.6462 - val_accuracy: 0.7724\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4333 - accuracy: 0.8213 - val_loss: 0.6410 - val_accuracy: 0.7799\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4284 - accuracy: 0.8112 - val_loss: 0.6359 - val_accuracy: 0.7799\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4240 - accuracy: 0.8313 - val_loss: 0.6308 - val_accuracy: 0.7873\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4218 - accuracy: 0.8253 - val_loss: 0.6260 - val_accuracy: 0.7799\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4225 - accuracy: 0.8373 - val_loss: 0.6214 - val_accuracy: 0.7799\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4132 - accuracy: 0.8293 - val_loss: 0.6172 - val_accuracy: 0.7799\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4083 - accuracy: 0.8313 - val_loss: 0.6130 - val_accuracy: 0.7761\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4061 - accuracy: 0.8353 - val_loss: 0.6082 - val_accuracy: 0.7724\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4021 - accuracy: 0.8434 - val_loss: 0.6030 - val_accuracy: 0.7799\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3952 - accuracy: 0.8434 - val_loss: 0.5987 - val_accuracy: 0.7799\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3920 - accuracy: 0.8554 - val_loss: 0.5941 - val_accuracy: 0.7836\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3909 - accuracy: 0.8514 - val_loss: 0.5898 - val_accuracy: 0.7836\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3870 - accuracy: 0.8574 - val_loss: 0.5852 - val_accuracy: 0.7836\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3772 - accuracy: 0.8534 - val_loss: 0.5803 - val_accuracy: 0.7836\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3807 - accuracy: 0.8514 - val_loss: 0.5755 - val_accuracy: 0.7985\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3751 - accuracy: 0.8594 - val_loss: 0.5704 - val_accuracy: 0.8060\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3755 - accuracy: 0.8574 - val_loss: 0.5653 - val_accuracy: 0.8097\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3801 - accuracy: 0.8514 - val_loss: 0.5608 - val_accuracy: 0.8097\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3774 - accuracy: 0.8534 - val_loss: 0.5563 - val_accuracy: 0.8097\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3703 - accuracy: 0.8554 - val_loss: 0.5518 - val_accuracy: 0.8060\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3659 - accuracy: 0.8614 - val_loss: 0.5472 - val_accuracy: 0.8060\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3574 - accuracy: 0.8635 - val_loss: 0.5436 - val_accuracy: 0.8060\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3603 - accuracy: 0.8655 - val_loss: 0.5404 - val_accuracy: 0.8060\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3576 - accuracy: 0.8635 - val_loss: 0.5376 - val_accuracy: 0.8060\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3617 - accuracy: 0.8594 - val_loss: 0.5351 - val_accuracy: 0.8060\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3657 - accuracy: 0.8635 - val_loss: 0.5326 - val_accuracy: 0.8060\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3594 - accuracy: 0.8695 - val_loss: 0.5301 - val_accuracy: 0.8060\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3569 - accuracy: 0.8635 - val_loss: 0.5276 - val_accuracy: 0.8060\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3479 - accuracy: 0.8715 - val_loss: 0.5251 - val_accuracy: 0.8060\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3565 - accuracy: 0.8635 - val_loss: 0.5224 - val_accuracy: 0.8097\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3513 - accuracy: 0.8695 - val_loss: 0.5192 - val_accuracy: 0.8097\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3521 - accuracy: 0.8675 - val_loss: 0.5162 - val_accuracy: 0.8097\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3486 - accuracy: 0.8594 - val_loss: 0.5141 - val_accuracy: 0.8097\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3462 - accuracy: 0.8675 - val_loss: 0.5129 - val_accuracy: 0.8060\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3562 - accuracy: 0.8695 - val_loss: 0.5104 - val_accuracy: 0.8060\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3451 - accuracy: 0.8614 - val_loss: 0.5084 - val_accuracy: 0.8097\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3441 - accuracy: 0.8675 - val_loss: 0.5066 - val_accuracy: 0.8097\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3403 - accuracy: 0.8755 - val_loss: 0.5033 - val_accuracy: 0.8097\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3404 - accuracy: 0.8675 - val_loss: 0.5010 - val_accuracy: 0.8060\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3409 - accuracy: 0.8655 - val_loss: 0.4991 - val_accuracy: 0.8060\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3481 - accuracy: 0.8675 - val_loss: 0.4983 - val_accuracy: 0.8060\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3569 - accuracy: 0.8434 - val_loss: 0.4972 - val_accuracy: 0.8060\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3386 - accuracy: 0.8675 - val_loss: 0.4968 - val_accuracy: 0.8060\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3479 - accuracy: 0.8675 - val_loss: 0.4971 - val_accuracy: 0.8134\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3586 - accuracy: 0.8534 - val_loss: 0.4964 - val_accuracy: 0.8172\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3390 - accuracy: 0.8695 - val_loss: 0.4976 - val_accuracy: 0.8172\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3326 - accuracy: 0.8695 - val_loss: 0.4952 - val_accuracy: 0.8172\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3371 - accuracy: 0.8695 - val_loss: 0.4932 - val_accuracy: 0.8172\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3385 - accuracy: 0.8695 - val_loss: 0.4913 - val_accuracy: 0.8172\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3319 - accuracy: 0.8675 - val_loss: 0.4901 - val_accuracy: 0.8172\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3285 - accuracy: 0.8735 - val_loss: 0.4877 - val_accuracy: 0.8172\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3370 - accuracy: 0.8695 - val_loss: 0.4877 - val_accuracy: 0.8172\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3332 - accuracy: 0.8795 - val_loss: 0.4870 - val_accuracy: 0.8172\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3306 - accuracy: 0.8735 - val_loss: 0.4871 - val_accuracy: 0.8172\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3358 - accuracy: 0.8755 - val_loss: 0.4852 - val_accuracy: 0.8172\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3255 - accuracy: 0.8735 - val_loss: 0.4827 - val_accuracy: 0.8172\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3283 - accuracy: 0.8675 - val_loss: 0.4825 - val_accuracy: 0.8172\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3311 - accuracy: 0.8755 - val_loss: 0.4839 - val_accuracy: 0.8172\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3375 - accuracy: 0.8675 - val_loss: 0.4839 - val_accuracy: 0.8172\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3363 - accuracy: 0.8755 - val_loss: 0.4809 - val_accuracy: 0.8172\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3327 - accuracy: 0.8675 - val_loss: 0.4784 - val_accuracy: 0.8172\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3249 - accuracy: 0.8735 - val_loss: 0.4744 - val_accuracy: 0.8172\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3290 - accuracy: 0.8735 - val_loss: 0.4723 - val_accuracy: 0.8246\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3308 - accuracy: 0.8735 - val_loss: 0.4708 - val_accuracy: 0.8284\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3281 - accuracy: 0.8695 - val_loss: 0.4711 - val_accuracy: 0.8284\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3232 - accuracy: 0.8735 - val_loss: 0.4716 - val_accuracy: 0.8284\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3301 - accuracy: 0.8755 - val_loss: 0.4719 - val_accuracy: 0.8284\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3271 - accuracy: 0.8695 - val_loss: 0.4722 - val_accuracy: 0.8284\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3285 - accuracy: 0.8815 - val_loss: 0.4721 - val_accuracy: 0.8284\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3246 - accuracy: 0.8655 - val_loss: 0.4713 - val_accuracy: 0.8284\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3200 - accuracy: 0.8835 - val_loss: 0.4706 - val_accuracy: 0.8284\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3200 - accuracy: 0.8755 - val_loss: 0.4697 - val_accuracy: 0.8284\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3234 - accuracy: 0.8795 - val_loss: 0.4686 - val_accuracy: 0.8284\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3145 - accuracy: 0.8815 - val_loss: 0.4683 - val_accuracy: 0.8284\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3280 - accuracy: 0.8795 - val_loss: 0.4689 - val_accuracy: 0.8284\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3292 - accuracy: 0.8655 - val_loss: 0.4680 - val_accuracy: 0.8321\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3272 - accuracy: 0.8715 - val_loss: 0.4680 - val_accuracy: 0.8321\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3232 - accuracy: 0.8735 - val_loss: 0.4671 - val_accuracy: 0.8284\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3212 - accuracy: 0.8795 - val_loss: 0.4652 - val_accuracy: 0.8284\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3175 - accuracy: 0.8735 - val_loss: 0.4642 - val_accuracy: 0.8284\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3226 - accuracy: 0.8675 - val_loss: 0.4640 - val_accuracy: 0.8284\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3185 - accuracy: 0.8755 - val_loss: 0.4645 - val_accuracy: 0.8246\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 1.1726 - accuracy: 0.3434 - val_loss: 0.7276 - val_accuracy: 0.6119\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 1.0635 - accuracy: 0.4578 - val_loss: 0.7268 - val_accuracy: 0.6119\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.9741 - accuracy: 0.5100 - val_loss: 0.7255 - val_accuracy: 0.6119\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.8968 - accuracy: 0.5843 - val_loss: 0.7243 - val_accuracy: 0.6157\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.8522 - accuracy: 0.5984 - val_loss: 0.7237 - val_accuracy: 0.5784\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.7914 - accuracy: 0.6406 - val_loss: 0.7230 - val_accuracy: 0.5410\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.7629 - accuracy: 0.6466 - val_loss: 0.7229 - val_accuracy: 0.4813\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.7305 - accuracy: 0.6586 - val_loss: 0.7228 - val_accuracy: 0.4776\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.7256 - accuracy: 0.6647 - val_loss: 0.7220 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6859 - accuracy: 0.6908 - val_loss: 0.7211 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6729 - accuracy: 0.7048 - val_loss: 0.7199 - val_accuracy: 0.5672\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6519 - accuracy: 0.7088 - val_loss: 0.7184 - val_accuracy: 0.5634\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6447 - accuracy: 0.7189 - val_loss: 0.7169 - val_accuracy: 0.5560\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6143 - accuracy: 0.7309 - val_loss: 0.7155 - val_accuracy: 0.5597\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6053 - accuracy: 0.7430 - val_loss: 0.7144 - val_accuracy: 0.5784\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5994 - accuracy: 0.7349 - val_loss: 0.7133 - val_accuracy: 0.5821\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5888 - accuracy: 0.7410 - val_loss: 0.7125 - val_accuracy: 0.5746\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5803 - accuracy: 0.7610 - val_loss: 0.7112 - val_accuracy: 0.5784\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.5695 - accuracy: 0.7490 - val_loss: 0.7099 - val_accuracy: 0.6045\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5709 - accuracy: 0.7550 - val_loss: 0.7084 - val_accuracy: 0.6082\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5546 - accuracy: 0.7490 - val_loss: 0.7070 - val_accuracy: 0.6119\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5542 - accuracy: 0.7671 - val_loss: 0.7053 - val_accuracy: 0.6231\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5458 - accuracy: 0.7711 - val_loss: 0.7041 - val_accuracy: 0.6119\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5368 - accuracy: 0.7711 - val_loss: 0.7026 - val_accuracy: 0.6119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5357 - accuracy: 0.7691 - val_loss: 0.7011 - val_accuracy: 0.6045\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.5185 - accuracy: 0.7791 - val_loss: 0.6997 - val_accuracy: 0.6157\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5188 - accuracy: 0.7871 - val_loss: 0.6982 - val_accuracy: 0.6119\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5193 - accuracy: 0.7892 - val_loss: 0.6964 - val_accuracy: 0.6119\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5153 - accuracy: 0.7771 - val_loss: 0.6938 - val_accuracy: 0.6157\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4905 - accuracy: 0.7972 - val_loss: 0.6916 - val_accuracy: 0.6306\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5015 - accuracy: 0.7771 - val_loss: 0.6895 - val_accuracy: 0.6269\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4920 - accuracy: 0.7851 - val_loss: 0.6872 - val_accuracy: 0.6269\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4776 - accuracy: 0.7992 - val_loss: 0.6845 - val_accuracy: 0.6343\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4732 - accuracy: 0.7972 - val_loss: 0.6817 - val_accuracy: 0.6418\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4677 - accuracy: 0.8032 - val_loss: 0.6791 - val_accuracy: 0.6418\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4648 - accuracy: 0.8153 - val_loss: 0.6757 - val_accuracy: 0.6530\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4593 - accuracy: 0.8092 - val_loss: 0.6726 - val_accuracy: 0.6567\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4499 - accuracy: 0.8092 - val_loss: 0.6695 - val_accuracy: 0.6567\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4512 - accuracy: 0.8193 - val_loss: 0.6663 - val_accuracy: 0.6567\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4403 - accuracy: 0.8253 - val_loss: 0.6631 - val_accuracy: 0.6679\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4379 - accuracy: 0.8133 - val_loss: 0.6597 - val_accuracy: 0.6716\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4307 - accuracy: 0.8373 - val_loss: 0.6559 - val_accuracy: 0.6754\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4362 - accuracy: 0.8273 - val_loss: 0.6523 - val_accuracy: 0.6791\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4327 - accuracy: 0.8293 - val_loss: 0.6484 - val_accuracy: 0.6866\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4235 - accuracy: 0.8253 - val_loss: 0.6445 - val_accuracy: 0.6940\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4324 - accuracy: 0.8273 - val_loss: 0.6404 - val_accuracy: 0.6940\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4185 - accuracy: 0.8353 - val_loss: 0.6363 - val_accuracy: 0.6903\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4191 - accuracy: 0.8333 - val_loss: 0.6318 - val_accuracy: 0.6903\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4168 - accuracy: 0.8293 - val_loss: 0.6270 - val_accuracy: 0.7015\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4116 - accuracy: 0.8353 - val_loss: 0.6221 - val_accuracy: 0.7127\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4121 - accuracy: 0.8394 - val_loss: 0.6173 - val_accuracy: 0.7164\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4066 - accuracy: 0.8454 - val_loss: 0.6123 - val_accuracy: 0.7276\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4037 - accuracy: 0.8414 - val_loss: 0.6074 - val_accuracy: 0.7276\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3916 - accuracy: 0.8534 - val_loss: 0.6026 - val_accuracy: 0.7313\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3930 - accuracy: 0.8414 - val_loss: 0.5985 - val_accuracy: 0.7425\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3959 - accuracy: 0.8434 - val_loss: 0.5937 - val_accuracy: 0.7463\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3962 - accuracy: 0.8454 - val_loss: 0.5899 - val_accuracy: 0.7463\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3832 - accuracy: 0.8514 - val_loss: 0.5864 - val_accuracy: 0.7425\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3885 - accuracy: 0.8373 - val_loss: 0.5835 - val_accuracy: 0.7425\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3906 - accuracy: 0.8434 - val_loss: 0.5812 - val_accuracy: 0.7425\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3803 - accuracy: 0.8454 - val_loss: 0.5797 - val_accuracy: 0.7425\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3854 - accuracy: 0.8414 - val_loss: 0.5773 - val_accuracy: 0.7425\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3719 - accuracy: 0.8574 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3784 - accuracy: 0.8434 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3781 - accuracy: 0.8554 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3715 - accuracy: 0.8474 - val_loss: 0.5684 - val_accuracy: 0.7537\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3633 - accuracy: 0.8635 - val_loss: 0.5666 - val_accuracy: 0.7575\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3738 - accuracy: 0.8434 - val_loss: 0.5649 - val_accuracy: 0.7575\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3621 - accuracy: 0.8534 - val_loss: 0.5636 - val_accuracy: 0.7537\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3641 - accuracy: 0.8554 - val_loss: 0.5624 - val_accuracy: 0.7537\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3748 - accuracy: 0.8494 - val_loss: 0.5616 - val_accuracy: 0.7575\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3627 - accuracy: 0.8534 - val_loss: 0.5608 - val_accuracy: 0.7612\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3543 - accuracy: 0.8715 - val_loss: 0.5601 - val_accuracy: 0.7575\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3603 - accuracy: 0.8594 - val_loss: 0.5593 - val_accuracy: 0.7537\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3669 - accuracy: 0.8534 - val_loss: 0.5576 - val_accuracy: 0.7537\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3540 - accuracy: 0.8594 - val_loss: 0.5562 - val_accuracy: 0.7537\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3569 - accuracy: 0.8675 - val_loss: 0.5559 - val_accuracy: 0.7649\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3616 - accuracy: 0.8655 - val_loss: 0.5551 - val_accuracy: 0.7612\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3502 - accuracy: 0.8735 - val_loss: 0.5551 - val_accuracy: 0.7612\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3520 - accuracy: 0.8695 - val_loss: 0.5548 - val_accuracy: 0.7612\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3476 - accuracy: 0.8735 - val_loss: 0.5543 - val_accuracy: 0.7612\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3553 - accuracy: 0.8655 - val_loss: 0.5546 - val_accuracy: 0.7649\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3487 - accuracy: 0.8655 - val_loss: 0.5534 - val_accuracy: 0.7612\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3560 - accuracy: 0.8574 - val_loss: 0.5525 - val_accuracy: 0.7612\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3503 - accuracy: 0.8695 - val_loss: 0.5513 - val_accuracy: 0.7575\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3461 - accuracy: 0.8795 - val_loss: 0.5493 - val_accuracy: 0.7575\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3477 - accuracy: 0.8695 - val_loss: 0.5473 - val_accuracy: 0.7649\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3507 - accuracy: 0.8715 - val_loss: 0.5449 - val_accuracy: 0.7687\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3430 - accuracy: 0.8715 - val_loss: 0.5440 - val_accuracy: 0.7724\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3526 - accuracy: 0.8675 - val_loss: 0.5437 - val_accuracy: 0.7724\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3534 - accuracy: 0.8614 - val_loss: 0.5434 - val_accuracy: 0.7761\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3395 - accuracy: 0.8755 - val_loss: 0.5409 - val_accuracy: 0.7724\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3485 - accuracy: 0.8715 - val_loss: 0.5385 - val_accuracy: 0.7761\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3427 - accuracy: 0.8695 - val_loss: 0.5367 - val_accuracy: 0.7687\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3357 - accuracy: 0.8755 - val_loss: 0.5358 - val_accuracy: 0.7687\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3374 - accuracy: 0.8695 - val_loss: 0.5351 - val_accuracy: 0.7799\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3394 - accuracy: 0.8614 - val_loss: 0.5347 - val_accuracy: 0.7799\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3367 - accuracy: 0.8735 - val_loss: 0.5344 - val_accuracy: 0.7761\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3399 - accuracy: 0.8715 - val_loss: 0.5336 - val_accuracy: 0.7724\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3429 - accuracy: 0.8695 - val_loss: 0.5326 - val_accuracy: 0.7761\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 1.0747 - accuracy: 0.3996 - val_loss: 0.7447 - val_accuracy: 0.4440\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 1.0376 - accuracy: 0.4096 - val_loss: 0.7372 - val_accuracy: 0.4478\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.9852 - accuracy: 0.4237 - val_loss: 0.7295 - val_accuracy: 0.4552\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.9187 - accuracy: 0.4297 - val_loss: 0.7205 - val_accuracy: 0.4590\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.8723 - accuracy: 0.4378 - val_loss: 0.7100 - val_accuracy: 0.5037\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.8366 - accuracy: 0.4317 - val_loss: 0.6991 - val_accuracy: 0.6231\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.7917 - accuracy: 0.4418 - val_loss: 0.6877 - val_accuracy: 0.6269\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.7353 - accuracy: 0.4759 - val_loss: 0.6768 - val_accuracy: 0.6455\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.7141 - accuracy: 0.4980 - val_loss: 0.6662 - val_accuracy: 0.6530\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6701 - accuracy: 0.5783 - val_loss: 0.6559 - val_accuracy: 0.7052\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6637 - accuracy: 0.6325 - val_loss: 0.6468 - val_accuracy: 0.7425\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.6293 - accuracy: 0.7269 - val_loss: 0.6382 - val_accuracy: 0.7761\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6062 - accuracy: 0.7329 - val_loss: 0.6308 - val_accuracy: 0.7873\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5930 - accuracy: 0.7430 - val_loss: 0.6240 - val_accuracy: 0.8060\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.5769 - accuracy: 0.7269 - val_loss: 0.6174 - val_accuracy: 0.8060\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.5663 - accuracy: 0.7269 - val_loss: 0.6115 - val_accuracy: 0.8172\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5450 - accuracy: 0.7430 - val_loss: 0.6077 - val_accuracy: 0.8246\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.5379 - accuracy: 0.7550 - val_loss: 0.6050 - val_accuracy: 0.8284\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5308 - accuracy: 0.7490 - val_loss: 0.6032 - val_accuracy: 0.8060\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5194 - accuracy: 0.7490 - val_loss: 0.6006 - val_accuracy: 0.8060\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.5156 - accuracy: 0.7570 - val_loss: 0.5997 - val_accuracy: 0.8060\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.5008 - accuracy: 0.7731 - val_loss: 0.5996 - val_accuracy: 0.7985\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 108us/step - loss: 0.4933 - accuracy: 0.7671 - val_loss: 0.5980 - val_accuracy: 0.8022\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.4955 - accuracy: 0.7731 - val_loss: 0.5954 - val_accuracy: 0.7985\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 110us/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.5949 - val_accuracy: 0.7948\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4943 - accuracy: 0.7610 - val_loss: 0.5927 - val_accuracy: 0.7910\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.4863 - accuracy: 0.7570 - val_loss: 0.5905 - val_accuracy: 0.7948\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4775 - accuracy: 0.7631 - val_loss: 0.5867 - val_accuracy: 0.7799\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4781 - accuracy: 0.7651 - val_loss: 0.5829 - val_accuracy: 0.7836\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.4655 - accuracy: 0.7892 - val_loss: 0.5779 - val_accuracy: 0.7910\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4667 - accuracy: 0.7811 - val_loss: 0.5723 - val_accuracy: 0.7948\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4652 - accuracy: 0.7831 - val_loss: 0.5678 - val_accuracy: 0.7985\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 106us/step - loss: 0.4660 - accuracy: 0.7771 - val_loss: 0.5639 - val_accuracy: 0.7985\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 114us/step - loss: 0.4592 - accuracy: 0.7952 - val_loss: 0.5599 - val_accuracy: 0.7985\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4471 - accuracy: 0.8133 - val_loss: 0.5548 - val_accuracy: 0.7985\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4507 - accuracy: 0.7972 - val_loss: 0.5497 - val_accuracy: 0.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4405 - accuracy: 0.8233 - val_loss: 0.5459 - val_accuracy: 0.8097\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4434 - accuracy: 0.8072 - val_loss: 0.5397 - val_accuracy: 0.8172\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4332 - accuracy: 0.8273 - val_loss: 0.5351 - val_accuracy: 0.8172\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.4408 - accuracy: 0.8173 - val_loss: 0.5302 - val_accuracy: 0.8172\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.4273 - accuracy: 0.8213 - val_loss: 0.5268 - val_accuracy: 0.8172\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.4293 - accuracy: 0.8233 - val_loss: 0.5228 - val_accuracy: 0.8172\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4200 - accuracy: 0.8333 - val_loss: 0.5190 - val_accuracy: 0.8209\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4287 - accuracy: 0.8153 - val_loss: 0.5160 - val_accuracy: 0.8246\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.4173 - accuracy: 0.8353 - val_loss: 0.5130 - val_accuracy: 0.8284\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 108us/step - loss: 0.4167 - accuracy: 0.8213 - val_loss: 0.5095 - val_accuracy: 0.8284\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4063 - accuracy: 0.8414 - val_loss: 0.5056 - val_accuracy: 0.8284\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4130 - accuracy: 0.8394 - val_loss: 0.5033 - val_accuracy: 0.8321\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4159 - accuracy: 0.8373 - val_loss: 0.5012 - val_accuracy: 0.8284\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4124 - accuracy: 0.8434 - val_loss: 0.4996 - val_accuracy: 0.8284\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4061 - accuracy: 0.8373 - val_loss: 0.4970 - val_accuracy: 0.8358\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4077 - accuracy: 0.8353 - val_loss: 0.4949 - val_accuracy: 0.8358\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4064 - accuracy: 0.8434 - val_loss: 0.4924 - val_accuracy: 0.8433\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4084 - accuracy: 0.8373 - val_loss: 0.4897 - val_accuracy: 0.8433\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4062 - accuracy: 0.8414 - val_loss: 0.4873 - val_accuracy: 0.8396\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4023 - accuracy: 0.8353 - val_loss: 0.4850 - val_accuracy: 0.8396\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4017 - accuracy: 0.8414 - val_loss: 0.4833 - val_accuracy: 0.8396\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4050 - accuracy: 0.8293 - val_loss: 0.4811 - val_accuracy: 0.8396\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3958 - accuracy: 0.8474 - val_loss: 0.4793 - val_accuracy: 0.8321\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4053 - accuracy: 0.8313 - val_loss: 0.4771 - val_accuracy: 0.8321\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4065 - accuracy: 0.8313 - val_loss: 0.4748 - val_accuracy: 0.8321\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3955 - accuracy: 0.8434 - val_loss: 0.4730 - val_accuracy: 0.8396\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3971 - accuracy: 0.8434 - val_loss: 0.4714 - val_accuracy: 0.8321\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3953 - accuracy: 0.8434 - val_loss: 0.4697 - val_accuracy: 0.8321\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 106us/step - loss: 0.3897 - accuracy: 0.8373 - val_loss: 0.4679 - val_accuracy: 0.8358\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3930 - accuracy: 0.8373 - val_loss: 0.4668 - val_accuracy: 0.8358\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3859 - accuracy: 0.8514 - val_loss: 0.4648 - val_accuracy: 0.8358\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3890 - accuracy: 0.8434 - val_loss: 0.4643 - val_accuracy: 0.8358\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3934 - accuracy: 0.8414 - val_loss: 0.4640 - val_accuracy: 0.8321\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3828 - accuracy: 0.8554 - val_loss: 0.4636 - val_accuracy: 0.8321\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3858 - accuracy: 0.8454 - val_loss: 0.4632 - val_accuracy: 0.8321\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3972 - accuracy: 0.8333 - val_loss: 0.4622 - val_accuracy: 0.8321\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3780 - accuracy: 0.8574 - val_loss: 0.4618 - val_accuracy: 0.8321\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.3793 - accuracy: 0.8414 - val_loss: 0.4611 - val_accuracy: 0.8321\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3799 - accuracy: 0.8514 - val_loss: 0.4599 - val_accuracy: 0.8321\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3817 - accuracy: 0.8353 - val_loss: 0.4589 - val_accuracy: 0.8358\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3799 - accuracy: 0.8373 - val_loss: 0.4581 - val_accuracy: 0.8358\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3825 - accuracy: 0.8554 - val_loss: 0.4574 - val_accuracy: 0.8470\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3773 - accuracy: 0.8494 - val_loss: 0.4566 - val_accuracy: 0.8470\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3809 - accuracy: 0.8414 - val_loss: 0.4566 - val_accuracy: 0.8433\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3865 - accuracy: 0.8333 - val_loss: 0.4548 - val_accuracy: 0.8507\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3711 - accuracy: 0.8494 - val_loss: 0.4542 - val_accuracy: 0.8470\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3650 - accuracy: 0.8675 - val_loss: 0.4544 - val_accuracy: 0.8470\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3805 - accuracy: 0.8414 - val_loss: 0.4534 - val_accuracy: 0.8433\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3776 - accuracy: 0.8574 - val_loss: 0.4531 - val_accuracy: 0.8433\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3813 - accuracy: 0.8574 - val_loss: 0.4528 - val_accuracy: 0.8433\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.3683 - accuracy: 0.8594 - val_loss: 0.4535 - val_accuracy: 0.8433\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3739 - accuracy: 0.8534 - val_loss: 0.4553 - val_accuracy: 0.8433\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3666 - accuracy: 0.8635 - val_loss: 0.4568 - val_accuracy: 0.8396\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3710 - accuracy: 0.8494 - val_loss: 0.4575 - val_accuracy: 0.8433\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3650 - accuracy: 0.8574 - val_loss: 0.4564 - val_accuracy: 0.8396\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3704 - accuracy: 0.8675 - val_loss: 0.4559 - val_accuracy: 0.8433\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3661 - accuracy: 0.8534 - val_loss: 0.4559 - val_accuracy: 0.8470\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3595 - accuracy: 0.8755 - val_loss: 0.4551 - val_accuracy: 0.8433\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3626 - accuracy: 0.8635 - val_loss: 0.4557 - val_accuracy: 0.8396\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3751 - accuracy: 0.8514 - val_loss: 0.4561 - val_accuracy: 0.8358\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3614 - accuracy: 0.8574 - val_loss: 0.4573 - val_accuracy: 0.8321\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3605 - accuracy: 0.8514 - val_loss: 0.4591 - val_accuracy: 0.8284\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3606 - accuracy: 0.8574 - val_loss: 0.4595 - val_accuracy: 0.8284\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3671 - accuracy: 0.8594 - val_loss: 0.4590 - val_accuracy: 0.8284\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 1s 1ms/step - loss: 0.7021 - accuracy: 0.5872 - val_loss: 0.7181 - val_accuracy: 0.6343\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.6565 - accuracy: 0.6493 - val_loss: 0.7146 - val_accuracy: 0.6754\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.6376 - accuracy: 0.6733 - val_loss: 0.7107 - val_accuracy: 0.6567\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.5880 - accuracy: 0.7094 - val_loss: 0.7068 - val_accuracy: 0.6455\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.5673 - accuracy: 0.7275 - val_loss: 0.7032 - val_accuracy: 0.6418\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.5530 - accuracy: 0.7555 - val_loss: 0.6994 - val_accuracy: 0.6530\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.5379 - accuracy: 0.7595 - val_loss: 0.6956 - val_accuracy: 0.6493\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.5276 - accuracy: 0.7735 - val_loss: 0.6921 - val_accuracy: 0.6418\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.5150 - accuracy: 0.7735 - val_loss: 0.6889 - val_accuracy: 0.6381\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.5072 - accuracy: 0.7876 - val_loss: 0.6862 - val_accuracy: 0.6381\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.5018 - accuracy: 0.7776 - val_loss: 0.6833 - val_accuracy: 0.6493\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4943 - accuracy: 0.7756 - val_loss: 0.6805 - val_accuracy: 0.6493\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4968 - accuracy: 0.7816 - val_loss: 0.6777 - val_accuracy: 0.6493\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4817 - accuracy: 0.7796 - val_loss: 0.6752 - val_accuracy: 0.6567\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4784 - accuracy: 0.7876 - val_loss: 0.6726 - val_accuracy: 0.6530\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4734 - accuracy: 0.7936 - val_loss: 0.6700 - val_accuracy: 0.6567\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4735 - accuracy: 0.7916 - val_loss: 0.6672 - val_accuracy: 0.6604\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4678 - accuracy: 0.7916 - val_loss: 0.6646 - val_accuracy: 0.6604\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4616 - accuracy: 0.7976 - val_loss: 0.6617 - val_accuracy: 0.6604\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4527 - accuracy: 0.8016 - val_loss: 0.6584 - val_accuracy: 0.6604\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4530 - accuracy: 0.7976 - val_loss: 0.6551 - val_accuracy: 0.6530\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4464 - accuracy: 0.8056 - val_loss: 0.6514 - val_accuracy: 0.6567\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4451 - accuracy: 0.7996 - val_loss: 0.6477 - val_accuracy: 0.6567\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4421 - accuracy: 0.8036 - val_loss: 0.6441 - val_accuracy: 0.6567\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4357 - accuracy: 0.8156 - val_loss: 0.6405 - val_accuracy: 0.6567\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4401 - accuracy: 0.7936 - val_loss: 0.6368 - val_accuracy: 0.6604\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4348 - accuracy: 0.8136 - val_loss: 0.6333 - val_accuracy: 0.6530\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4292 - accuracy: 0.8156 - val_loss: 0.6299 - val_accuracy: 0.6642\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4279 - accuracy: 0.8257 - val_loss: 0.6270 - val_accuracy: 0.6642\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4361 - accuracy: 0.8196 - val_loss: 0.6240 - val_accuracy: 0.6604\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4293 - accuracy: 0.8176 - val_loss: 0.6211 - val_accuracy: 0.6604\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4238 - accuracy: 0.8236 - val_loss: 0.6181 - val_accuracy: 0.6642\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4117 - accuracy: 0.8317 - val_loss: 0.6149 - val_accuracy: 0.6642\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4240 - accuracy: 0.8116 - val_loss: 0.6119 - val_accuracy: 0.6642\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4080 - accuracy: 0.8337 - val_loss: 0.6082 - val_accuracy: 0.6642\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4082 - accuracy: 0.8216 - val_loss: 0.6047 - val_accuracy: 0.6754\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4069 - accuracy: 0.8297 - val_loss: 0.6015 - val_accuracy: 0.6828\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4057 - accuracy: 0.8317 - val_loss: 0.5983 - val_accuracy: 0.6866\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4171 - accuracy: 0.8036 - val_loss: 0.5963 - val_accuracy: 0.6866\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3960 - accuracy: 0.8317 - val_loss: 0.5934 - val_accuracy: 0.6866\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3968 - accuracy: 0.8277 - val_loss: 0.5911 - val_accuracy: 0.6903\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.4056 - accuracy: 0.8216 - val_loss: 0.5884 - val_accuracy: 0.6978\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3964 - accuracy: 0.8297 - val_loss: 0.5855 - val_accuracy: 0.6978\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3976 - accuracy: 0.8397 - val_loss: 0.5831 - val_accuracy: 0.7015\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3839 - accuracy: 0.8257 - val_loss: 0.5809 - val_accuracy: 0.7052\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3917 - accuracy: 0.8337 - val_loss: 0.5782 - val_accuracy: 0.7164\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3809 - accuracy: 0.8357 - val_loss: 0.5750 - val_accuracy: 0.7239\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3924 - accuracy: 0.8377 - val_loss: 0.5727 - val_accuracy: 0.7276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3925 - accuracy: 0.8377 - val_loss: 0.5700 - val_accuracy: 0.7313\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3787 - accuracy: 0.8437 - val_loss: 0.5688 - val_accuracy: 0.7313\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3849 - accuracy: 0.8297 - val_loss: 0.5680 - val_accuracy: 0.7276\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3761 - accuracy: 0.8257 - val_loss: 0.5675 - val_accuracy: 0.7276\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3749 - accuracy: 0.8437 - val_loss: 0.5671 - val_accuracy: 0.7201\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3703 - accuracy: 0.8417 - val_loss: 0.5654 - val_accuracy: 0.7127\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3761 - accuracy: 0.8537 - val_loss: 0.5611 - val_accuracy: 0.7164\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3763 - accuracy: 0.8337 - val_loss: 0.5589 - val_accuracy: 0.7164\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3720 - accuracy: 0.8377 - val_loss: 0.5548 - val_accuracy: 0.7351\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3751 - accuracy: 0.8497 - val_loss: 0.5522 - val_accuracy: 0.7313\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3778 - accuracy: 0.8357 - val_loss: 0.5498 - val_accuracy: 0.7351\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3649 - accuracy: 0.8477 - val_loss: 0.5466 - val_accuracy: 0.7276\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3646 - accuracy: 0.8397 - val_loss: 0.5438 - val_accuracy: 0.7276\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3760 - accuracy: 0.8497 - val_loss: 0.5391 - val_accuracy: 0.7388\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3621 - accuracy: 0.8457 - val_loss: 0.5349 - val_accuracy: 0.7463\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3642 - accuracy: 0.8497 - val_loss: 0.5313 - val_accuracy: 0.7612\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3558 - accuracy: 0.8437 - val_loss: 0.5283 - val_accuracy: 0.7649\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3715 - accuracy: 0.8317 - val_loss: 0.5264 - val_accuracy: 0.7612\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3554 - accuracy: 0.8597 - val_loss: 0.5255 - val_accuracy: 0.7612\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3678 - accuracy: 0.8517 - val_loss: 0.5251 - val_accuracy: 0.7463\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 104us/step - loss: 0.3619 - accuracy: 0.8497 - val_loss: 0.5251 - val_accuracy: 0.7537\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 108us/step - loss: 0.3564 - accuracy: 0.8657 - val_loss: 0.5258 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 104us/step - loss: 0.3453 - accuracy: 0.8597 - val_loss: 0.5257 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3500 - accuracy: 0.8557 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 104us/step - loss: 0.3510 - accuracy: 0.8597 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3493 - accuracy: 0.8657 - val_loss: 0.5246 - val_accuracy: 0.7463\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3479 - accuracy: 0.8577 - val_loss: 0.5245 - val_accuracy: 0.7463\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3407 - accuracy: 0.8637 - val_loss: 0.5239 - val_accuracy: 0.7463\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3426 - accuracy: 0.8477 - val_loss: 0.5233 - val_accuracy: 0.7463\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3504 - accuracy: 0.8637 - val_loss: 0.5218 - val_accuracy: 0.7463\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 104us/step - loss: 0.3505 - accuracy: 0.8597 - val_loss: 0.5183 - val_accuracy: 0.7463\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3642 - accuracy: 0.8417 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3483 - accuracy: 0.8597 - val_loss: 0.5140 - val_accuracy: 0.7537\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3403 - accuracy: 0.8677 - val_loss: 0.5134 - val_accuracy: 0.7575\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3367 - accuracy: 0.8697 - val_loss: 0.5124 - val_accuracy: 0.7612\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3345 - accuracy: 0.8838 - val_loss: 0.5126 - val_accuracy: 0.7612\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3529 - accuracy: 0.8637 - val_loss: 0.5109 - val_accuracy: 0.7612\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3482 - accuracy: 0.8778 - val_loss: 0.5071 - val_accuracy: 0.7612\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3348 - accuracy: 0.8858 - val_loss: 0.5039 - val_accuracy: 0.7575\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3298 - accuracy: 0.8637 - val_loss: 0.5012 - val_accuracy: 0.7612\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3403 - accuracy: 0.8597 - val_loss: 0.4980 - val_accuracy: 0.7724\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3341 - accuracy: 0.8798 - val_loss: 0.4956 - val_accuracy: 0.7799\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3273 - accuracy: 0.8838 - val_loss: 0.4928 - val_accuracy: 0.7836\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3320 - accuracy: 0.8737 - val_loss: 0.4900 - val_accuracy: 0.7873\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3298 - accuracy: 0.8758 - val_loss: 0.4913 - val_accuracy: 0.7799\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3229 - accuracy: 0.8818 - val_loss: 0.4930 - val_accuracy: 0.7724\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3371 - accuracy: 0.8697 - val_loss: 0.4955 - val_accuracy: 0.7649\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3278 - accuracy: 0.8898 - val_loss: 0.5007 - val_accuracy: 0.7687\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3382 - accuracy: 0.8637 - val_loss: 0.5040 - val_accuracy: 0.7687\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3263 - accuracy: 0.8778 - val_loss: 0.5065 - val_accuracy: 0.7724\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3258 - accuracy: 0.8778 - val_loss: 0.5064 - val_accuracy: 0.7687\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3297 - accuracy: 0.8657 - val_loss: 0.5058 - val_accuracy: 0.7724\n",
      "124/124 [==============================] - 0s 16us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 1s 1ms/step - loss: 0.7726 - accuracy: 0.5411 - val_loss: 0.7380 - val_accuracy: 0.4664\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 104us/step - loss: 0.7160 - accuracy: 0.5872 - val_loss: 0.7347 - val_accuracy: 0.4739\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.6850 - accuracy: 0.6934 - val_loss: 0.7312 - val_accuracy: 0.4963\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.6555 - accuracy: 0.7375 - val_loss: 0.7275 - val_accuracy: 0.5075\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.6222 - accuracy: 0.7715 - val_loss: 0.7235 - val_accuracy: 0.5037\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5942 - accuracy: 0.7756 - val_loss: 0.7189 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.5707 - accuracy: 0.7896 - val_loss: 0.7139 - val_accuracy: 0.6381\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.5514 - accuracy: 0.7976 - val_loss: 0.7088 - val_accuracy: 0.6381\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.5346 - accuracy: 0.8116 - val_loss: 0.7044 - val_accuracy: 0.6493\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.5152 - accuracy: 0.8136 - val_loss: 0.7009 - val_accuracy: 0.6716\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.5040 - accuracy: 0.8236 - val_loss: 0.6978 - val_accuracy: 0.6791\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4925 - accuracy: 0.8116 - val_loss: 0.6943 - val_accuracy: 0.6866\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4694 - accuracy: 0.8417 - val_loss: 0.6902 - val_accuracy: 0.6866\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4760 - accuracy: 0.8196 - val_loss: 0.6861 - val_accuracy: 0.6828\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4612 - accuracy: 0.8216 - val_loss: 0.6809 - val_accuracy: 0.6866\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4521 - accuracy: 0.8337 - val_loss: 0.6750 - val_accuracy: 0.6866\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4496 - accuracy: 0.8317 - val_loss: 0.6687 - val_accuracy: 0.6940\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4420 - accuracy: 0.8397 - val_loss: 0.6621 - val_accuracy: 0.7015\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4365 - accuracy: 0.8317 - val_loss: 0.6561 - val_accuracy: 0.6940\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4298 - accuracy: 0.8457 - val_loss: 0.6500 - val_accuracy: 0.6940\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4283 - accuracy: 0.8337 - val_loss: 0.6430 - val_accuracy: 0.6940\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4267 - accuracy: 0.8397 - val_loss: 0.6378 - val_accuracy: 0.6903\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4232 - accuracy: 0.8257 - val_loss: 0.6316 - val_accuracy: 0.6903\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4152 - accuracy: 0.8357 - val_loss: 0.6251 - val_accuracy: 0.6940\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.4266 - accuracy: 0.8277 - val_loss: 0.6192 - val_accuracy: 0.6978\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4184 - accuracy: 0.8377 - val_loss: 0.6125 - val_accuracy: 0.6978\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4173 - accuracy: 0.8337 - val_loss: 0.6067 - val_accuracy: 0.7015\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4112 - accuracy: 0.8397 - val_loss: 0.6017 - val_accuracy: 0.6978\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4005 - accuracy: 0.8457 - val_loss: 0.5968 - val_accuracy: 0.6978\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3996 - accuracy: 0.8477 - val_loss: 0.5920 - val_accuracy: 0.7052\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3965 - accuracy: 0.8517 - val_loss: 0.5881 - val_accuracy: 0.7052\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 99us/step - loss: 0.3928 - accuracy: 0.8517 - val_loss: 0.5836 - val_accuracy: 0.7164\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3951 - accuracy: 0.8497 - val_loss: 0.5801 - val_accuracy: 0.7201\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4013 - accuracy: 0.8517 - val_loss: 0.5757 - val_accuracy: 0.7276\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3974 - accuracy: 0.8537 - val_loss: 0.5710 - val_accuracy: 0.7276\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3915 - accuracy: 0.8437 - val_loss: 0.5653 - val_accuracy: 0.7276\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3877 - accuracy: 0.8597 - val_loss: 0.5599 - val_accuracy: 0.7351\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3815 - accuracy: 0.8617 - val_loss: 0.5560 - val_accuracy: 0.7351\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3841 - accuracy: 0.8517 - val_loss: 0.5513 - val_accuracy: 0.7351\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3822 - accuracy: 0.8497 - val_loss: 0.5460 - val_accuracy: 0.7388\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3841 - accuracy: 0.8557 - val_loss: 0.5416 - val_accuracy: 0.7388\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.4002 - accuracy: 0.8397 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3802 - accuracy: 0.8557 - val_loss: 0.5322 - val_accuracy: 0.7463\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3731 - accuracy: 0.8517 - val_loss: 0.5289 - val_accuracy: 0.7537\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3776 - accuracy: 0.8537 - val_loss: 0.5248 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3843 - accuracy: 0.8617 - val_loss: 0.5217 - val_accuracy: 0.7575\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3786 - accuracy: 0.8517 - val_loss: 0.5191 - val_accuracy: 0.7575\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3822 - accuracy: 0.8517 - val_loss: 0.5174 - val_accuracy: 0.7575\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3754 - accuracy: 0.8557 - val_loss: 0.5142 - val_accuracy: 0.7649\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3768 - accuracy: 0.8517 - val_loss: 0.5097 - val_accuracy: 0.7724\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3759 - accuracy: 0.8517 - val_loss: 0.5067 - val_accuracy: 0.7873\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3662 - accuracy: 0.8597 - val_loss: 0.5051 - val_accuracy: 0.7873\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3718 - accuracy: 0.8597 - val_loss: 0.5033 - val_accuracy: 0.7873\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3596 - accuracy: 0.8637 - val_loss: 0.5024 - val_accuracy: 0.7836\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3674 - accuracy: 0.8557 - val_loss: 0.5010 - val_accuracy: 0.7836\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3638 - accuracy: 0.8717 - val_loss: 0.5011 - val_accuracy: 0.7836\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3655 - accuracy: 0.8677 - val_loss: 0.5010 - val_accuracy: 0.7836\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3633 - accuracy: 0.8597 - val_loss: 0.5002 - val_accuracy: 0.7799\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3586 - accuracy: 0.8717 - val_loss: 0.4999 - val_accuracy: 0.7799\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499/499 [==============================] - 0s 96us/step - loss: 0.3654 - accuracy: 0.8537 - val_loss: 0.5006 - val_accuracy: 0.7761\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3639 - accuracy: 0.8557 - val_loss: 0.4995 - val_accuracy: 0.7761\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3565 - accuracy: 0.8577 - val_loss: 0.4985 - val_accuracy: 0.7836\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3638 - accuracy: 0.8617 - val_loss: 0.4970 - val_accuracy: 0.7836\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3592 - accuracy: 0.8657 - val_loss: 0.4944 - val_accuracy: 0.7873\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3667 - accuracy: 0.8577 - val_loss: 0.4925 - val_accuracy: 0.7910\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3590 - accuracy: 0.8637 - val_loss: 0.4920 - val_accuracy: 0.7910\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 106us/step - loss: 0.3552 - accuracy: 0.8637 - val_loss: 0.4920 - val_accuracy: 0.7910\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3560 - accuracy: 0.8798 - val_loss: 0.4912 - val_accuracy: 0.7985\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3492 - accuracy: 0.8717 - val_loss: 0.4900 - val_accuracy: 0.7985\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3525 - accuracy: 0.8637 - val_loss: 0.4890 - val_accuracy: 0.7948\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3527 - accuracy: 0.8697 - val_loss: 0.4879 - val_accuracy: 0.7948\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3483 - accuracy: 0.8697 - val_loss: 0.4878 - val_accuracy: 0.7948\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 101us/step - loss: 0.3479 - accuracy: 0.8617 - val_loss: 0.4879 - val_accuracy: 0.7948\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3459 - accuracy: 0.8677 - val_loss: 0.4891 - val_accuracy: 0.7948\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3445 - accuracy: 0.8717 - val_loss: 0.4913 - val_accuracy: 0.7873\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3452 - accuracy: 0.8697 - val_loss: 0.4934 - val_accuracy: 0.7873\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3562 - accuracy: 0.8717 - val_loss: 0.4930 - val_accuracy: 0.7873\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3450 - accuracy: 0.8657 - val_loss: 0.4931 - val_accuracy: 0.7873\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3492 - accuracy: 0.8677 - val_loss: 0.4922 - val_accuracy: 0.7910\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3469 - accuracy: 0.8677 - val_loss: 0.4914 - val_accuracy: 0.7948\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3444 - accuracy: 0.8737 - val_loss: 0.4899 - val_accuracy: 0.7948\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3448 - accuracy: 0.8657 - val_loss: 0.4885 - val_accuracy: 0.7948\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 122us/step - loss: 0.3383 - accuracy: 0.8758 - val_loss: 0.4864 - val_accuracy: 0.7948\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3447 - accuracy: 0.8697 - val_loss: 0.4857 - val_accuracy: 0.7948\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3535 - accuracy: 0.8758 - val_loss: 0.4860 - val_accuracy: 0.7948\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3504 - accuracy: 0.8657 - val_loss: 0.4837 - val_accuracy: 0.7948\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 118us/step - loss: 0.3417 - accuracy: 0.8737 - val_loss: 0.4823 - val_accuracy: 0.7948\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 118us/step - loss: 0.3514 - accuracy: 0.8717 - val_loss: 0.4801 - val_accuracy: 0.7948\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 114us/step - loss: 0.3584 - accuracy: 0.8617 - val_loss: 0.4779 - val_accuracy: 0.7910\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 116us/step - loss: 0.3430 - accuracy: 0.8758 - val_loss: 0.4782 - val_accuracy: 0.7948\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 114us/step - loss: 0.3480 - accuracy: 0.8697 - val_loss: 0.4765 - val_accuracy: 0.7873\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 110us/step - loss: 0.3412 - accuracy: 0.8717 - val_loss: 0.4774 - val_accuracy: 0.7910\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3403 - accuracy: 0.8717 - val_loss: 0.4778 - val_accuracy: 0.7910\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3440 - accuracy: 0.8778 - val_loss: 0.4787 - val_accuracy: 0.7910\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3448 - accuracy: 0.8657 - val_loss: 0.4780 - val_accuracy: 0.7948\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3441 - accuracy: 0.8778 - val_loss: 0.4777 - val_accuracy: 0.7985\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3414 - accuracy: 0.8657 - val_loss: 0.4788 - val_accuracy: 0.7948\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 104us/step - loss: 0.3365 - accuracy: 0.8778 - val_loss: 0.4773 - val_accuracy: 0.7948\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3380 - accuracy: 0.8717 - val_loss: 0.4769 - val_accuracy: 0.7948\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3391 - accuracy: 0.8717 - val_loss: 0.4756 - val_accuracy: 0.7948\n",
      "124/124 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 0.8598 - accuracy: 0.5763 - val_loss: 0.8613 - val_accuracy: 0.3881\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.7873 - accuracy: 0.6165 - val_loss: 0.8538 - val_accuracy: 0.3881\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.7562 - accuracy: 0.6044 - val_loss: 0.8463 - val_accuracy: 0.3881\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.7057 - accuracy: 0.6365 - val_loss: 0.8394 - val_accuracy: 0.3955\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.6417 - accuracy: 0.6807 - val_loss: 0.8319 - val_accuracy: 0.3955\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.6385 - accuracy: 0.6928 - val_loss: 0.8238 - val_accuracy: 0.4030\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.6178 - accuracy: 0.7169 - val_loss: 0.8148 - val_accuracy: 0.4030\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5955 - accuracy: 0.7048 - val_loss: 0.8049 - val_accuracy: 0.4179\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.5805 - accuracy: 0.7410 - val_loss: 0.7949 - val_accuracy: 0.4104\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.5570 - accuracy: 0.7530 - val_loss: 0.7851 - val_accuracy: 0.4254\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5360 - accuracy: 0.7570 - val_loss: 0.7754 - val_accuracy: 0.4403\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5357 - accuracy: 0.7691 - val_loss: 0.7652 - val_accuracy: 0.4254\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5184 - accuracy: 0.7731 - val_loss: 0.7543 - val_accuracy: 0.4254\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5062 - accuracy: 0.7811 - val_loss: 0.7438 - val_accuracy: 0.4478\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5042 - accuracy: 0.7771 - val_loss: 0.7345 - val_accuracy: 0.4590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4796 - accuracy: 0.8012 - val_loss: 0.7254 - val_accuracy: 0.4590\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4997 - accuracy: 0.7992 - val_loss: 0.7159 - val_accuracy: 0.4701\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4865 - accuracy: 0.8032 - val_loss: 0.7060 - val_accuracy: 0.4925\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4829 - accuracy: 0.7932 - val_loss: 0.6952 - val_accuracy: 0.5448\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4571 - accuracy: 0.8112 - val_loss: 0.6852 - val_accuracy: 0.5821\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4613 - accuracy: 0.8092 - val_loss: 0.6754 - val_accuracy: 0.6381\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4684 - accuracy: 0.8112 - val_loss: 0.6659 - val_accuracy: 0.6791\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4467 - accuracy: 0.8253 - val_loss: 0.6564 - val_accuracy: 0.7052\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4481 - accuracy: 0.8213 - val_loss: 0.6471 - val_accuracy: 0.7164\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4325 - accuracy: 0.8494 - val_loss: 0.6377 - val_accuracy: 0.7276\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4480 - accuracy: 0.8313 - val_loss: 0.6283 - val_accuracy: 0.7313\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.4337 - accuracy: 0.8293 - val_loss: 0.6193 - val_accuracy: 0.7463\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4431 - accuracy: 0.8052 - val_loss: 0.6098 - val_accuracy: 0.7575\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4272 - accuracy: 0.8394 - val_loss: 0.6006 - val_accuracy: 0.7724\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4278 - accuracy: 0.8333 - val_loss: 0.5924 - val_accuracy: 0.7910\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4277 - accuracy: 0.8233 - val_loss: 0.5847 - val_accuracy: 0.7948\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4270 - accuracy: 0.8333 - val_loss: 0.5775 - val_accuracy: 0.7985\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4191 - accuracy: 0.8414 - val_loss: 0.5714 - val_accuracy: 0.8022\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4150 - accuracy: 0.8333 - val_loss: 0.5662 - val_accuracy: 0.7985\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4195 - accuracy: 0.8373 - val_loss: 0.5609 - val_accuracy: 0.7873\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4120 - accuracy: 0.8333 - val_loss: 0.5563 - val_accuracy: 0.7948\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4142 - accuracy: 0.8313 - val_loss: 0.5517 - val_accuracy: 0.7910\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4056 - accuracy: 0.8434 - val_loss: 0.5482 - val_accuracy: 0.7948\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3987 - accuracy: 0.8434 - val_loss: 0.5446 - val_accuracy: 0.7948\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4123 - accuracy: 0.8293 - val_loss: 0.5414 - val_accuracy: 0.7948\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3974 - accuracy: 0.8454 - val_loss: 0.5388 - val_accuracy: 0.7873\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3987 - accuracy: 0.8614 - val_loss: 0.5365 - val_accuracy: 0.7873\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3994 - accuracy: 0.8574 - val_loss: 0.5341 - val_accuracy: 0.7873\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.4030 - accuracy: 0.8414 - val_loss: 0.5313 - val_accuracy: 0.7910\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3942 - accuracy: 0.8574 - val_loss: 0.5291 - val_accuracy: 0.7948\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3873 - accuracy: 0.8635 - val_loss: 0.5267 - val_accuracy: 0.8022\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4040 - accuracy: 0.8534 - val_loss: 0.5241 - val_accuracy: 0.8022\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3950 - accuracy: 0.8474 - val_loss: 0.5217 - val_accuracy: 0.7910\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3867 - accuracy: 0.8594 - val_loss: 0.5189 - val_accuracy: 0.8022\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3905 - accuracy: 0.8474 - val_loss: 0.5162 - val_accuracy: 0.8060\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3745 - accuracy: 0.8594 - val_loss: 0.5142 - val_accuracy: 0.8022\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4022 - accuracy: 0.8474 - val_loss: 0.5124 - val_accuracy: 0.8022\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3979 - accuracy: 0.8353 - val_loss: 0.5105 - val_accuracy: 0.8097\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3876 - accuracy: 0.8494 - val_loss: 0.5098 - val_accuracy: 0.8134\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3857 - accuracy: 0.8514 - val_loss: 0.5085 - val_accuracy: 0.8134\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3822 - accuracy: 0.8494 - val_loss: 0.5069 - val_accuracy: 0.8134\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3742 - accuracy: 0.8454 - val_loss: 0.5049 - val_accuracy: 0.8134\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3840 - accuracy: 0.8554 - val_loss: 0.5028 - val_accuracy: 0.8134\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3818 - accuracy: 0.8494 - val_loss: 0.5007 - val_accuracy: 0.8134\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3784 - accuracy: 0.8594 - val_loss: 0.4988 - val_accuracy: 0.8097\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3717 - accuracy: 0.8554 - val_loss: 0.4971 - val_accuracy: 0.8097\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3759 - accuracy: 0.8554 - val_loss: 0.4953 - val_accuracy: 0.8097\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3623 - accuracy: 0.8715 - val_loss: 0.4933 - val_accuracy: 0.8097\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3670 - accuracy: 0.8594 - val_loss: 0.4919 - val_accuracy: 0.8172\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3678 - accuracy: 0.8675 - val_loss: 0.4905 - val_accuracy: 0.8209\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3641 - accuracy: 0.8574 - val_loss: 0.4896 - val_accuracy: 0.8246\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3644 - accuracy: 0.8614 - val_loss: 0.4889 - val_accuracy: 0.8246\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3641 - accuracy: 0.8675 - val_loss: 0.4881 - val_accuracy: 0.8246\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3586 - accuracy: 0.8675 - val_loss: 0.4876 - val_accuracy: 0.8246\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3664 - accuracy: 0.8635 - val_loss: 0.4868 - val_accuracy: 0.8246\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3555 - accuracy: 0.8554 - val_loss: 0.4859 - val_accuracy: 0.8321\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3698 - accuracy: 0.8655 - val_loss: 0.4851 - val_accuracy: 0.8246\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3621 - accuracy: 0.8695 - val_loss: 0.4849 - val_accuracy: 0.8246\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3519 - accuracy: 0.8675 - val_loss: 0.4850 - val_accuracy: 0.8246\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3559 - accuracy: 0.8675 - val_loss: 0.4847 - val_accuracy: 0.8246\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3528 - accuracy: 0.8675 - val_loss: 0.4843 - val_accuracy: 0.8321\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3570 - accuracy: 0.8675 - val_loss: 0.4829 - val_accuracy: 0.8321\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 108us/step - loss: 0.3623 - accuracy: 0.8534 - val_loss: 0.4806 - val_accuracy: 0.8321\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.3660 - accuracy: 0.8594 - val_loss: 0.4806 - val_accuracy: 0.8321\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3556 - accuracy: 0.8614 - val_loss: 0.4801 - val_accuracy: 0.8321\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 108us/step - loss: 0.3501 - accuracy: 0.8735 - val_loss: 0.4806 - val_accuracy: 0.8321\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 106us/step - loss: 0.3563 - accuracy: 0.8695 - val_loss: 0.4798 - val_accuracy: 0.8321\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3475 - accuracy: 0.8695 - val_loss: 0.4784 - val_accuracy: 0.8396\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3519 - accuracy: 0.8655 - val_loss: 0.4765 - val_accuracy: 0.8396\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3501 - accuracy: 0.8795 - val_loss: 0.4762 - val_accuracy: 0.8396\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3513 - accuracy: 0.8715 - val_loss: 0.4755 - val_accuracy: 0.8433\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3501 - accuracy: 0.8695 - val_loss: 0.4751 - val_accuracy: 0.8396\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3380 - accuracy: 0.8815 - val_loss: 0.4745 - val_accuracy: 0.8433\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3430 - accuracy: 0.8755 - val_loss: 0.4725 - val_accuracy: 0.8396\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3531 - accuracy: 0.8594 - val_loss: 0.4730 - val_accuracy: 0.8433\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3452 - accuracy: 0.8695 - val_loss: 0.4739 - val_accuracy: 0.8396\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3382 - accuracy: 0.8815 - val_loss: 0.4742 - val_accuracy: 0.8433\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3441 - accuracy: 0.8775 - val_loss: 0.4735 - val_accuracy: 0.8396\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3442 - accuracy: 0.8815 - val_loss: 0.4743 - val_accuracy: 0.8321\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3516 - accuracy: 0.8635 - val_loss: 0.4732 - val_accuracy: 0.8321\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3456 - accuracy: 0.8855 - val_loss: 0.4721 - val_accuracy: 0.8321\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3411 - accuracy: 0.8735 - val_loss: 0.4711 - val_accuracy: 0.8396\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3382 - accuracy: 0.8775 - val_loss: 0.4700 - val_accuracy: 0.8358\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3564 - accuracy: 0.8735 - val_loss: 0.4742 - val_accuracy: 0.8321\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3376 - accuracy: 0.8755 - val_loss: 0.4772 - val_accuracy: 0.8284\n",
      "125/125 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 1.0085 - accuracy: 0.3414 - val_loss: 0.7195 - val_accuracy: 0.6082\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.9634 - accuracy: 0.3434 - val_loss: 0.7177 - val_accuracy: 0.6119\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.9156 - accuracy: 0.3574 - val_loss: 0.7159 - val_accuracy: 0.6119\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.8663 - accuracy: 0.3735 - val_loss: 0.7143 - val_accuracy: 0.6119\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.8291 - accuracy: 0.3976 - val_loss: 0.7129 - val_accuracy: 0.6119\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.7897 - accuracy: 0.4237 - val_loss: 0.7115 - val_accuracy: 0.6119\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.7603 - accuracy: 0.4578 - val_loss: 0.7102 - val_accuracy: 0.6119\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.7295 - accuracy: 0.5341 - val_loss: 0.7090 - val_accuracy: 0.6119\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.7011 - accuracy: 0.6185 - val_loss: 0.7075 - val_accuracy: 0.6119\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6836 - accuracy: 0.6546 - val_loss: 0.7061 - val_accuracy: 0.6119\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.6589 - accuracy: 0.7008 - val_loss: 0.7047 - val_accuracy: 0.6119\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.6473 - accuracy: 0.7129 - val_loss: 0.7035 - val_accuracy: 0.6119\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6274 - accuracy: 0.7169 - val_loss: 0.7024 - val_accuracy: 0.6119\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.6118 - accuracy: 0.7430 - val_loss: 0.7013 - val_accuracy: 0.6119\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.6047 - accuracy: 0.7430 - val_loss: 0.7002 - val_accuracy: 0.6119\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5871 - accuracy: 0.7570 - val_loss: 0.6989 - val_accuracy: 0.6082\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5811 - accuracy: 0.7570 - val_loss: 0.6970 - val_accuracy: 0.6119\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5649 - accuracy: 0.7671 - val_loss: 0.6945 - val_accuracy: 0.6119\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5547 - accuracy: 0.7831 - val_loss: 0.6918 - val_accuracy: 0.6119\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5473 - accuracy: 0.7751 - val_loss: 0.6887 - val_accuracy: 0.6157\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5461 - accuracy: 0.7691 - val_loss: 0.6854 - val_accuracy: 0.6194\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5334 - accuracy: 0.7811 - val_loss: 0.6820 - val_accuracy: 0.6231\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5212 - accuracy: 0.7831 - val_loss: 0.6783 - val_accuracy: 0.6269\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5105 - accuracy: 0.7932 - val_loss: 0.6743 - val_accuracy: 0.6343\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5043 - accuracy: 0.7992 - val_loss: 0.6701 - val_accuracy: 0.6455\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4987 - accuracy: 0.8032 - val_loss: 0.6657 - val_accuracy: 0.6493\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5003 - accuracy: 0.7992 - val_loss: 0.6615 - val_accuracy: 0.6642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4928 - accuracy: 0.7952 - val_loss: 0.6574 - val_accuracy: 0.6716\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4770 - accuracy: 0.8092 - val_loss: 0.6530 - val_accuracy: 0.6754\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4721 - accuracy: 0.8333 - val_loss: 0.6487 - val_accuracy: 0.6866\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4629 - accuracy: 0.8313 - val_loss: 0.6445 - val_accuracy: 0.6903\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4573 - accuracy: 0.8454 - val_loss: 0.6402 - val_accuracy: 0.6978\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4584 - accuracy: 0.8253 - val_loss: 0.6361 - val_accuracy: 0.7015\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4446 - accuracy: 0.8373 - val_loss: 0.6317 - val_accuracy: 0.7052\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4437 - accuracy: 0.8293 - val_loss: 0.6274 - val_accuracy: 0.7164\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 108us/step - loss: 0.4359 - accuracy: 0.8454 - val_loss: 0.6231 - val_accuracy: 0.7201\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4315 - accuracy: 0.8454 - val_loss: 0.6185 - val_accuracy: 0.7201\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.4277 - accuracy: 0.8474 - val_loss: 0.6146 - val_accuracy: 0.7201\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4201 - accuracy: 0.8554 - val_loss: 0.6104 - val_accuracy: 0.7239\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4187 - accuracy: 0.8574 - val_loss: 0.6059 - val_accuracy: 0.7239\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4126 - accuracy: 0.8594 - val_loss: 0.6012 - val_accuracy: 0.7276\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4117 - accuracy: 0.8594 - val_loss: 0.5970 - val_accuracy: 0.7313\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4166 - accuracy: 0.8534 - val_loss: 0.5933 - val_accuracy: 0.7351\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4034 - accuracy: 0.8635 - val_loss: 0.5895 - val_accuracy: 0.7388\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4003 - accuracy: 0.8655 - val_loss: 0.5858 - val_accuracy: 0.7425\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3973 - accuracy: 0.8594 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3879 - accuracy: 0.8715 - val_loss: 0.5783 - val_accuracy: 0.7649\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3870 - accuracy: 0.8635 - val_loss: 0.5755 - val_accuracy: 0.7687\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3921 - accuracy: 0.8635 - val_loss: 0.5721 - val_accuracy: 0.7724\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.3909 - accuracy: 0.8635 - val_loss: 0.5689 - val_accuracy: 0.7761\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3795 - accuracy: 0.8614 - val_loss: 0.5662 - val_accuracy: 0.7799\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3777 - accuracy: 0.8655 - val_loss: 0.5633 - val_accuracy: 0.7910\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3884 - accuracy: 0.8594 - val_loss: 0.5602 - val_accuracy: 0.7910\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3766 - accuracy: 0.8594 - val_loss: 0.5574 - val_accuracy: 0.7948\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3742 - accuracy: 0.8574 - val_loss: 0.5554 - val_accuracy: 0.7948\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3809 - accuracy: 0.8594 - val_loss: 0.5528 - val_accuracy: 0.7948\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3754 - accuracy: 0.8574 - val_loss: 0.5494 - val_accuracy: 0.7948\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3683 - accuracy: 0.8775 - val_loss: 0.5460 - val_accuracy: 0.8060\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3622 - accuracy: 0.8695 - val_loss: 0.5431 - val_accuracy: 0.8060\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3591 - accuracy: 0.8795 - val_loss: 0.5411 - val_accuracy: 0.8060\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3653 - accuracy: 0.8614 - val_loss: 0.5394 - val_accuracy: 0.8060\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3576 - accuracy: 0.8614 - val_loss: 0.5371 - val_accuracy: 0.8097\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3591 - accuracy: 0.8675 - val_loss: 0.5353 - val_accuracy: 0.8097\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3574 - accuracy: 0.8755 - val_loss: 0.5330 - val_accuracy: 0.8097\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3671 - accuracy: 0.8614 - val_loss: 0.5314 - val_accuracy: 0.8097\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3504 - accuracy: 0.8735 - val_loss: 0.5291 - val_accuracy: 0.8097\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3540 - accuracy: 0.8735 - val_loss: 0.5265 - val_accuracy: 0.8097\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3628 - accuracy: 0.8534 - val_loss: 0.5231 - val_accuracy: 0.8134\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3500 - accuracy: 0.8695 - val_loss: 0.5204 - val_accuracy: 0.8097\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3538 - accuracy: 0.8494 - val_loss: 0.5191 - val_accuracy: 0.8097\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3440 - accuracy: 0.8755 - val_loss: 0.5181 - val_accuracy: 0.8060\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3498 - accuracy: 0.8715 - val_loss: 0.5171 - val_accuracy: 0.8060\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3475 - accuracy: 0.8735 - val_loss: 0.5159 - val_accuracy: 0.8134\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3432 - accuracy: 0.8675 - val_loss: 0.5145 - val_accuracy: 0.8097\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 112us/step - loss: 0.3425 - accuracy: 0.8675 - val_loss: 0.5128 - val_accuracy: 0.8022\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 125us/step - loss: 0.3450 - accuracy: 0.8655 - val_loss: 0.5112 - val_accuracy: 0.7985\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 114us/step - loss: 0.3428 - accuracy: 0.8815 - val_loss: 0.5114 - val_accuracy: 0.8022\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 114us/step - loss: 0.3403 - accuracy: 0.8735 - val_loss: 0.5104 - val_accuracy: 0.8022\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3302 - accuracy: 0.8855 - val_loss: 0.5088 - val_accuracy: 0.8022\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3376 - accuracy: 0.8695 - val_loss: 0.5076 - val_accuracy: 0.7985\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3377 - accuracy: 0.8815 - val_loss: 0.5057 - val_accuracy: 0.7985\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3460 - accuracy: 0.8675 - val_loss: 0.5039 - val_accuracy: 0.8060\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3353 - accuracy: 0.8755 - val_loss: 0.5029 - val_accuracy: 0.8097\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3400 - accuracy: 0.8755 - val_loss: 0.5022 - val_accuracy: 0.8097\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3542 - accuracy: 0.8715 - val_loss: 0.5002 - val_accuracy: 0.8097\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3370 - accuracy: 0.8715 - val_loss: 0.5001 - val_accuracy: 0.8097\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3350 - accuracy: 0.8735 - val_loss: 0.5001 - val_accuracy: 0.8060\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3328 - accuracy: 0.8815 - val_loss: 0.5004 - val_accuracy: 0.8060\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3292 - accuracy: 0.8855 - val_loss: 0.5010 - val_accuracy: 0.7985\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3286 - accuracy: 0.8835 - val_loss: 0.5006 - val_accuracy: 0.7985\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3341 - accuracy: 0.8695 - val_loss: 0.5006 - val_accuracy: 0.7985\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3315 - accuracy: 0.8755 - val_loss: 0.4983 - val_accuracy: 0.8060\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3257 - accuracy: 0.8835 - val_loss: 0.4971 - val_accuracy: 0.8097\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3385 - accuracy: 0.8675 - val_loss: 0.4962 - val_accuracy: 0.8097\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3358 - accuracy: 0.8715 - val_loss: 0.4959 - val_accuracy: 0.8097\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3253 - accuracy: 0.8735 - val_loss: 0.4949 - val_accuracy: 0.8172\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3324 - accuracy: 0.8675 - val_loss: 0.4939 - val_accuracy: 0.8172\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3291 - accuracy: 0.8795 - val_loss: 0.4945 - val_accuracy: 0.8172\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3226 - accuracy: 0.8775 - val_loss: 0.4938 - val_accuracy: 0.8172\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3223 - accuracy: 0.8855 - val_loss: 0.4938 - val_accuracy: 0.8134\n",
      "125/125 [==============================] - 0s 16us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 0.8146 - accuracy: 0.5863 - val_loss: 0.7124 - val_accuracy: 0.6418\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.7601 - accuracy: 0.6044 - val_loss: 0.7057 - val_accuracy: 0.6530\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6968 - accuracy: 0.6486 - val_loss: 0.6997 - val_accuracy: 0.6567\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6701 - accuracy: 0.6727 - val_loss: 0.6946 - val_accuracy: 0.7052\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6343 - accuracy: 0.7189 - val_loss: 0.6893 - val_accuracy: 0.6978\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6208 - accuracy: 0.7229 - val_loss: 0.6841 - val_accuracy: 0.6791\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5926 - accuracy: 0.7390 - val_loss: 0.6793 - val_accuracy: 0.6716\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5767 - accuracy: 0.7711 - val_loss: 0.6745 - val_accuracy: 0.6754\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5736 - accuracy: 0.7671 - val_loss: 0.6694 - val_accuracy: 0.6866\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5507 - accuracy: 0.7952 - val_loss: 0.6643 - val_accuracy: 0.6940\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5433 - accuracy: 0.7871 - val_loss: 0.6591 - val_accuracy: 0.7015\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5314 - accuracy: 0.7851 - val_loss: 0.6536 - val_accuracy: 0.7239\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5143 - accuracy: 0.8052 - val_loss: 0.6474 - val_accuracy: 0.7425\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5034 - accuracy: 0.8032 - val_loss: 0.6416 - val_accuracy: 0.7463\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4958 - accuracy: 0.7992 - val_loss: 0.6363 - val_accuracy: 0.7463\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4855 - accuracy: 0.8032 - val_loss: 0.6310 - val_accuracy: 0.7575\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4745 - accuracy: 0.8133 - val_loss: 0.6252 - val_accuracy: 0.7649\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4681 - accuracy: 0.8173 - val_loss: 0.6193 - val_accuracy: 0.7761\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4601 - accuracy: 0.8173 - val_loss: 0.6139 - val_accuracy: 0.7761\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4487 - accuracy: 0.8133 - val_loss: 0.6085 - val_accuracy: 0.7836\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4439 - accuracy: 0.8353 - val_loss: 0.6034 - val_accuracy: 0.7873\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4363 - accuracy: 0.8293 - val_loss: 0.5979 - val_accuracy: 0.7948\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4365 - accuracy: 0.8273 - val_loss: 0.5930 - val_accuracy: 0.7910\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.4287 - accuracy: 0.8494 - val_loss: 0.5882 - val_accuracy: 0.7985\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4221 - accuracy: 0.8353 - val_loss: 0.5826 - val_accuracy: 0.7985\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4136 - accuracy: 0.8574 - val_loss: 0.5773 - val_accuracy: 0.7985\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4076 - accuracy: 0.8474 - val_loss: 0.5722 - val_accuracy: 0.7985\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4105 - accuracy: 0.8534 - val_loss: 0.5675 - val_accuracy: 0.8060\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4060 - accuracy: 0.8434 - val_loss: 0.5629 - val_accuracy: 0.8060\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3987 - accuracy: 0.8474 - val_loss: 0.5581 - val_accuracy: 0.8060\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3949 - accuracy: 0.8534 - val_loss: 0.5531 - val_accuracy: 0.8060\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4095 - accuracy: 0.8273 - val_loss: 0.5488 - val_accuracy: 0.8060\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3899 - accuracy: 0.8534 - val_loss: 0.5446 - val_accuracy: 0.8097\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4019 - accuracy: 0.8494 - val_loss: 0.5411 - val_accuracy: 0.8134\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3880 - accuracy: 0.8414 - val_loss: 0.5379 - val_accuracy: 0.8097\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3867 - accuracy: 0.8554 - val_loss: 0.5335 - val_accuracy: 0.8097\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3843 - accuracy: 0.8454 - val_loss: 0.5295 - val_accuracy: 0.8097\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3736 - accuracy: 0.8594 - val_loss: 0.5259 - val_accuracy: 0.8134\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3723 - accuracy: 0.8554 - val_loss: 0.5219 - val_accuracy: 0.8172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3824 - accuracy: 0.8494 - val_loss: 0.5187 - val_accuracy: 0.8209\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3861 - accuracy: 0.8494 - val_loss: 0.5173 - val_accuracy: 0.8209\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3796 - accuracy: 0.8514 - val_loss: 0.5150 - val_accuracy: 0.8321\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3903 - accuracy: 0.8474 - val_loss: 0.5123 - val_accuracy: 0.8358\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3719 - accuracy: 0.8594 - val_loss: 0.5091 - val_accuracy: 0.8358\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3743 - accuracy: 0.8474 - val_loss: 0.5067 - val_accuracy: 0.8321\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3819 - accuracy: 0.8514 - val_loss: 0.5035 - val_accuracy: 0.8321\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3758 - accuracy: 0.8454 - val_loss: 0.5004 - val_accuracy: 0.8321\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3664 - accuracy: 0.8554 - val_loss: 0.4966 - val_accuracy: 0.8321\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3623 - accuracy: 0.8594 - val_loss: 0.4930 - val_accuracy: 0.8321\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3747 - accuracy: 0.8514 - val_loss: 0.4913 - val_accuracy: 0.8321\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3690 - accuracy: 0.8635 - val_loss: 0.4900 - val_accuracy: 0.8358\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3595 - accuracy: 0.8695 - val_loss: 0.4884 - val_accuracy: 0.8358\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3620 - accuracy: 0.8675 - val_loss: 0.4868 - val_accuracy: 0.8358\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3604 - accuracy: 0.8675 - val_loss: 0.4838 - val_accuracy: 0.8358\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3650 - accuracy: 0.8594 - val_loss: 0.4814 - val_accuracy: 0.8358\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3599 - accuracy: 0.8614 - val_loss: 0.4802 - val_accuracy: 0.8358\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3602 - accuracy: 0.8574 - val_loss: 0.4793 - val_accuracy: 0.8358\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3623 - accuracy: 0.8635 - val_loss: 0.4802 - val_accuracy: 0.8358\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3571 - accuracy: 0.8655 - val_loss: 0.4801 - val_accuracy: 0.8358\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3567 - accuracy: 0.8735 - val_loss: 0.4784 - val_accuracy: 0.8358\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3610 - accuracy: 0.8635 - val_loss: 0.4758 - val_accuracy: 0.8358\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3590 - accuracy: 0.8635 - val_loss: 0.4743 - val_accuracy: 0.8358\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3615 - accuracy: 0.8554 - val_loss: 0.4726 - val_accuracy: 0.8358\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3777 - accuracy: 0.8373 - val_loss: 0.4718 - val_accuracy: 0.8358\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3611 - accuracy: 0.8554 - val_loss: 0.4710 - val_accuracy: 0.8321\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3607 - accuracy: 0.8554 - val_loss: 0.4709 - val_accuracy: 0.8284\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3549 - accuracy: 0.8675 - val_loss: 0.4718 - val_accuracy: 0.8284\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3687 - accuracy: 0.8353 - val_loss: 0.4710 - val_accuracy: 0.8284\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3591 - accuracy: 0.8594 - val_loss: 0.4703 - val_accuracy: 0.8246\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3645 - accuracy: 0.8574 - val_loss: 0.4695 - val_accuracy: 0.8246\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3593 - accuracy: 0.8735 - val_loss: 0.4689 - val_accuracy: 0.8284\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3554 - accuracy: 0.8675 - val_loss: 0.4682 - val_accuracy: 0.8284\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3509 - accuracy: 0.8635 - val_loss: 0.4656 - val_accuracy: 0.8209\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3572 - accuracy: 0.8695 - val_loss: 0.4655 - val_accuracy: 0.8172\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3447 - accuracy: 0.8755 - val_loss: 0.4649 - val_accuracy: 0.8134\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3448 - accuracy: 0.8715 - val_loss: 0.4646 - val_accuracy: 0.8172\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3501 - accuracy: 0.8695 - val_loss: 0.4652 - val_accuracy: 0.8097\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3419 - accuracy: 0.8675 - val_loss: 0.4667 - val_accuracy: 0.8097\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3476 - accuracy: 0.8655 - val_loss: 0.4687 - val_accuracy: 0.8097\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3640 - accuracy: 0.8594 - val_loss: 0.4678 - val_accuracy: 0.8097\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3494 - accuracy: 0.8715 - val_loss: 0.4666 - val_accuracy: 0.8097\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3604 - accuracy: 0.8675 - val_loss: 0.4660 - val_accuracy: 0.8097\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3429 - accuracy: 0.8715 - val_loss: 0.4659 - val_accuracy: 0.8097\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3772 - accuracy: 0.8474 - val_loss: 0.4660 - val_accuracy: 0.8134\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3500 - accuracy: 0.8594 - val_loss: 0.4653 - val_accuracy: 0.8097\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3460 - accuracy: 0.8735 - val_loss: 0.4664 - val_accuracy: 0.8022\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3389 - accuracy: 0.8775 - val_loss: 0.4669 - val_accuracy: 0.8022\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3448 - accuracy: 0.8695 - val_loss: 0.4659 - val_accuracy: 0.8022\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3424 - accuracy: 0.8735 - val_loss: 0.4636 - val_accuracy: 0.8060\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3446 - accuracy: 0.8795 - val_loss: 0.4628 - val_accuracy: 0.8134\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3435 - accuracy: 0.8755 - val_loss: 0.4659 - val_accuracy: 0.8022\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3443 - accuracy: 0.8635 - val_loss: 0.4678 - val_accuracy: 0.8022\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3364 - accuracy: 0.8775 - val_loss: 0.4661 - val_accuracy: 0.8060\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3527 - accuracy: 0.8755 - val_loss: 0.4661 - val_accuracy: 0.8060\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3407 - accuracy: 0.8675 - val_loss: 0.4651 - val_accuracy: 0.8060\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3412 - accuracy: 0.8795 - val_loss: 0.4663 - val_accuracy: 0.8097\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3324 - accuracy: 0.8835 - val_loss: 0.4656 - val_accuracy: 0.8097\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3398 - accuracy: 0.8635 - val_loss: 0.4653 - val_accuracy: 0.8060\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3621 - accuracy: 0.8614 - val_loss: 0.4650 - val_accuracy: 0.8022\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3505 - accuracy: 0.8715 - val_loss: 0.4644 - val_accuracy: 0.7985\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 1s 1ms/step - loss: 0.8643 - accuracy: 0.5651 - val_loss: 0.7538 - val_accuracy: 0.3246\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.8076 - accuracy: 0.5972 - val_loss: 0.7455 - val_accuracy: 0.3134\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.7568 - accuracy: 0.6293 - val_loss: 0.7393 - val_accuracy: 0.3060\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.7139 - accuracy: 0.6493 - val_loss: 0.7339 - val_accuracy: 0.4515\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.6990 - accuracy: 0.6433 - val_loss: 0.7286 - val_accuracy: 0.5336\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.6697 - accuracy: 0.6613 - val_loss: 0.7238 - val_accuracy: 0.5821\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.6284 - accuracy: 0.7194 - val_loss: 0.7196 - val_accuracy: 0.5896\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.6265 - accuracy: 0.6954 - val_loss: 0.7163 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.6017 - accuracy: 0.7094 - val_loss: 0.7134 - val_accuracy: 0.6045\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.5837 - accuracy: 0.7375 - val_loss: 0.7100 - val_accuracy: 0.6082\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5657 - accuracy: 0.7335 - val_loss: 0.7061 - val_accuracy: 0.6082\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.5468 - accuracy: 0.7335 - val_loss: 0.7023 - val_accuracy: 0.6119\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.5531 - accuracy: 0.7555 - val_loss: 0.6979 - val_accuracy: 0.6157\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.5334 - accuracy: 0.7535 - val_loss: 0.6938 - val_accuracy: 0.6119\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.5267 - accuracy: 0.7555 - val_loss: 0.6892 - val_accuracy: 0.6157\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.5102 - accuracy: 0.7836 - val_loss: 0.6847 - val_accuracy: 0.6157\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.5037 - accuracy: 0.7996 - val_loss: 0.6805 - val_accuracy: 0.6157\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4989 - accuracy: 0.8096 - val_loss: 0.6765 - val_accuracy: 0.6157\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4995 - accuracy: 0.7936 - val_loss: 0.6724 - val_accuracy: 0.6157\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4824 - accuracy: 0.8297 - val_loss: 0.6685 - val_accuracy: 0.6157\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.4780 - accuracy: 0.8176 - val_loss: 0.6648 - val_accuracy: 0.6119\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.4718 - accuracy: 0.8196 - val_loss: 0.6613 - val_accuracy: 0.6119\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4698 - accuracy: 0.8277 - val_loss: 0.6588 - val_accuracy: 0.6157\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4608 - accuracy: 0.8317 - val_loss: 0.6569 - val_accuracy: 0.6157\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4596 - accuracy: 0.8257 - val_loss: 0.6548 - val_accuracy: 0.6157\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4429 - accuracy: 0.8497 - val_loss: 0.6524 - val_accuracy: 0.6157\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4573 - accuracy: 0.8397 - val_loss: 0.6501 - val_accuracy: 0.6194\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4384 - accuracy: 0.8357 - val_loss: 0.6477 - val_accuracy: 0.6194\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4291 - accuracy: 0.8417 - val_loss: 0.6456 - val_accuracy: 0.6231\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4277 - accuracy: 0.8437 - val_loss: 0.6432 - val_accuracy: 0.6269\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.4187 - accuracy: 0.8457 - val_loss: 0.6407 - val_accuracy: 0.6306\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4298 - accuracy: 0.8437 - val_loss: 0.6391 - val_accuracy: 0.6343\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4187 - accuracy: 0.8417 - val_loss: 0.6377 - val_accuracy: 0.6381\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4152 - accuracy: 0.8457 - val_loss: 0.6364 - val_accuracy: 0.6418\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4119 - accuracy: 0.8457 - val_loss: 0.6342 - val_accuracy: 0.6493\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4037 - accuracy: 0.8517 - val_loss: 0.6329 - val_accuracy: 0.6604\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4064 - accuracy: 0.8517 - val_loss: 0.6299 - val_accuracy: 0.6604\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4084 - accuracy: 0.8437 - val_loss: 0.6281 - val_accuracy: 0.6679\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4032 - accuracy: 0.8557 - val_loss: 0.6274 - val_accuracy: 0.6679\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.4005 - accuracy: 0.8577 - val_loss: 0.6259 - val_accuracy: 0.6679\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3980 - accuracy: 0.8577 - val_loss: 0.6243 - val_accuracy: 0.6716\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3989 - accuracy: 0.8577 - val_loss: 0.6225 - val_accuracy: 0.6754\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3919 - accuracy: 0.8677 - val_loss: 0.6204 - val_accuracy: 0.6754\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3968 - accuracy: 0.8617 - val_loss: 0.6196 - val_accuracy: 0.6791\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3884 - accuracy: 0.8617 - val_loss: 0.6180 - val_accuracy: 0.6828\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3884 - accuracy: 0.8577 - val_loss: 0.6163 - val_accuracy: 0.6791\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3901 - accuracy: 0.8577 - val_loss: 0.6153 - val_accuracy: 0.6716\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3865 - accuracy: 0.8517 - val_loss: 0.6150 - val_accuracy: 0.6791\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3801 - accuracy: 0.8617 - val_loss: 0.6138 - val_accuracy: 0.6828\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3827 - accuracy: 0.8577 - val_loss: 0.6118 - val_accuracy: 0.6940\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3846 - accuracy: 0.8497 - val_loss: 0.6103 - val_accuracy: 0.6940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3747 - accuracy: 0.8597 - val_loss: 0.6095 - val_accuracy: 0.6978\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3762 - accuracy: 0.8677 - val_loss: 0.6067 - val_accuracy: 0.7015\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3778 - accuracy: 0.8497 - val_loss: 0.6052 - val_accuracy: 0.7127\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3760 - accuracy: 0.8617 - val_loss: 0.6049 - val_accuracy: 0.7164\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3816 - accuracy: 0.8617 - val_loss: 0.6045 - val_accuracy: 0.7239\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3673 - accuracy: 0.8557 - val_loss: 0.6045 - val_accuracy: 0.7239\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3742 - accuracy: 0.8697 - val_loss: 0.6023 - val_accuracy: 0.7313\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3698 - accuracy: 0.8617 - val_loss: 0.6007 - val_accuracy: 0.7351\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3535 - accuracy: 0.8717 - val_loss: 0.5986 - val_accuracy: 0.7351\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3573 - accuracy: 0.8637 - val_loss: 0.5966 - val_accuracy: 0.7351\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3582 - accuracy: 0.8717 - val_loss: 0.5954 - val_accuracy: 0.7313\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3583 - accuracy: 0.8637 - val_loss: 0.5951 - val_accuracy: 0.7313\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3615 - accuracy: 0.8717 - val_loss: 0.5917 - val_accuracy: 0.7313\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3532 - accuracy: 0.8717 - val_loss: 0.5877 - val_accuracy: 0.7239\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3584 - accuracy: 0.8657 - val_loss: 0.5849 - val_accuracy: 0.7276\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3593 - accuracy: 0.8677 - val_loss: 0.5841 - val_accuracy: 0.7276\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3685 - accuracy: 0.8617 - val_loss: 0.5806 - val_accuracy: 0.7351\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3494 - accuracy: 0.8717 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3540 - accuracy: 0.8717 - val_loss: 0.5759 - val_accuracy: 0.7575\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3502 - accuracy: 0.8697 - val_loss: 0.5730 - val_accuracy: 0.7612\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3522 - accuracy: 0.8758 - val_loss: 0.5688 - val_accuracy: 0.7612\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3395 - accuracy: 0.8838 - val_loss: 0.5663 - val_accuracy: 0.7649\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3459 - accuracy: 0.8737 - val_loss: 0.5659 - val_accuracy: 0.7649\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3426 - accuracy: 0.8818 - val_loss: 0.5650 - val_accuracy: 0.7649\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3523 - accuracy: 0.8717 - val_loss: 0.5637 - val_accuracy: 0.7687\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3502 - accuracy: 0.8697 - val_loss: 0.5624 - val_accuracy: 0.7724\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3473 - accuracy: 0.8697 - val_loss: 0.5607 - val_accuracy: 0.7761\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3546 - accuracy: 0.8597 - val_loss: 0.5612 - val_accuracy: 0.7761\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3386 - accuracy: 0.8737 - val_loss: 0.5592 - val_accuracy: 0.7724\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 102us/step - loss: 0.3400 - accuracy: 0.8737 - val_loss: 0.5579 - val_accuracy: 0.7724\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3425 - accuracy: 0.8798 - val_loss: 0.5578 - val_accuracy: 0.7724\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3391 - accuracy: 0.8778 - val_loss: 0.5586 - val_accuracy: 0.7724\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3438 - accuracy: 0.8798 - val_loss: 0.5575 - val_accuracy: 0.7724\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3342 - accuracy: 0.8858 - val_loss: 0.5557 - val_accuracy: 0.7724\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3353 - accuracy: 0.8798 - val_loss: 0.5544 - val_accuracy: 0.7724\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3462 - accuracy: 0.8697 - val_loss: 0.5528 - val_accuracy: 0.7724\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3435 - accuracy: 0.8717 - val_loss: 0.5523 - val_accuracy: 0.7761\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3294 - accuracy: 0.8818 - val_loss: 0.5513 - val_accuracy: 0.7724\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3316 - accuracy: 0.8838 - val_loss: 0.5496 - val_accuracy: 0.7724\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3354 - accuracy: 0.8818 - val_loss: 0.5492 - val_accuracy: 0.7612\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3571 - accuracy: 0.8717 - val_loss: 0.5490 - val_accuracy: 0.7575\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3412 - accuracy: 0.8677 - val_loss: 0.5488 - val_accuracy: 0.7537\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3416 - accuracy: 0.8677 - val_loss: 0.5493 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3354 - accuracy: 0.8717 - val_loss: 0.5474 - val_accuracy: 0.7463\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3386 - accuracy: 0.8758 - val_loss: 0.5454 - val_accuracy: 0.7463\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3377 - accuracy: 0.8878 - val_loss: 0.5456 - val_accuracy: 0.7537\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3342 - accuracy: 0.8818 - val_loss: 0.5462 - val_accuracy: 0.7575\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3425 - accuracy: 0.8717 - val_loss: 0.5466 - val_accuracy: 0.7575\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3360 - accuracy: 0.8858 - val_loss: 0.5449 - val_accuracy: 0.7500\n",
      "124/124 [==============================] - 0s 24us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 1s 1ms/step - loss: 0.7057 - accuracy: 0.6573 - val_loss: 0.7245 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.6738 - accuracy: 0.6794 - val_loss: 0.7218 - val_accuracy: 0.6194\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.6439 - accuracy: 0.6934 - val_loss: 0.7191 - val_accuracy: 0.6157\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.6180 - accuracy: 0.7475 - val_loss: 0.7164 - val_accuracy: 0.6119\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.6092 - accuracy: 0.7295 - val_loss: 0.7136 - val_accuracy: 0.6157\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5779 - accuracy: 0.7535 - val_loss: 0.7109 - val_accuracy: 0.6119\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.5535 - accuracy: 0.7836 - val_loss: 0.7081 - val_accuracy: 0.6157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.5458 - accuracy: 0.7936 - val_loss: 0.7052 - val_accuracy: 0.6194\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.5439 - accuracy: 0.7856 - val_loss: 0.7024 - val_accuracy: 0.6269\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5114 - accuracy: 0.7996 - val_loss: 0.6997 - val_accuracy: 0.6306\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4954 - accuracy: 0.8036 - val_loss: 0.6968 - val_accuracy: 0.6306\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4861 - accuracy: 0.8156 - val_loss: 0.6936 - val_accuracy: 0.6269\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4828 - accuracy: 0.8056 - val_loss: 0.6898 - val_accuracy: 0.6269\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4731 - accuracy: 0.8156 - val_loss: 0.6853 - val_accuracy: 0.6381\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4563 - accuracy: 0.8156 - val_loss: 0.6805 - val_accuracy: 0.6418\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4600 - accuracy: 0.8277 - val_loss: 0.6755 - val_accuracy: 0.6455\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4390 - accuracy: 0.8357 - val_loss: 0.6704 - val_accuracy: 0.6455\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4360 - accuracy: 0.8417 - val_loss: 0.6643 - val_accuracy: 0.6455\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4331 - accuracy: 0.8417 - val_loss: 0.6578 - val_accuracy: 0.6455\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4213 - accuracy: 0.8497 - val_loss: 0.6506 - val_accuracy: 0.6493\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4162 - accuracy: 0.8557 - val_loss: 0.6432 - val_accuracy: 0.6604\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4131 - accuracy: 0.8537 - val_loss: 0.6359 - val_accuracy: 0.6642\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4063 - accuracy: 0.8497 - val_loss: 0.6290 - val_accuracy: 0.6679\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4015 - accuracy: 0.8657 - val_loss: 0.6220 - val_accuracy: 0.6791\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3986 - accuracy: 0.8457 - val_loss: 0.6155 - val_accuracy: 0.6828\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3904 - accuracy: 0.8637 - val_loss: 0.6100 - val_accuracy: 0.6866\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3922 - accuracy: 0.8617 - val_loss: 0.6038 - val_accuracy: 0.6978\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3973 - accuracy: 0.8597 - val_loss: 0.5984 - val_accuracy: 0.7090\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3864 - accuracy: 0.8637 - val_loss: 0.5928 - val_accuracy: 0.7127\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3861 - accuracy: 0.8557 - val_loss: 0.5876 - val_accuracy: 0.7090\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3822 - accuracy: 0.8597 - val_loss: 0.5829 - val_accuracy: 0.7164\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3794 - accuracy: 0.8617 - val_loss: 0.5786 - val_accuracy: 0.7239\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3798 - accuracy: 0.8577 - val_loss: 0.5740 - val_accuracy: 0.7276\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3708 - accuracy: 0.8637 - val_loss: 0.5710 - val_accuracy: 0.7276\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3695 - accuracy: 0.8697 - val_loss: 0.5672 - val_accuracy: 0.7313\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3681 - accuracy: 0.8657 - val_loss: 0.5635 - val_accuracy: 0.7388\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3670 - accuracy: 0.8697 - val_loss: 0.5595 - val_accuracy: 0.7463\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 100us/step - loss: 0.3730 - accuracy: 0.8697 - val_loss: 0.5558 - val_accuracy: 0.7537\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 118us/step - loss: 0.3710 - accuracy: 0.8637 - val_loss: 0.5528 - val_accuracy: 0.7575\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 104us/step - loss: 0.3746 - accuracy: 0.8597 - val_loss: 0.5491 - val_accuracy: 0.7575\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3686 - accuracy: 0.8697 - val_loss: 0.5444 - val_accuracy: 0.7649\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3686 - accuracy: 0.8677 - val_loss: 0.5396 - val_accuracy: 0.7799\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3624 - accuracy: 0.8617 - val_loss: 0.5347 - val_accuracy: 0.7873\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3733 - accuracy: 0.8677 - val_loss: 0.5297 - val_accuracy: 0.7910\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3571 - accuracy: 0.8617 - val_loss: 0.5259 - val_accuracy: 0.7985\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3522 - accuracy: 0.8737 - val_loss: 0.5221 - val_accuracy: 0.8097\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3642 - accuracy: 0.8637 - val_loss: 0.5181 - val_accuracy: 0.8172\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3644 - accuracy: 0.8697 - val_loss: 0.5149 - val_accuracy: 0.8172\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3488 - accuracy: 0.8818 - val_loss: 0.5106 - val_accuracy: 0.8209\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3496 - accuracy: 0.8737 - val_loss: 0.5071 - val_accuracy: 0.8246\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3598 - accuracy: 0.8637 - val_loss: 0.5031 - val_accuracy: 0.8246\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3470 - accuracy: 0.8778 - val_loss: 0.5005 - val_accuracy: 0.8284\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3517 - accuracy: 0.8677 - val_loss: 0.4978 - val_accuracy: 0.8246\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3486 - accuracy: 0.8737 - val_loss: 0.4966 - val_accuracy: 0.8209\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3490 - accuracy: 0.8737 - val_loss: 0.4952 - val_accuracy: 0.8172\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3432 - accuracy: 0.8858 - val_loss: 0.4937 - val_accuracy: 0.8246\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3456 - accuracy: 0.8717 - val_loss: 0.4911 - val_accuracy: 0.8284\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3383 - accuracy: 0.8798 - val_loss: 0.4897 - val_accuracy: 0.8321\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3400 - accuracy: 0.8798 - val_loss: 0.4886 - val_accuracy: 0.8284\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3407 - accuracy: 0.8737 - val_loss: 0.4869 - val_accuracy: 0.8246\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3425 - accuracy: 0.8798 - val_loss: 0.4859 - val_accuracy: 0.8172\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3383 - accuracy: 0.8798 - val_loss: 0.4859 - val_accuracy: 0.8134\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3371 - accuracy: 0.8798 - val_loss: 0.4860 - val_accuracy: 0.8172\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3351 - accuracy: 0.8798 - val_loss: 0.4869 - val_accuracy: 0.8134\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3435 - accuracy: 0.8758 - val_loss: 0.4878 - val_accuracy: 0.8134\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3404 - accuracy: 0.8717 - val_loss: 0.4879 - val_accuracy: 0.8060\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3413 - accuracy: 0.8778 - val_loss: 0.4874 - val_accuracy: 0.8022\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3333 - accuracy: 0.8798 - val_loss: 0.4853 - val_accuracy: 0.8060\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3377 - accuracy: 0.8758 - val_loss: 0.4842 - val_accuracy: 0.8097\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3372 - accuracy: 0.8737 - val_loss: 0.4846 - val_accuracy: 0.8060\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3411 - accuracy: 0.8697 - val_loss: 0.4858 - val_accuracy: 0.8022\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3370 - accuracy: 0.8697 - val_loss: 0.4893 - val_accuracy: 0.7910\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3374 - accuracy: 0.8717 - val_loss: 0.4900 - val_accuracy: 0.7948\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3433 - accuracy: 0.8737 - val_loss: 0.4927 - val_accuracy: 0.7836\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3407 - accuracy: 0.8737 - val_loss: 0.4930 - val_accuracy: 0.7836\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3462 - accuracy: 0.8717 - val_loss: 0.4931 - val_accuracy: 0.7799\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3408 - accuracy: 0.8677 - val_loss: 0.4933 - val_accuracy: 0.7799\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3493 - accuracy: 0.8758 - val_loss: 0.4913 - val_accuracy: 0.7836\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3432 - accuracy: 0.8758 - val_loss: 0.4901 - val_accuracy: 0.7873\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3346 - accuracy: 0.8838 - val_loss: 0.4887 - val_accuracy: 0.7948\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3270 - accuracy: 0.8878 - val_loss: 0.4899 - val_accuracy: 0.7948\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3333 - accuracy: 0.8798 - val_loss: 0.4887 - val_accuracy: 0.8022\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3404 - accuracy: 0.8717 - val_loss: 0.4881 - val_accuracy: 0.8022\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3443 - accuracy: 0.8737 - val_loss: 0.4889 - val_accuracy: 0.7985\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3394 - accuracy: 0.8818 - val_loss: 0.4898 - val_accuracy: 0.7985\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3189 - accuracy: 0.8898 - val_loss: 0.4913 - val_accuracy: 0.7873\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3220 - accuracy: 0.8798 - val_loss: 0.4925 - val_accuracy: 0.7836\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3191 - accuracy: 0.8898 - val_loss: 0.4933 - val_accuracy: 0.7799\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3262 - accuracy: 0.8818 - val_loss: 0.4937 - val_accuracy: 0.7724\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3356 - accuracy: 0.8818 - val_loss: 0.4951 - val_accuracy: 0.7724\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3247 - accuracy: 0.8737 - val_loss: 0.4974 - val_accuracy: 0.7649\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3371 - accuracy: 0.8778 - val_loss: 0.4983 - val_accuracy: 0.7687\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3316 - accuracy: 0.8818 - val_loss: 0.4979 - val_accuracy: 0.7799\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3273 - accuracy: 0.8838 - val_loss: 0.4984 - val_accuracy: 0.7799\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3299 - accuracy: 0.8878 - val_loss: 0.5000 - val_accuracy: 0.7761\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3249 - accuracy: 0.8778 - val_loss: 0.5004 - val_accuracy: 0.7761\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3283 - accuracy: 0.8878 - val_loss: 0.4997 - val_accuracy: 0.7799\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3205 - accuracy: 0.8858 - val_loss: 0.5004 - val_accuracy: 0.7687\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3228 - accuracy: 0.8858 - val_loss: 0.4987 - val_accuracy: 0.7724\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3322 - accuracy: 0.8838 - val_loss: 0.4983 - val_accuracy: 0.7910\n",
      "124/124 [==============================] - 0s 24us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 0.7387 - accuracy: 0.5723 - val_loss: 0.7259 - val_accuracy: 0.3881\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.6838 - accuracy: 0.6104 - val_loss: 0.7237 - val_accuracy: 0.4739\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.6580 - accuracy: 0.6305 - val_loss: 0.7211 - val_accuracy: 0.5299\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 99us/step - loss: 0.6353 - accuracy: 0.6687 - val_loss: 0.7184 - val_accuracy: 0.5933\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.6208 - accuracy: 0.6847 - val_loss: 0.7156 - val_accuracy: 0.7090\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.5999 - accuracy: 0.6968 - val_loss: 0.7127 - val_accuracy: 0.7313\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.5829 - accuracy: 0.7169 - val_loss: 0.7098 - val_accuracy: 0.7425\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.5658 - accuracy: 0.7349 - val_loss: 0.7070 - val_accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5593 - accuracy: 0.7430 - val_loss: 0.7042 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5363 - accuracy: 0.7651 - val_loss: 0.7015 - val_accuracy: 0.7463\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5379 - accuracy: 0.7651 - val_loss: 0.6988 - val_accuracy: 0.7425\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5247 - accuracy: 0.7671 - val_loss: 0.6955 - val_accuracy: 0.7425\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5164 - accuracy: 0.7831 - val_loss: 0.6919 - val_accuracy: 0.7351\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5081 - accuracy: 0.7992 - val_loss: 0.6881 - val_accuracy: 0.7351\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4825 - accuracy: 0.8112 - val_loss: 0.6836 - val_accuracy: 0.7537\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5078 - accuracy: 0.8032 - val_loss: 0.6787 - val_accuracy: 0.7612\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4837 - accuracy: 0.8233 - val_loss: 0.6737 - val_accuracy: 0.7575\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4846 - accuracy: 0.8273 - val_loss: 0.6687 - val_accuracy: 0.7612\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4702 - accuracy: 0.8293 - val_loss: 0.6633 - val_accuracy: 0.7761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4625 - accuracy: 0.8333 - val_loss: 0.6575 - val_accuracy: 0.7761\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4565 - accuracy: 0.8333 - val_loss: 0.6518 - val_accuracy: 0.7724\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.4561 - accuracy: 0.8333 - val_loss: 0.6455 - val_accuracy: 0.7612\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.4489 - accuracy: 0.8353 - val_loss: 0.6392 - val_accuracy: 0.7575\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 106us/step - loss: 0.4393 - accuracy: 0.8394 - val_loss: 0.6324 - val_accuracy: 0.7612\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 108us/step - loss: 0.4379 - accuracy: 0.8333 - val_loss: 0.6255 - val_accuracy: 0.7537\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4356 - accuracy: 0.8534 - val_loss: 0.6186 - val_accuracy: 0.7649\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4315 - accuracy: 0.8434 - val_loss: 0.6121 - val_accuracy: 0.7687\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4224 - accuracy: 0.8454 - val_loss: 0.6062 - val_accuracy: 0.7687\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4145 - accuracy: 0.8494 - val_loss: 0.6008 - val_accuracy: 0.7761\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4146 - accuracy: 0.8394 - val_loss: 0.5954 - val_accuracy: 0.7612\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4111 - accuracy: 0.8414 - val_loss: 0.5903 - val_accuracy: 0.7612\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4181 - accuracy: 0.8454 - val_loss: 0.5851 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4012 - accuracy: 0.8494 - val_loss: 0.5800 - val_accuracy: 0.7463\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3987 - accuracy: 0.8534 - val_loss: 0.5752 - val_accuracy: 0.7463\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3985 - accuracy: 0.8534 - val_loss: 0.5707 - val_accuracy: 0.7463\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3991 - accuracy: 0.8434 - val_loss: 0.5661 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3868 - accuracy: 0.8494 - val_loss: 0.5615 - val_accuracy: 0.7537\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3813 - accuracy: 0.8594 - val_loss: 0.5575 - val_accuracy: 0.7537\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3923 - accuracy: 0.8534 - val_loss: 0.5531 - val_accuracy: 0.7612\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3833 - accuracy: 0.8614 - val_loss: 0.5495 - val_accuracy: 0.7724\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3886 - accuracy: 0.8514 - val_loss: 0.5457 - val_accuracy: 0.7761\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3874 - accuracy: 0.8614 - val_loss: 0.5427 - val_accuracy: 0.7836\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3802 - accuracy: 0.8554 - val_loss: 0.5396 - val_accuracy: 0.7873\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3769 - accuracy: 0.8574 - val_loss: 0.5372 - val_accuracy: 0.7724\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3734 - accuracy: 0.8614 - val_loss: 0.5353 - val_accuracy: 0.7724\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3697 - accuracy: 0.8614 - val_loss: 0.5329 - val_accuracy: 0.7649\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3772 - accuracy: 0.8574 - val_loss: 0.5304 - val_accuracy: 0.7687\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3712 - accuracy: 0.8695 - val_loss: 0.5288 - val_accuracy: 0.7724\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3689 - accuracy: 0.8635 - val_loss: 0.5271 - val_accuracy: 0.7724\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3735 - accuracy: 0.8574 - val_loss: 0.5245 - val_accuracy: 0.7761\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3634 - accuracy: 0.8675 - val_loss: 0.5217 - val_accuracy: 0.7761\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3620 - accuracy: 0.8655 - val_loss: 0.5194 - val_accuracy: 0.7799\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3706 - accuracy: 0.8715 - val_loss: 0.5171 - val_accuracy: 0.7836\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3579 - accuracy: 0.8614 - val_loss: 0.5153 - val_accuracy: 0.7873\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3520 - accuracy: 0.8755 - val_loss: 0.5133 - val_accuracy: 0.7761\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3514 - accuracy: 0.8815 - val_loss: 0.5114 - val_accuracy: 0.7836\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3633 - accuracy: 0.8635 - val_loss: 0.5102 - val_accuracy: 0.7761\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3526 - accuracy: 0.8675 - val_loss: 0.5097 - val_accuracy: 0.7687\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3601 - accuracy: 0.8614 - val_loss: 0.5085 - val_accuracy: 0.7687\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3593 - accuracy: 0.8614 - val_loss: 0.5088 - val_accuracy: 0.7575\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3417 - accuracy: 0.8735 - val_loss: 0.5086 - val_accuracy: 0.7612\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3428 - accuracy: 0.8735 - val_loss: 0.5102 - val_accuracy: 0.7575\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3479 - accuracy: 0.8655 - val_loss: 0.5096 - val_accuracy: 0.7612\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3438 - accuracy: 0.8715 - val_loss: 0.5069 - val_accuracy: 0.7612\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3397 - accuracy: 0.8755 - val_loss: 0.5048 - val_accuracy: 0.7687\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3330 - accuracy: 0.8916 - val_loss: 0.5042 - val_accuracy: 0.7649\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3542 - accuracy: 0.8655 - val_loss: 0.5046 - val_accuracy: 0.7687\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3418 - accuracy: 0.8775 - val_loss: 0.5059 - val_accuracy: 0.7799\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3376 - accuracy: 0.8815 - val_loss: 0.5073 - val_accuracy: 0.7649\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3395 - accuracy: 0.8855 - val_loss: 0.5078 - val_accuracy: 0.7612\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3397 - accuracy: 0.8815 - val_loss: 0.5072 - val_accuracy: 0.7724\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3402 - accuracy: 0.8695 - val_loss: 0.5049 - val_accuracy: 0.7687\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3366 - accuracy: 0.8835 - val_loss: 0.5022 - val_accuracy: 0.7724\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3374 - accuracy: 0.8775 - val_loss: 0.5019 - val_accuracy: 0.7724\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3302 - accuracy: 0.8896 - val_loss: 0.5018 - val_accuracy: 0.7724\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3407 - accuracy: 0.8815 - val_loss: 0.5005 - val_accuracy: 0.7799\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3280 - accuracy: 0.8896 - val_loss: 0.5001 - val_accuracy: 0.7724\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3322 - accuracy: 0.8916 - val_loss: 0.4985 - val_accuracy: 0.7724\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3313 - accuracy: 0.8735 - val_loss: 0.4979 - val_accuracy: 0.7649\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3336 - accuracy: 0.8916 - val_loss: 0.4968 - val_accuracy: 0.7724\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3228 - accuracy: 0.8835 - val_loss: 0.4949 - val_accuracy: 0.7761\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3326 - accuracy: 0.8835 - val_loss: 0.4947 - val_accuracy: 0.7799\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3280 - accuracy: 0.8936 - val_loss: 0.4946 - val_accuracy: 0.7910\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3366 - accuracy: 0.8835 - val_loss: 0.4945 - val_accuracy: 0.7799\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3352 - accuracy: 0.8876 - val_loss: 0.4931 - val_accuracy: 0.7873\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3242 - accuracy: 0.8855 - val_loss: 0.4914 - val_accuracy: 0.7799\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3319 - accuracy: 0.8815 - val_loss: 0.4908 - val_accuracy: 0.7836\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3171 - accuracy: 0.8916 - val_loss: 0.4897 - val_accuracy: 0.7836\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3253 - accuracy: 0.8896 - val_loss: 0.4870 - val_accuracy: 0.7985\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3261 - accuracy: 0.8956 - val_loss: 0.4854 - val_accuracy: 0.8060\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3213 - accuracy: 0.8956 - val_loss: 0.4862 - val_accuracy: 0.8022\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3292 - accuracy: 0.8795 - val_loss: 0.4842 - val_accuracy: 0.8060\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3282 - accuracy: 0.8835 - val_loss: 0.4823 - val_accuracy: 0.8134\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3219 - accuracy: 0.8996 - val_loss: 0.4808 - val_accuracy: 0.8172\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3379 - accuracy: 0.8876 - val_loss: 0.4800 - val_accuracy: 0.8097\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3218 - accuracy: 0.8896 - val_loss: 0.4795 - val_accuracy: 0.8209\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3182 - accuracy: 0.8876 - val_loss: 0.4803 - val_accuracy: 0.8097\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 104us/step - loss: 0.3208 - accuracy: 0.9016 - val_loss: 0.4792 - val_accuracy: 0.8134\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3246 - accuracy: 0.8815 - val_loss: 0.4758 - val_accuracy: 0.8284\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3186 - accuracy: 0.8936 - val_loss: 0.4749 - val_accuracy: 0.8284\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 0.9011 - accuracy: 0.4217 - val_loss: 0.7576 - val_accuracy: 0.3284\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.8369 - accuracy: 0.4859 - val_loss: 0.7485 - val_accuracy: 0.3806\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.7971 - accuracy: 0.5241 - val_loss: 0.7384 - val_accuracy: 0.3731\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.7268 - accuracy: 0.6084 - val_loss: 0.7280 - val_accuracy: 0.4179\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6922 - accuracy: 0.7028 - val_loss: 0.7189 - val_accuracy: 0.4925\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.6676 - accuracy: 0.7329 - val_loss: 0.7115 - val_accuracy: 0.6157\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.6353 - accuracy: 0.7610 - val_loss: 0.7054 - val_accuracy: 0.6604\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6233 - accuracy: 0.7711 - val_loss: 0.6997 - val_accuracy: 0.6791\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5959 - accuracy: 0.7791 - val_loss: 0.6945 - val_accuracy: 0.6940\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5850 - accuracy: 0.7851 - val_loss: 0.6896 - val_accuracy: 0.7015\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.5765 - accuracy: 0.7871 - val_loss: 0.6851 - val_accuracy: 0.7239\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.5637 - accuracy: 0.8012 - val_loss: 0.6809 - val_accuracy: 0.7276\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5601 - accuracy: 0.8153 - val_loss: 0.6766 - val_accuracy: 0.7276\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5500 - accuracy: 0.8213 - val_loss: 0.6723 - val_accuracy: 0.7351\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5350 - accuracy: 0.8153 - val_loss: 0.6679 - val_accuracy: 0.7463\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5206 - accuracy: 0.8333 - val_loss: 0.6635 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.5191 - accuracy: 0.8333 - val_loss: 0.6588 - val_accuracy: 0.7649\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5074 - accuracy: 0.8373 - val_loss: 0.6541 - val_accuracy: 0.7724\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.5088 - accuracy: 0.8373 - val_loss: 0.6493 - val_accuracy: 0.7910\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4938 - accuracy: 0.8394 - val_loss: 0.6439 - val_accuracy: 0.7948\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4902 - accuracy: 0.8394 - val_loss: 0.6386 - val_accuracy: 0.7985\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4796 - accuracy: 0.8454 - val_loss: 0.6334 - val_accuracy: 0.8060\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4721 - accuracy: 0.8394 - val_loss: 0.6279 - val_accuracy: 0.8060\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4664 - accuracy: 0.8554 - val_loss: 0.6226 - val_accuracy: 0.8097\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4666 - accuracy: 0.8273 - val_loss: 0.6173 - val_accuracy: 0.8097\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4540 - accuracy: 0.8514 - val_loss: 0.6119 - val_accuracy: 0.8097\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4530 - accuracy: 0.8554 - val_loss: 0.6061 - val_accuracy: 0.8097\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4372 - accuracy: 0.8554 - val_loss: 0.6002 - val_accuracy: 0.8134\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4404 - accuracy: 0.8494 - val_loss: 0.5943 - val_accuracy: 0.8209\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4288 - accuracy: 0.8614 - val_loss: 0.5884 - val_accuracy: 0.8246\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.4269 - accuracy: 0.8695 - val_loss: 0.5826 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4207 - accuracy: 0.8655 - val_loss: 0.5766 - val_accuracy: 0.8246\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4188 - accuracy: 0.8695 - val_loss: 0.5702 - val_accuracy: 0.8246\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4063 - accuracy: 0.8775 - val_loss: 0.5639 - val_accuracy: 0.8246\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4094 - accuracy: 0.8655 - val_loss: 0.5580 - val_accuracy: 0.8134\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4061 - accuracy: 0.8675 - val_loss: 0.5523 - val_accuracy: 0.8209\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4030 - accuracy: 0.8514 - val_loss: 0.5466 - val_accuracy: 0.8246\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3987 - accuracy: 0.8715 - val_loss: 0.5416 - val_accuracy: 0.8284\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3960 - accuracy: 0.8715 - val_loss: 0.5365 - val_accuracy: 0.8284\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3916 - accuracy: 0.8675 - val_loss: 0.5319 - val_accuracy: 0.8284\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3907 - accuracy: 0.8614 - val_loss: 0.5276 - val_accuracy: 0.8321\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3854 - accuracy: 0.8695 - val_loss: 0.5234 - val_accuracy: 0.8433\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3863 - accuracy: 0.8574 - val_loss: 0.5198 - val_accuracy: 0.8396\n",
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3845 - accuracy: 0.8614 - val_loss: 0.5161 - val_accuracy: 0.8396\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3874 - accuracy: 0.8655 - val_loss: 0.5125 - val_accuracy: 0.8396\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3805 - accuracy: 0.8614 - val_loss: 0.5087 - val_accuracy: 0.8396\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3780 - accuracy: 0.8635 - val_loss: 0.5050 - val_accuracy: 0.8396\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3707 - accuracy: 0.8655 - val_loss: 0.5021 - val_accuracy: 0.8433\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3647 - accuracy: 0.8795 - val_loss: 0.4992 - val_accuracy: 0.8433\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3736 - accuracy: 0.8655 - val_loss: 0.4965 - val_accuracy: 0.8433\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3603 - accuracy: 0.8755 - val_loss: 0.4938 - val_accuracy: 0.8433\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3655 - accuracy: 0.8735 - val_loss: 0.4919 - val_accuracy: 0.8433\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3618 - accuracy: 0.8855 - val_loss: 0.4896 - val_accuracy: 0.8433\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3667 - accuracy: 0.8675 - val_loss: 0.4878 - val_accuracy: 0.8433\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3639 - accuracy: 0.8675 - val_loss: 0.4861 - val_accuracy: 0.8433\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3622 - accuracy: 0.8815 - val_loss: 0.4847 - val_accuracy: 0.8433\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3622 - accuracy: 0.8655 - val_loss: 0.4830 - val_accuracy: 0.8433\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3548 - accuracy: 0.8715 - val_loss: 0.4815 - val_accuracy: 0.8396\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3539 - accuracy: 0.8675 - val_loss: 0.4803 - val_accuracy: 0.8396\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3677 - accuracy: 0.8655 - val_loss: 0.4793 - val_accuracy: 0.8396\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3577 - accuracy: 0.8755 - val_loss: 0.4781 - val_accuracy: 0.8396\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3482 - accuracy: 0.8775 - val_loss: 0.4775 - val_accuracy: 0.8396\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3470 - accuracy: 0.8775 - val_loss: 0.4765 - val_accuracy: 0.8396\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3561 - accuracy: 0.8715 - val_loss: 0.4760 - val_accuracy: 0.8396\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3646 - accuracy: 0.8614 - val_loss: 0.4745 - val_accuracy: 0.8396\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3463 - accuracy: 0.8655 - val_loss: 0.4741 - val_accuracy: 0.8358\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3483 - accuracy: 0.8835 - val_loss: 0.4745 - val_accuracy: 0.8396\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3460 - accuracy: 0.8715 - val_loss: 0.4752 - val_accuracy: 0.8396\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3422 - accuracy: 0.8715 - val_loss: 0.4756 - val_accuracy: 0.8358\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3438 - accuracy: 0.8675 - val_loss: 0.4757 - val_accuracy: 0.8358\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3425 - accuracy: 0.8775 - val_loss: 0.4756 - val_accuracy: 0.8358\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3386 - accuracy: 0.8715 - val_loss: 0.4752 - val_accuracy: 0.8358\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3417 - accuracy: 0.8755 - val_loss: 0.4749 - val_accuracy: 0.8358\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3400 - accuracy: 0.8855 - val_loss: 0.4742 - val_accuracy: 0.8358\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3340 - accuracy: 0.8775 - val_loss: 0.4738 - val_accuracy: 0.8358\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3432 - accuracy: 0.8775 - val_loss: 0.4738 - val_accuracy: 0.8358\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3416 - accuracy: 0.8795 - val_loss: 0.4737 - val_accuracy: 0.8358\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3471 - accuracy: 0.8735 - val_loss: 0.4734 - val_accuracy: 0.8358\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3431 - accuracy: 0.8695 - val_loss: 0.4735 - val_accuracy: 0.8396\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3424 - accuracy: 0.8695 - val_loss: 0.4737 - val_accuracy: 0.8396\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3335 - accuracy: 0.8735 - val_loss: 0.4737 - val_accuracy: 0.8396\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3352 - accuracy: 0.8755 - val_loss: 0.4736 - val_accuracy: 0.8396\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3437 - accuracy: 0.8715 - val_loss: 0.4728 - val_accuracy: 0.8396\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3316 - accuracy: 0.8755 - val_loss: 0.4721 - val_accuracy: 0.8396\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3218 - accuracy: 0.8835 - val_loss: 0.4718 - val_accuracy: 0.8396\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3344 - accuracy: 0.8695 - val_loss: 0.4722 - val_accuracy: 0.8396\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3257 - accuracy: 0.8795 - val_loss: 0.4725 - val_accuracy: 0.8396\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3342 - accuracy: 0.8695 - val_loss: 0.4721 - val_accuracy: 0.8396\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3244 - accuracy: 0.8815 - val_loss: 0.4714 - val_accuracy: 0.8321\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3293 - accuracy: 0.8775 - val_loss: 0.4713 - val_accuracy: 0.8321\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3313 - accuracy: 0.8715 - val_loss: 0.4717 - val_accuracy: 0.8321\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3304 - accuracy: 0.8715 - val_loss: 0.4716 - val_accuracy: 0.8284\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3242 - accuracy: 0.8835 - val_loss: 0.4718 - val_accuracy: 0.8321\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3214 - accuracy: 0.8855 - val_loss: 0.4735 - val_accuracy: 0.8284\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3278 - accuracy: 0.8715 - val_loss: 0.4741 - val_accuracy: 0.8246\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3219 - accuracy: 0.8835 - val_loss: 0.4736 - val_accuracy: 0.8284\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3247 - accuracy: 0.8755 - val_loss: 0.4738 - val_accuracy: 0.8246\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3284 - accuracy: 0.8795 - val_loss: 0.4747 - val_accuracy: 0.8209\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3191 - accuracy: 0.8795 - val_loss: 0.4752 - val_accuracy: 0.8209\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3188 - accuracy: 0.8815 - val_loss: 0.4757 - val_accuracy: 0.8134\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 498 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "498/498 [==============================] - 1s 1ms/step - loss: 0.9460 - accuracy: 0.4438 - val_loss: 0.7046 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.8467 - accuracy: 0.5141 - val_loss: 0.6968 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.7587 - accuracy: 0.6124 - val_loss: 0.6890 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.7003 - accuracy: 0.6466 - val_loss: 0.6810 - val_accuracy: 0.5970\n",
      "Epoch 5/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6558 - accuracy: 0.6888 - val_loss: 0.6735 - val_accuracy: 0.6194\n",
      "Epoch 6/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.6308 - accuracy: 0.7048 - val_loss: 0.6666 - val_accuracy: 0.6455\n",
      "Epoch 7/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.6118 - accuracy: 0.7048 - val_loss: 0.6607 - val_accuracy: 0.6567\n",
      "Epoch 8/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5818 - accuracy: 0.7369 - val_loss: 0.6550 - val_accuracy: 0.6530\n",
      "Epoch 9/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5685 - accuracy: 0.7510 - val_loss: 0.6495 - val_accuracy: 0.6642\n",
      "Epoch 10/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5428 - accuracy: 0.7490 - val_loss: 0.6444 - val_accuracy: 0.6754\n",
      "Epoch 11/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.5371 - accuracy: 0.7691 - val_loss: 0.6401 - val_accuracy: 0.6866\n",
      "Epoch 12/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.5358 - accuracy: 0.7711 - val_loss: 0.6364 - val_accuracy: 0.6828\n",
      "Epoch 13/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.5143 - accuracy: 0.7892 - val_loss: 0.6332 - val_accuracy: 0.6828\n",
      "Epoch 14/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4964 - accuracy: 0.7851 - val_loss: 0.6306 - val_accuracy: 0.6828\n",
      "Epoch 15/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4839 - accuracy: 0.8092 - val_loss: 0.6287 - val_accuracy: 0.6828\n",
      "Epoch 16/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4906 - accuracy: 0.7932 - val_loss: 0.6269 - val_accuracy: 0.6828\n",
      "Epoch 17/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.4616 - accuracy: 0.8213 - val_loss: 0.6252 - val_accuracy: 0.6866\n",
      "Epoch 18/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4764 - accuracy: 0.8012 - val_loss: 0.6243 - val_accuracy: 0.6940\n",
      "Epoch 19/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4703 - accuracy: 0.8072 - val_loss: 0.6233 - val_accuracy: 0.6978\n",
      "Epoch 20/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4556 - accuracy: 0.8173 - val_loss: 0.6216 - val_accuracy: 0.7015\n",
      "Epoch 21/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4593 - accuracy: 0.7972 - val_loss: 0.6202 - val_accuracy: 0.7052\n",
      "Epoch 22/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4501 - accuracy: 0.8253 - val_loss: 0.6185 - val_accuracy: 0.7164\n",
      "Epoch 23/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4431 - accuracy: 0.8112 - val_loss: 0.6182 - val_accuracy: 0.7201\n",
      "Epoch 24/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4318 - accuracy: 0.8253 - val_loss: 0.6171 - val_accuracy: 0.7201\n",
      "Epoch 25/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4376 - accuracy: 0.8112 - val_loss: 0.6160 - val_accuracy: 0.7239\n",
      "Epoch 26/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4377 - accuracy: 0.8273 - val_loss: 0.6146 - val_accuracy: 0.7239\n",
      "Epoch 27/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4216 - accuracy: 0.8353 - val_loss: 0.6142 - val_accuracy: 0.7276\n",
      "Epoch 28/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4259 - accuracy: 0.8213 - val_loss: 0.6139 - val_accuracy: 0.7351\n",
      "Epoch 29/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4287 - accuracy: 0.8293 - val_loss: 0.6136 - val_accuracy: 0.7351\n",
      "Epoch 30/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4087 - accuracy: 0.8474 - val_loss: 0.6133 - val_accuracy: 0.7388\n",
      "Epoch 31/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4202 - accuracy: 0.8333 - val_loss: 0.6135 - val_accuracy: 0.7388\n",
      "Epoch 32/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.4052 - accuracy: 0.8474 - val_loss: 0.6115 - val_accuracy: 0.7388\n",
      "Epoch 33/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4207 - accuracy: 0.8353 - val_loss: 0.6087 - val_accuracy: 0.7351\n",
      "Epoch 34/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4078 - accuracy: 0.8434 - val_loss: 0.6058 - val_accuracy: 0.7351\n",
      "Epoch 35/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.4043 - accuracy: 0.8534 - val_loss: 0.6042 - val_accuracy: 0.7425\n",
      "Epoch 36/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3983 - accuracy: 0.8474 - val_loss: 0.6011 - val_accuracy: 0.7388\n",
      "Epoch 37/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.4180 - accuracy: 0.8353 - val_loss: 0.6009 - val_accuracy: 0.7351\n",
      "Epoch 38/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.4068 - accuracy: 0.8353 - val_loss: 0.5981 - val_accuracy: 0.7313\n",
      "Epoch 39/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3906 - accuracy: 0.8594 - val_loss: 0.5964 - val_accuracy: 0.7313\n",
      "Epoch 40/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3997 - accuracy: 0.8574 - val_loss: 0.5946 - val_accuracy: 0.7313\n",
      "Epoch 41/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3922 - accuracy: 0.8534 - val_loss: 0.5903 - val_accuracy: 0.7313\n",
      "Epoch 42/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3800 - accuracy: 0.8675 - val_loss: 0.5858 - val_accuracy: 0.7313\n",
      "Epoch 43/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3844 - accuracy: 0.8715 - val_loss: 0.5878 - val_accuracy: 0.7313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3911 - accuracy: 0.8614 - val_loss: 0.5882 - val_accuracy: 0.7313\n",
      "Epoch 45/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3823 - accuracy: 0.8554 - val_loss: 0.5877 - val_accuracy: 0.7313\n",
      "Epoch 46/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3893 - accuracy: 0.8474 - val_loss: 0.5846 - val_accuracy: 0.7313\n",
      "Epoch 47/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3737 - accuracy: 0.8655 - val_loss: 0.5819 - val_accuracy: 0.7351\n",
      "Epoch 48/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3975 - accuracy: 0.8474 - val_loss: 0.5809 - val_accuracy: 0.7313\n",
      "Epoch 49/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3807 - accuracy: 0.8574 - val_loss: 0.5789 - val_accuracy: 0.7313\n",
      "Epoch 50/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3732 - accuracy: 0.8614 - val_loss: 0.5754 - val_accuracy: 0.7313\n",
      "Epoch 51/100\n",
      "498/498 [==============================] - 0s 88us/step - loss: 0.3911 - accuracy: 0.8554 - val_loss: 0.5724 - val_accuracy: 0.7313\n",
      "Epoch 52/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3750 - accuracy: 0.8655 - val_loss: 0.5706 - val_accuracy: 0.7313\n",
      "Epoch 53/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3856 - accuracy: 0.8534 - val_loss: 0.5709 - val_accuracy: 0.7351\n",
      "Epoch 54/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3755 - accuracy: 0.8635 - val_loss: 0.5672 - val_accuracy: 0.7388\n",
      "Epoch 55/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3764 - accuracy: 0.8534 - val_loss: 0.5641 - val_accuracy: 0.7463\n",
      "Epoch 56/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3772 - accuracy: 0.8635 - val_loss: 0.5567 - val_accuracy: 0.7463\n",
      "Epoch 57/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3827 - accuracy: 0.8514 - val_loss: 0.5537 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3748 - accuracy: 0.8594 - val_loss: 0.5513 - val_accuracy: 0.7463\n",
      "Epoch 59/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3880 - accuracy: 0.8574 - val_loss: 0.5506 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3772 - accuracy: 0.8635 - val_loss: 0.5561 - val_accuracy: 0.7537\n",
      "Epoch 61/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3819 - accuracy: 0.8554 - val_loss: 0.5560 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3789 - accuracy: 0.8534 - val_loss: 0.5549 - val_accuracy: 0.7537\n",
      "Epoch 63/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3661 - accuracy: 0.8675 - val_loss: 0.5532 - val_accuracy: 0.7537\n",
      "Epoch 64/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3617 - accuracy: 0.8755 - val_loss: 0.5523 - val_accuracy: 0.7575\n",
      "Epoch 65/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3618 - accuracy: 0.8614 - val_loss: 0.5563 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3727 - accuracy: 0.8635 - val_loss: 0.5573 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3696 - accuracy: 0.8574 - val_loss: 0.5572 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3708 - accuracy: 0.8675 - val_loss: 0.5560 - val_accuracy: 0.7463\n",
      "Epoch 69/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3685 - accuracy: 0.8735 - val_loss: 0.5522 - val_accuracy: 0.7575\n",
      "Epoch 70/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3546 - accuracy: 0.8735 - val_loss: 0.5514 - val_accuracy: 0.7649\n",
      "Epoch 71/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3771 - accuracy: 0.8635 - val_loss: 0.5491 - val_accuracy: 0.7724\n",
      "Epoch 72/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3537 - accuracy: 0.8795 - val_loss: 0.5494 - val_accuracy: 0.7612\n",
      "Epoch 73/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3603 - accuracy: 0.8655 - val_loss: 0.5476 - val_accuracy: 0.7687\n",
      "Epoch 74/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3682 - accuracy: 0.8574 - val_loss: 0.5495 - val_accuracy: 0.7612\n",
      "Epoch 75/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3586 - accuracy: 0.8594 - val_loss: 0.5489 - val_accuracy: 0.7687\n",
      "Epoch 76/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3686 - accuracy: 0.8594 - val_loss: 0.5443 - val_accuracy: 0.7761\n",
      "Epoch 77/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3793 - accuracy: 0.8474 - val_loss: 0.5418 - val_accuracy: 0.7873\n",
      "Epoch 78/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3549 - accuracy: 0.8675 - val_loss: 0.5409 - val_accuracy: 0.7910\n",
      "Epoch 79/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3559 - accuracy: 0.8735 - val_loss: 0.5411 - val_accuracy: 0.7873\n",
      "Epoch 80/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3608 - accuracy: 0.8614 - val_loss: 0.5395 - val_accuracy: 0.7910\n",
      "Epoch 81/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3589 - accuracy: 0.8715 - val_loss: 0.5376 - val_accuracy: 0.7910\n",
      "Epoch 82/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3605 - accuracy: 0.8775 - val_loss: 0.5384 - val_accuracy: 0.7873\n",
      "Epoch 83/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3634 - accuracy: 0.8655 - val_loss: 0.5364 - val_accuracy: 0.7985\n",
      "Epoch 84/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3515 - accuracy: 0.8655 - val_loss: 0.5365 - val_accuracy: 0.8022\n",
      "Epoch 85/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3610 - accuracy: 0.8514 - val_loss: 0.5364 - val_accuracy: 0.7985\n",
      "Epoch 86/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3631 - accuracy: 0.8574 - val_loss: 0.5399 - val_accuracy: 0.7910\n",
      "Epoch 87/100\n",
      "498/498 [==============================] - 0s 102us/step - loss: 0.3472 - accuracy: 0.8835 - val_loss: 0.5410 - val_accuracy: 0.7948\n",
      "Epoch 88/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3532 - accuracy: 0.8735 - val_loss: 0.5411 - val_accuracy: 0.7948\n",
      "Epoch 89/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3508 - accuracy: 0.8695 - val_loss: 0.5414 - val_accuracy: 0.7948\n",
      "Epoch 90/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3512 - accuracy: 0.8735 - val_loss: 0.5377 - val_accuracy: 0.7985\n",
      "Epoch 91/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3664 - accuracy: 0.8574 - val_loss: 0.5365 - val_accuracy: 0.7985\n",
      "Epoch 92/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3524 - accuracy: 0.8735 - val_loss: 0.5350 - val_accuracy: 0.7985\n",
      "Epoch 93/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3604 - accuracy: 0.8655 - val_loss: 0.5341 - val_accuracy: 0.7985\n",
      "Epoch 94/100\n",
      "498/498 [==============================] - 0s 94us/step - loss: 0.3545 - accuracy: 0.8574 - val_loss: 0.5367 - val_accuracy: 0.8022\n",
      "Epoch 95/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3477 - accuracy: 0.8735 - val_loss: 0.5365 - val_accuracy: 0.8060\n",
      "Epoch 96/100\n",
      "498/498 [==============================] - 0s 92us/step - loss: 0.3441 - accuracy: 0.8715 - val_loss: 0.5358 - val_accuracy: 0.8022\n",
      "Epoch 97/100\n",
      "498/498 [==============================] - 0s 98us/step - loss: 0.3718 - accuracy: 0.8594 - val_loss: 0.5395 - val_accuracy: 0.7985\n",
      "Epoch 98/100\n",
      "498/498 [==============================] - 0s 90us/step - loss: 0.3438 - accuracy: 0.8735 - val_loss: 0.5384 - val_accuracy: 0.8022\n",
      "Epoch 99/100\n",
      "498/498 [==============================] - 0s 96us/step - loss: 0.3469 - accuracy: 0.8614 - val_loss: 0.5364 - val_accuracy: 0.8022\n",
      "Epoch 100/100\n",
      "498/498 [==============================] - 0s 100us/step - loss: 0.3638 - accuracy: 0.8594 - val_loss: 0.5360 - val_accuracy: 0.8022\n",
      "125/125 [==============================] - 0s 24us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 1s 1ms/step - loss: 0.7224 - accuracy: 0.5591 - val_loss: 0.7457 - val_accuracy: 0.4291\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.6830 - accuracy: 0.5852 - val_loss: 0.7318 - val_accuracy: 0.4216\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.6441 - accuracy: 0.6653 - val_loss: 0.7201 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.6033 - accuracy: 0.7255 - val_loss: 0.7103 - val_accuracy: 0.7052\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.5763 - accuracy: 0.7555 - val_loss: 0.7015 - val_accuracy: 0.7052\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.5573 - accuracy: 0.7756 - val_loss: 0.6931 - val_accuracy: 0.6940\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.5431 - accuracy: 0.7856 - val_loss: 0.6853 - val_accuracy: 0.6940\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.5217 - accuracy: 0.7976 - val_loss: 0.6777 - val_accuracy: 0.6754\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.5065 - accuracy: 0.8016 - val_loss: 0.6706 - val_accuracy: 0.6754\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5144 - accuracy: 0.8176 - val_loss: 0.6641 - val_accuracy: 0.6791\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4909 - accuracy: 0.8176 - val_loss: 0.6578 - val_accuracy: 0.6791\n",
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4792 - accuracy: 0.8277 - val_loss: 0.6517 - val_accuracy: 0.6828\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4652 - accuracy: 0.8377 - val_loss: 0.6463 - val_accuracy: 0.6866\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4575 - accuracy: 0.8337 - val_loss: 0.6415 - val_accuracy: 0.6903\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4612 - accuracy: 0.8216 - val_loss: 0.6372 - val_accuracy: 0.6940\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4532 - accuracy: 0.8257 - val_loss: 0.6331 - val_accuracy: 0.6978\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4493 - accuracy: 0.8257 - val_loss: 0.6291 - val_accuracy: 0.6978\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4389 - accuracy: 0.8337 - val_loss: 0.6257 - val_accuracy: 0.6978\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4307 - accuracy: 0.8437 - val_loss: 0.6224 - val_accuracy: 0.6978\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4292 - accuracy: 0.8457 - val_loss: 0.6189 - val_accuracy: 0.6978\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4169 - accuracy: 0.8497 - val_loss: 0.6161 - val_accuracy: 0.6978\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.4196 - accuracy: 0.8377 - val_loss: 0.6134 - val_accuracy: 0.6978\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4118 - accuracy: 0.8517 - val_loss: 0.6109 - val_accuracy: 0.7052\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4060 - accuracy: 0.8377 - val_loss: 0.6084 - val_accuracy: 0.7052\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4060 - accuracy: 0.8477 - val_loss: 0.6061 - val_accuracy: 0.7090\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4028 - accuracy: 0.8417 - val_loss: 0.6045 - val_accuracy: 0.7090\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3940 - accuracy: 0.8457 - val_loss: 0.6026 - val_accuracy: 0.7090\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3873 - accuracy: 0.8577 - val_loss: 0.6012 - val_accuracy: 0.7090\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3945 - accuracy: 0.8617 - val_loss: 0.5994 - val_accuracy: 0.7127\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3881 - accuracy: 0.8497 - val_loss: 0.5979 - val_accuracy: 0.7127\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3899 - accuracy: 0.8437 - val_loss: 0.5967 - val_accuracy: 0.7090\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3873 - accuracy: 0.8577 - val_loss: 0.5954 - val_accuracy: 0.7052\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3770 - accuracy: 0.8557 - val_loss: 0.5935 - val_accuracy: 0.7090\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3756 - accuracy: 0.8597 - val_loss: 0.5914 - val_accuracy: 0.7090\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3724 - accuracy: 0.8657 - val_loss: 0.5894 - val_accuracy: 0.7164\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3793 - accuracy: 0.8537 - val_loss: 0.5867 - val_accuracy: 0.7201\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3771 - accuracy: 0.8597 - val_loss: 0.5840 - val_accuracy: 0.7201\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3655 - accuracy: 0.8637 - val_loss: 0.5819 - val_accuracy: 0.7201\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3612 - accuracy: 0.8697 - val_loss: 0.5802 - val_accuracy: 0.7201\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3636 - accuracy: 0.8597 - val_loss: 0.5785 - val_accuracy: 0.7201\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3653 - accuracy: 0.8657 - val_loss: 0.5761 - val_accuracy: 0.7201\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3620 - accuracy: 0.8758 - val_loss: 0.5738 - val_accuracy: 0.7239\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3550 - accuracy: 0.8717 - val_loss: 0.5711 - val_accuracy: 0.7201\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3643 - accuracy: 0.8577 - val_loss: 0.5688 - val_accuracy: 0.7276\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3589 - accuracy: 0.8697 - val_loss: 0.5670 - val_accuracy: 0.7313\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3444 - accuracy: 0.8778 - val_loss: 0.5653 - val_accuracy: 0.7313\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3523 - accuracy: 0.8697 - val_loss: 0.5638 - val_accuracy: 0.7463\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3463 - accuracy: 0.8677 - val_loss: 0.5619 - val_accuracy: 0.7463\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3462 - accuracy: 0.8778 - val_loss: 0.5592 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 88us/step - loss: 0.3452 - accuracy: 0.8597 - val_loss: 0.5563 - val_accuracy: 0.7463\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3423 - accuracy: 0.8758 - val_loss: 0.5550 - val_accuracy: 0.7463\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3456 - accuracy: 0.8778 - val_loss: 0.5527 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3501 - accuracy: 0.8657 - val_loss: 0.5513 - val_accuracy: 0.7575\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3499 - accuracy: 0.8737 - val_loss: 0.5488 - val_accuracy: 0.7649\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3435 - accuracy: 0.8737 - val_loss: 0.5454 - val_accuracy: 0.7687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3380 - accuracy: 0.8798 - val_loss: 0.5424 - val_accuracy: 0.7687\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3453 - accuracy: 0.8838 - val_loss: 0.5399 - val_accuracy: 0.7724\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3507 - accuracy: 0.8677 - val_loss: 0.5365 - val_accuracy: 0.7799\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3425 - accuracy: 0.8778 - val_loss: 0.5334 - val_accuracy: 0.7799\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3423 - accuracy: 0.8758 - val_loss: 0.5312 - val_accuracy: 0.7799\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3301 - accuracy: 0.8838 - val_loss: 0.5298 - val_accuracy: 0.7687\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3329 - accuracy: 0.8717 - val_loss: 0.5278 - val_accuracy: 0.7687\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3355 - accuracy: 0.8798 - val_loss: 0.5254 - val_accuracy: 0.7687\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3316 - accuracy: 0.8697 - val_loss: 0.5228 - val_accuracy: 0.7761\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3313 - accuracy: 0.8758 - val_loss: 0.5203 - val_accuracy: 0.7761\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3284 - accuracy: 0.8798 - val_loss: 0.5193 - val_accuracy: 0.7761\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3317 - accuracy: 0.8758 - val_loss: 0.5172 - val_accuracy: 0.7761\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3434 - accuracy: 0.8737 - val_loss: 0.5161 - val_accuracy: 0.7761\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3275 - accuracy: 0.8818 - val_loss: 0.5132 - val_accuracy: 0.7761\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3274 - accuracy: 0.8898 - val_loss: 0.5109 - val_accuracy: 0.7761\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3282 - accuracy: 0.8798 - val_loss: 0.5103 - val_accuracy: 0.7761\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3233 - accuracy: 0.8818 - val_loss: 0.5111 - val_accuracy: 0.7761\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3296 - accuracy: 0.8798 - val_loss: 0.5111 - val_accuracy: 0.7761\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3202 - accuracy: 0.8898 - val_loss: 0.5093 - val_accuracy: 0.7761\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3235 - accuracy: 0.8858 - val_loss: 0.5075 - val_accuracy: 0.7761\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3291 - accuracy: 0.8778 - val_loss: 0.5051 - val_accuracy: 0.7761\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3219 - accuracy: 0.8918 - val_loss: 0.5037 - val_accuracy: 0.7761\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3220 - accuracy: 0.8918 - val_loss: 0.5015 - val_accuracy: 0.7799\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3165 - accuracy: 0.8778 - val_loss: 0.4992 - val_accuracy: 0.7799\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3126 - accuracy: 0.8958 - val_loss: 0.4964 - val_accuracy: 0.7836\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3228 - accuracy: 0.8858 - val_loss: 0.4947 - val_accuracy: 0.7836\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3209 - accuracy: 0.8818 - val_loss: 0.4936 - val_accuracy: 0.7799\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3190 - accuracy: 0.8938 - val_loss: 0.4935 - val_accuracy: 0.7836\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3195 - accuracy: 0.8898 - val_loss: 0.4912 - val_accuracy: 0.7799\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3181 - accuracy: 0.8958 - val_loss: 0.4904 - val_accuracy: 0.7799\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3271 - accuracy: 0.8818 - val_loss: 0.4874 - val_accuracy: 0.7836\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3136 - accuracy: 0.8938 - val_loss: 0.4866 - val_accuracy: 0.7836\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3079 - accuracy: 0.8898 - val_loss: 0.4859 - val_accuracy: 0.7836\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3197 - accuracy: 0.8838 - val_loss: 0.4856 - val_accuracy: 0.7761\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3202 - accuracy: 0.8758 - val_loss: 0.4864 - val_accuracy: 0.7799\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3168 - accuracy: 0.8898 - val_loss: 0.4860 - val_accuracy: 0.7873\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3054 - accuracy: 0.9018 - val_loss: 0.4846 - val_accuracy: 0.7873\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3120 - accuracy: 0.8878 - val_loss: 0.4827 - val_accuracy: 0.7836\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3107 - accuracy: 0.8878 - val_loss: 0.4822 - val_accuracy: 0.7873\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3221 - accuracy: 0.8878 - val_loss: 0.4801 - val_accuracy: 0.7873\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3250 - accuracy: 0.8978 - val_loss: 0.4799 - val_accuracy: 0.7873\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3131 - accuracy: 0.8858 - val_loss: 0.4794 - val_accuracy: 0.7873\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3100 - accuracy: 0.8858 - val_loss: 0.4804 - val_accuracy: 0.7836\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3040 - accuracy: 0.9018 - val_loss: 0.4810 - val_accuracy: 0.7836\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3156 - accuracy: 0.8858 - val_loss: 0.4809 - val_accuracy: 0.7836\n",
      "124/124 [==============================] - 0s 24us/step\n",
      "Train on 499 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "499/499 [==============================] - 1s 1ms/step - loss: 0.7134 - accuracy: 0.6212 - val_loss: 1.0582 - val_accuracy: 0.3881\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.6750 - accuracy: 0.6493 - val_loss: 1.0167 - val_accuracy: 0.3918\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.6484 - accuracy: 0.6814 - val_loss: 0.9796 - val_accuracy: 0.3918\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.6189 - accuracy: 0.7435 - val_loss: 0.9460 - val_accuracy: 0.3918\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.6010 - accuracy: 0.7555 - val_loss: 0.9145 - val_accuracy: 0.3955\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.5725 - accuracy: 0.7756 - val_loss: 0.8867 - val_accuracy: 0.3881\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5579 - accuracy: 0.7715 - val_loss: 0.8607 - val_accuracy: 0.3918\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5424 - accuracy: 0.7675 - val_loss: 0.8382 - val_accuracy: 0.3955\n",
      "Epoch 9/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5187 - accuracy: 0.7876 - val_loss: 0.8183 - val_accuracy: 0.4030\n",
      "Epoch 10/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5254 - accuracy: 0.7856 - val_loss: 0.7996 - val_accuracy: 0.4067\n",
      "Epoch 11/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.5162 - accuracy: 0.8016 - val_loss: 0.7817 - val_accuracy: 0.4291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.5021 - accuracy: 0.7936 - val_loss: 0.7633 - val_accuracy: 0.4963\n",
      "Epoch 13/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4907 - accuracy: 0.8096 - val_loss: 0.7479 - val_accuracy: 0.5261\n",
      "Epoch 14/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4850 - accuracy: 0.8136 - val_loss: 0.7324 - val_accuracy: 0.5634\n",
      "Epoch 15/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4725 - accuracy: 0.8176 - val_loss: 0.7166 - val_accuracy: 0.5709\n",
      "Epoch 16/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4630 - accuracy: 0.8116 - val_loss: 0.7035 - val_accuracy: 0.6194\n",
      "Epoch 17/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4525 - accuracy: 0.8136 - val_loss: 0.6912 - val_accuracy: 0.6343\n",
      "Epoch 18/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4487 - accuracy: 0.8236 - val_loss: 0.6806 - val_accuracy: 0.6493\n",
      "Epoch 19/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4498 - accuracy: 0.8176 - val_loss: 0.6711 - val_accuracy: 0.6866\n",
      "Epoch 20/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4415 - accuracy: 0.8297 - val_loss: 0.6623 - val_accuracy: 0.6903\n",
      "Epoch 21/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4302 - accuracy: 0.8216 - val_loss: 0.6532 - val_accuracy: 0.7090\n",
      "Epoch 22/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4272 - accuracy: 0.8156 - val_loss: 0.6457 - val_accuracy: 0.7164\n",
      "Epoch 23/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4197 - accuracy: 0.8257 - val_loss: 0.6386 - val_accuracy: 0.7351\n",
      "Epoch 24/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4203 - accuracy: 0.8277 - val_loss: 0.6324 - val_accuracy: 0.7239\n",
      "Epoch 25/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4155 - accuracy: 0.8417 - val_loss: 0.6275 - val_accuracy: 0.7239\n",
      "Epoch 26/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4165 - accuracy: 0.8257 - val_loss: 0.6216 - val_accuracy: 0.7239\n",
      "Epoch 27/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4028 - accuracy: 0.8437 - val_loss: 0.6176 - val_accuracy: 0.7201\n",
      "Epoch 28/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.4026 - accuracy: 0.8377 - val_loss: 0.6140 - val_accuracy: 0.7164\n",
      "Epoch 29/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.4051 - accuracy: 0.8257 - val_loss: 0.6100 - val_accuracy: 0.7164\n",
      "Epoch 30/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3995 - accuracy: 0.8457 - val_loss: 0.6064 - val_accuracy: 0.7164\n",
      "Epoch 31/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3923 - accuracy: 0.8537 - val_loss: 0.6019 - val_accuracy: 0.7201\n",
      "Epoch 32/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.4072 - accuracy: 0.8357 - val_loss: 0.5983 - val_accuracy: 0.7164\n",
      "Epoch 33/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3982 - accuracy: 0.8537 - val_loss: 0.5950 - val_accuracy: 0.7239\n",
      "Epoch 34/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3972 - accuracy: 0.8477 - val_loss: 0.5932 - val_accuracy: 0.7201\n",
      "Epoch 35/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3927 - accuracy: 0.8557 - val_loss: 0.5917 - val_accuracy: 0.7239\n",
      "Epoch 36/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3857 - accuracy: 0.8577 - val_loss: 0.5879 - val_accuracy: 0.7276\n",
      "Epoch 37/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3923 - accuracy: 0.8397 - val_loss: 0.5854 - val_accuracy: 0.7313\n",
      "Epoch 38/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3759 - accuracy: 0.8637 - val_loss: 0.5837 - val_accuracy: 0.7388\n",
      "Epoch 39/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3817 - accuracy: 0.8617 - val_loss: 0.5820 - val_accuracy: 0.7351\n",
      "Epoch 40/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3871 - accuracy: 0.8537 - val_loss: 0.5803 - val_accuracy: 0.7313\n",
      "Epoch 41/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3788 - accuracy: 0.8617 - val_loss: 0.5781 - val_accuracy: 0.7388\n",
      "Epoch 42/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3695 - accuracy: 0.8637 - val_loss: 0.5752 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3741 - accuracy: 0.8557 - val_loss: 0.5729 - val_accuracy: 0.7537\n",
      "Epoch 44/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3827 - accuracy: 0.8577 - val_loss: 0.5710 - val_accuracy: 0.7575\n",
      "Epoch 45/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3662 - accuracy: 0.8737 - val_loss: 0.5682 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3710 - accuracy: 0.8657 - val_loss: 0.5673 - val_accuracy: 0.7575\n",
      "Epoch 47/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3678 - accuracy: 0.8657 - val_loss: 0.5680 - val_accuracy: 0.7537\n",
      "Epoch 48/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3674 - accuracy: 0.8737 - val_loss: 0.5683 - val_accuracy: 0.7612\n",
      "Epoch 49/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3616 - accuracy: 0.8637 - val_loss: 0.5671 - val_accuracy: 0.7649\n",
      "Epoch 50/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3752 - accuracy: 0.8657 - val_loss: 0.5646 - val_accuracy: 0.7724\n",
      "Epoch 51/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3571 - accuracy: 0.8577 - val_loss: 0.5614 - val_accuracy: 0.7761\n",
      "Epoch 52/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3549 - accuracy: 0.8617 - val_loss: 0.5588 - val_accuracy: 0.7761\n",
      "Epoch 53/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3533 - accuracy: 0.8697 - val_loss: 0.5582 - val_accuracy: 0.7761\n",
      "Epoch 54/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3555 - accuracy: 0.8717 - val_loss: 0.5580 - val_accuracy: 0.7724\n",
      "Epoch 55/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3561 - accuracy: 0.8717 - val_loss: 0.5572 - val_accuracy: 0.7799\n",
      "Epoch 56/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3587 - accuracy: 0.8717 - val_loss: 0.5560 - val_accuracy: 0.7799\n",
      "Epoch 57/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3511 - accuracy: 0.8778 - val_loss: 0.5572 - val_accuracy: 0.7761\n",
      "Epoch 58/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3562 - accuracy: 0.8737 - val_loss: 0.5569 - val_accuracy: 0.7724\n",
      "Epoch 59/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3620 - accuracy: 0.8697 - val_loss: 0.5545 - val_accuracy: 0.7761\n",
      "Epoch 60/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3506 - accuracy: 0.8717 - val_loss: 0.5515 - val_accuracy: 0.7799\n",
      "Epoch 61/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3408 - accuracy: 0.8778 - val_loss: 0.5516 - val_accuracy: 0.7761\n",
      "Epoch 62/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3406 - accuracy: 0.8758 - val_loss: 0.5499 - val_accuracy: 0.7761\n",
      "Epoch 63/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3395 - accuracy: 0.8798 - val_loss: 0.5509 - val_accuracy: 0.7724\n",
      "Epoch 64/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3470 - accuracy: 0.8677 - val_loss: 0.5506 - val_accuracy: 0.7724\n",
      "Epoch 65/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3413 - accuracy: 0.8758 - val_loss: 0.5472 - val_accuracy: 0.7724\n",
      "Epoch 66/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3365 - accuracy: 0.8798 - val_loss: 0.5433 - val_accuracy: 0.7873\n",
      "Epoch 67/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3359 - accuracy: 0.8798 - val_loss: 0.5423 - val_accuracy: 0.7836\n",
      "Epoch 68/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3275 - accuracy: 0.8858 - val_loss: 0.5429 - val_accuracy: 0.7799\n",
      "Epoch 69/100\n",
      "499/499 [==============================] - 0s 98us/step - loss: 0.3378 - accuracy: 0.8798 - val_loss: 0.5435 - val_accuracy: 0.7799\n",
      "Epoch 70/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3356 - accuracy: 0.8838 - val_loss: 0.5450 - val_accuracy: 0.7799\n",
      "Epoch 71/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3261 - accuracy: 0.8858 - val_loss: 0.5419 - val_accuracy: 0.7799\n",
      "Epoch 72/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3329 - accuracy: 0.8798 - val_loss: 0.5382 - val_accuracy: 0.7761\n",
      "Epoch 73/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3379 - accuracy: 0.8838 - val_loss: 0.5324 - val_accuracy: 0.7761\n",
      "Epoch 74/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3281 - accuracy: 0.8798 - val_loss: 0.5319 - val_accuracy: 0.7761\n",
      "Epoch 75/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3176 - accuracy: 0.8858 - val_loss: 0.5308 - val_accuracy: 0.7761\n",
      "Epoch 76/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3383 - accuracy: 0.8717 - val_loss: 0.5336 - val_accuracy: 0.7761\n",
      "Epoch 77/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3248 - accuracy: 0.8818 - val_loss: 0.5300 - val_accuracy: 0.7799\n",
      "Epoch 78/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3345 - accuracy: 0.8838 - val_loss: 0.5277 - val_accuracy: 0.7799\n",
      "Epoch 79/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3288 - accuracy: 0.8798 - val_loss: 0.5295 - val_accuracy: 0.7761\n",
      "Epoch 80/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3234 - accuracy: 0.8778 - val_loss: 0.5312 - val_accuracy: 0.7799\n",
      "Epoch 81/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3199 - accuracy: 0.8898 - val_loss: 0.5318 - val_accuracy: 0.7799\n",
      "Epoch 82/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3454 - accuracy: 0.8798 - val_loss: 0.5284 - val_accuracy: 0.7836\n",
      "Epoch 83/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3173 - accuracy: 0.8858 - val_loss: 0.5231 - val_accuracy: 0.7836\n",
      "Epoch 84/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3139 - accuracy: 0.9018 - val_loss: 0.5216 - val_accuracy: 0.7873\n",
      "Epoch 85/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3259 - accuracy: 0.8818 - val_loss: 0.5221 - val_accuracy: 0.7799\n",
      "Epoch 86/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3213 - accuracy: 0.8878 - val_loss: 0.5147 - val_accuracy: 0.7799\n",
      "Epoch 87/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3230 - accuracy: 0.8818 - val_loss: 0.5130 - val_accuracy: 0.7799\n",
      "Epoch 88/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3171 - accuracy: 0.8818 - val_loss: 0.5197 - val_accuracy: 0.7799\n",
      "Epoch 89/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3281 - accuracy: 0.8838 - val_loss: 0.5196 - val_accuracy: 0.7799\n",
      "Epoch 90/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3067 - accuracy: 0.8918 - val_loss: 0.5157 - val_accuracy: 0.7799\n",
      "Epoch 91/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3130 - accuracy: 0.8818 - val_loss: 0.5128 - val_accuracy: 0.7799\n",
      "Epoch 92/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3235 - accuracy: 0.8858 - val_loss: 0.5134 - val_accuracy: 0.7836\n",
      "Epoch 93/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3133 - accuracy: 0.8938 - val_loss: 0.5187 - val_accuracy: 0.7799\n",
      "Epoch 94/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3294 - accuracy: 0.8717 - val_loss: 0.5236 - val_accuracy: 0.7799\n",
      "Epoch 95/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3103 - accuracy: 0.8958 - val_loss: 0.5209 - val_accuracy: 0.7836\n",
      "Epoch 96/100\n",
      "499/499 [==============================] - 0s 92us/step - loss: 0.3059 - accuracy: 0.8858 - val_loss: 0.5221 - val_accuracy: 0.7836\n",
      "Epoch 97/100\n",
      "499/499 [==============================] - 0s 94us/step - loss: 0.3097 - accuracy: 0.8938 - val_loss: 0.5199 - val_accuracy: 0.7836\n",
      "Epoch 98/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3035 - accuracy: 0.8938 - val_loss: 0.5160 - val_accuracy: 0.7836\n",
      "Epoch 99/100\n",
      "499/499 [==============================] - 0s 96us/step - loss: 0.3236 - accuracy: 0.8758 - val_loss: 0.5203 - val_accuracy: 0.7836\n",
      "Epoch 100/100\n",
      "499/499 [==============================] - 0s 90us/step - loss: 0.3123 - accuracy: 0.8858 - val_loss: 0.5171 - val_accuracy: 0.7873\n",
      "124/124 [==============================] - 0s 16us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "623/623 [==============================] - 0s 706us/step - loss: 0.6833 - accuracy: 0.7127 - val_loss: 0.9108 - val_accuracy: 0.3881\n",
      "Epoch 2/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.6318 - accuracy: 0.7416 - val_loss: 0.8711 - val_accuracy: 0.3657\n",
      "Epoch 3/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.6230 - accuracy: 0.7352 - val_loss: 0.8388 - val_accuracy: 0.3507\n",
      "Epoch 4/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.5837 - accuracy: 0.7560 - val_loss: 0.8110 - val_accuracy: 0.3918\n",
      "Epoch 5/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.5647 - accuracy: 0.7544 - val_loss: 0.7874 - val_accuracy: 0.3769\n",
      "Epoch 6/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.5386 - accuracy: 0.7753 - val_loss: 0.7673 - val_accuracy: 0.3843\n",
      "Epoch 7/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.5263 - accuracy: 0.7801 - val_loss: 0.7499 - val_accuracy: 0.3918\n",
      "Epoch 8/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.5174 - accuracy: 0.7769 - val_loss: 0.7339 - val_accuracy: 0.4701\n",
      "Epoch 9/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4967 - accuracy: 0.7865 - val_loss: 0.7187 - val_accuracy: 0.5522\n",
      "Epoch 10/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4833 - accuracy: 0.7817 - val_loss: 0.7065 - val_accuracy: 0.5746\n",
      "Epoch 11/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4808 - accuracy: 0.7769 - val_loss: 0.6959 - val_accuracy: 0.6194\n",
      "Epoch 12/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4741 - accuracy: 0.7833 - val_loss: 0.6855 - val_accuracy: 0.6604\n",
      "Epoch 13/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4546 - accuracy: 0.7833 - val_loss: 0.6765 - val_accuracy: 0.6754\n",
      "Epoch 14/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4667 - accuracy: 0.7945 - val_loss: 0.6683 - val_accuracy: 0.6754\n",
      "Epoch 15/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4564 - accuracy: 0.7817 - val_loss: 0.6608 - val_accuracy: 0.6754\n",
      "Epoch 16/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4505 - accuracy: 0.7994 - val_loss: 0.6519 - val_accuracy: 0.6791\n",
      "Epoch 17/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4431 - accuracy: 0.7961 - val_loss: 0.6436 - val_accuracy: 0.6716\n",
      "Epoch 18/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4353 - accuracy: 0.8106 - val_loss: 0.6366 - val_accuracy: 0.6716\n",
      "Epoch 19/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4403 - accuracy: 0.8138 - val_loss: 0.6303 - val_accuracy: 0.6866\n",
      "Epoch 20/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4296 - accuracy: 0.8042 - val_loss: 0.6255 - val_accuracy: 0.6903\n",
      "Epoch 21/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4195 - accuracy: 0.8202 - val_loss: 0.6208 - val_accuracy: 0.6978\n",
      "Epoch 22/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4276 - accuracy: 0.8154 - val_loss: 0.6151 - val_accuracy: 0.7090\n",
      "Epoch 23/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4156 - accuracy: 0.8154 - val_loss: 0.6100 - val_accuracy: 0.7052\n",
      "Epoch 24/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4115 - accuracy: 0.8331 - val_loss: 0.6059 - val_accuracy: 0.7090\n",
      "Epoch 25/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4093 - accuracy: 0.8186 - val_loss: 0.6019 - val_accuracy: 0.7201\n",
      "Epoch 26/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3997 - accuracy: 0.8395 - val_loss: 0.5979 - val_accuracy: 0.7239\n",
      "Epoch 27/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3973 - accuracy: 0.8283 - val_loss: 0.5930 - val_accuracy: 0.7276\n",
      "Epoch 28/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3942 - accuracy: 0.8331 - val_loss: 0.5878 - val_accuracy: 0.7239\n",
      "Epoch 29/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3928 - accuracy: 0.8395 - val_loss: 0.5832 - val_accuracy: 0.7239\n",
      "Epoch 30/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3860 - accuracy: 0.8459 - val_loss: 0.5776 - val_accuracy: 0.7276\n",
      "Epoch 31/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3882 - accuracy: 0.8331 - val_loss: 0.5731 - val_accuracy: 0.7313\n",
      "Epoch 32/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3876 - accuracy: 0.8218 - val_loss: 0.5688 - val_accuracy: 0.7351\n",
      "Epoch 33/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3812 - accuracy: 0.8459 - val_loss: 0.5644 - val_accuracy: 0.7351\n",
      "Epoch 34/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3765 - accuracy: 0.8475 - val_loss: 0.5606 - val_accuracy: 0.7351\n",
      "Epoch 35/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3771 - accuracy: 0.8475 - val_loss: 0.5557 - val_accuracy: 0.7388\n",
      "Epoch 36/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3803 - accuracy: 0.8475 - val_loss: 0.5522 - val_accuracy: 0.7425\n",
      "Epoch 37/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3718 - accuracy: 0.8523 - val_loss: 0.5490 - val_accuracy: 0.7425\n",
      "Epoch 38/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3731 - accuracy: 0.8523 - val_loss: 0.5469 - val_accuracy: 0.7425\n",
      "Epoch 39/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3671 - accuracy: 0.8571 - val_loss: 0.5444 - val_accuracy: 0.7463\n",
      "Epoch 40/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3599 - accuracy: 0.8555 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3670 - accuracy: 0.8507 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3616 - accuracy: 0.8652 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3649 - accuracy: 0.8571 - val_loss: 0.5328 - val_accuracy: 0.7537\n",
      "Epoch 44/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3572 - accuracy: 0.8652 - val_loss: 0.5300 - val_accuracy: 0.7612\n",
      "Epoch 45/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3582 - accuracy: 0.8555 - val_loss: 0.5280 - val_accuracy: 0.7687\n",
      "Epoch 46/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3609 - accuracy: 0.8604 - val_loss: 0.5253 - val_accuracy: 0.7761\n",
      "Epoch 47/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3555 - accuracy: 0.8443 - val_loss: 0.5199 - val_accuracy: 0.7873\n",
      "Epoch 48/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3597 - accuracy: 0.8491 - val_loss: 0.5169 - val_accuracy: 0.7873\n",
      "Epoch 49/100\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3627 - accuracy: 0.8555 - val_loss: 0.5131 - val_accuracy: 0.7910\n",
      "Epoch 50/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3426 - accuracy: 0.8684 - val_loss: 0.5112 - val_accuracy: 0.7948\n",
      "Epoch 51/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3535 - accuracy: 0.8571 - val_loss: 0.5085 - val_accuracy: 0.7910\n",
      "Epoch 52/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3455 - accuracy: 0.8587 - val_loss: 0.5054 - val_accuracy: 0.7948\n",
      "Epoch 53/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3482 - accuracy: 0.8636 - val_loss: 0.5037 - val_accuracy: 0.7948\n",
      "Epoch 54/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3448 - accuracy: 0.8764 - val_loss: 0.5013 - val_accuracy: 0.7948\n",
      "Epoch 55/100\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3457 - accuracy: 0.8587 - val_loss: 0.5000 - val_accuracy: 0.8022\n",
      "Epoch 56/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3456 - accuracy: 0.8620 - val_loss: 0.4990 - val_accuracy: 0.8097\n",
      "Epoch 57/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3491 - accuracy: 0.8652 - val_loss: 0.4972 - val_accuracy: 0.8060\n",
      "Epoch 58/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3421 - accuracy: 0.8571 - val_loss: 0.4950 - val_accuracy: 0.8097\n",
      "Epoch 59/100\n",
      "623/623 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - 0s 72us/step - loss: 0.3424 - accuracy: 0.8539 - val_loss: 0.4931 - val_accuracy: 0.8097\n",
      "Epoch 60/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3340 - accuracy: 0.8716 - val_loss: 0.4903 - val_accuracy: 0.8097\n",
      "Epoch 61/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3412 - accuracy: 0.8507 - val_loss: 0.4884 - val_accuracy: 0.8097\n",
      "Epoch 62/100\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3368 - accuracy: 0.8700 - val_loss: 0.4866 - val_accuracy: 0.8097\n",
      "Epoch 63/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3449 - accuracy: 0.8636 - val_loss: 0.4841 - val_accuracy: 0.8097\n",
      "Epoch 64/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3387 - accuracy: 0.8684 - val_loss: 0.4835 - val_accuracy: 0.8097\n",
      "Epoch 65/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3367 - accuracy: 0.8700 - val_loss: 0.4834 - val_accuracy: 0.8134\n",
      "Epoch 66/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3414 - accuracy: 0.8636 - val_loss: 0.4820 - val_accuracy: 0.8172\n",
      "Epoch 67/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3368 - accuracy: 0.8732 - val_loss: 0.4800 - val_accuracy: 0.8172\n",
      "Epoch 68/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3408 - accuracy: 0.8684 - val_loss: 0.4781 - val_accuracy: 0.8358\n",
      "Epoch 69/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3370 - accuracy: 0.8668 - val_loss: 0.4775 - val_accuracy: 0.8358\n",
      "Epoch 70/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3422 - accuracy: 0.8587 - val_loss: 0.4777 - val_accuracy: 0.8358\n",
      "Epoch 71/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3352 - accuracy: 0.8668 - val_loss: 0.4784 - val_accuracy: 0.8358\n",
      "Epoch 72/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3314 - accuracy: 0.8684 - val_loss: 0.4769 - val_accuracy: 0.8321\n",
      "Epoch 73/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3379 - accuracy: 0.8652 - val_loss: 0.4739 - val_accuracy: 0.8358\n",
      "Epoch 74/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3310 - accuracy: 0.8636 - val_loss: 0.4721 - val_accuracy: 0.8396\n",
      "Epoch 75/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3308 - accuracy: 0.8716 - val_loss: 0.4704 - val_accuracy: 0.8358\n",
      "Epoch 76/100\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3278 - accuracy: 0.8748 - val_loss: 0.4707 - val_accuracy: 0.8321\n",
      "Epoch 77/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3423 - accuracy: 0.8732 - val_loss: 0.4707 - val_accuracy: 0.8321\n",
      "Epoch 78/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3295 - accuracy: 0.8668 - val_loss: 0.4721 - val_accuracy: 0.8284\n",
      "Epoch 79/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3327 - accuracy: 0.8652 - val_loss: 0.4730 - val_accuracy: 0.8321\n",
      "Epoch 80/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3331 - accuracy: 0.8636 - val_loss: 0.4725 - val_accuracy: 0.8284\n",
      "Epoch 81/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3307 - accuracy: 0.8636 - val_loss: 0.4723 - val_accuracy: 0.8284\n",
      "Epoch 82/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3266 - accuracy: 0.8716 - val_loss: 0.4715 - val_accuracy: 0.8246\n",
      "Epoch 83/100\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3289 - accuracy: 0.8700 - val_loss: 0.4710 - val_accuracy: 0.8321\n",
      "Epoch 84/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3319 - accuracy: 0.8636 - val_loss: 0.4718 - val_accuracy: 0.8284\n",
      "Epoch 85/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3316 - accuracy: 0.8700 - val_loss: 0.4731 - val_accuracy: 0.8246\n",
      "Epoch 86/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3319 - accuracy: 0.8716 - val_loss: 0.4746 - val_accuracy: 0.8246\n",
      "Epoch 87/100\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3260 - accuracy: 0.8732 - val_loss: 0.4761 - val_accuracy: 0.8284\n",
      "Epoch 88/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3351 - accuracy: 0.8668 - val_loss: 0.4763 - val_accuracy: 0.8284\n",
      "Epoch 89/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3250 - accuracy: 0.8684 - val_loss: 0.4764 - val_accuracy: 0.8284\n",
      "Epoch 90/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3269 - accuracy: 0.8700 - val_loss: 0.4769 - val_accuracy: 0.8284\n",
      "Epoch 91/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3246 - accuracy: 0.8796 - val_loss: 0.4769 - val_accuracy: 0.8284\n",
      "Epoch 92/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3300 - accuracy: 0.8748 - val_loss: 0.4757 - val_accuracy: 0.8284\n",
      "Epoch 93/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3283 - accuracy: 0.8780 - val_loss: 0.4744 - val_accuracy: 0.8284\n",
      "Epoch 94/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3231 - accuracy: 0.8764 - val_loss: 0.4745 - val_accuracy: 0.8284\n",
      "Epoch 95/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3403 - accuracy: 0.8620 - val_loss: 0.4744 - val_accuracy: 0.8246\n",
      "Epoch 96/100\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3240 - accuracy: 0.8764 - val_loss: 0.4756 - val_accuracy: 0.8246\n",
      "Epoch 97/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3269 - accuracy: 0.8716 - val_loss: 0.4767 - val_accuracy: 0.8246\n",
      "Epoch 98/100\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3303 - accuracy: 0.8748 - val_loss: 0.4771 - val_accuracy: 0.8246\n",
      "Epoch 99/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3250 - accuracy: 0.8748 - val_loss: 0.4760 - val_accuracy: 0.8284\n",
      "Epoch 100/100\n",
      "623/623 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.89 - 0s 69us/step - loss: 0.3252 - accuracy: 0.8748 - val_loss: 0.4759 - val_accuracy: 0.8284\n"
     ]
    }
   ],
   "source": [
    "## early_stopping and GridSearch\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True)\n",
    "grid_model = KerasClassifier(build_fn=build_model, verbose=1)\n",
    "\n",
    "batch_size=[128]\n",
    "layer=[1,2]\n",
    "epochs=[100]\n",
    "neurons= [6,8,10]\n",
    "param_grid = dict(neurons=neurons, epochs=epochs,layer=layer,batch_size=batch_size)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=grid_model, param_grid=param_grid, cv=5, verbose=1)  \n",
    "\n",
    "grid_history = grid.fit(X_train, y_train, validation_data=(X_val, y_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490709662437439\n",
      "{'batch_size': 128, 'epochs': 100, 'layer': 1, 'neurons': 8}\n"
     ]
    }
   ],
   "source": [
    "print(grid_history.best_score_)\n",
    "print(grid_history.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store the best model\n",
    "\n",
    "model = grid_history.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/100\n",
      "623/623 [==============================] - 0s 772us/step - loss: 0.9107 - accuracy: 0.6164 - val_loss: 0.7531 - val_accuracy: 0.5485\n",
      "Epoch 2/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.8324 - accuracy: 0.6260 - val_loss: 0.7412 - val_accuracy: 0.5672\n",
      "Epoch 3/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.7818 - accuracy: 0.6661 - val_loss: 0.7321 - val_accuracy: 0.5821\n",
      "Epoch 4/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.7466 - accuracy: 0.6613 - val_loss: 0.7244 - val_accuracy: 0.5784\n",
      "Epoch 5/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.7010 - accuracy: 0.6918 - val_loss: 0.7178 - val_accuracy: 0.6157\n",
      "Epoch 6/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.6663 - accuracy: 0.7255 - val_loss: 0.7116 - val_accuracy: 0.6194\n",
      "Epoch 7/100\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.6341 - accuracy: 0.7255 - val_loss: 0.7060 - val_accuracy: 0.6381\n",
      "Epoch 8/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.6067 - accuracy: 0.7400 - val_loss: 0.6997 - val_accuracy: 0.6604\n",
      "Epoch 9/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.5818 - accuracy: 0.7464 - val_loss: 0.6925 - val_accuracy: 0.6716\n",
      "Epoch 10/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.5534 - accuracy: 0.7673 - val_loss: 0.6852 - val_accuracy: 0.7127\n",
      "Epoch 11/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.5423 - accuracy: 0.7640 - val_loss: 0.6773 - val_accuracy: 0.7127\n",
      "Epoch 12/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.5232 - accuracy: 0.7865 - val_loss: 0.6699 - val_accuracy: 0.7164\n",
      "Epoch 13/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.5094 - accuracy: 0.7817 - val_loss: 0.6621 - val_accuracy: 0.7276\n",
      "Epoch 14/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4990 - accuracy: 0.7961 - val_loss: 0.6542 - val_accuracy: 0.7351\n",
      "Epoch 15/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4870 - accuracy: 0.7978 - val_loss: 0.6462 - val_accuracy: 0.7351\n",
      "Epoch 16/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4817 - accuracy: 0.8090 - val_loss: 0.6389 - val_accuracy: 0.7351\n",
      "Epoch 17/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4691 - accuracy: 0.8074 - val_loss: 0.6311 - val_accuracy: 0.7388\n",
      "Epoch 18/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4651 - accuracy: 0.8058 - val_loss: 0.6242 - val_accuracy: 0.7388\n",
      "Epoch 19/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4554 - accuracy: 0.8218 - val_loss: 0.6171 - val_accuracy: 0.7388\n",
      "Epoch 20/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4472 - accuracy: 0.8234 - val_loss: 0.6106 - val_accuracy: 0.7351\n",
      "Epoch 21/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4416 - accuracy: 0.8250 - val_loss: 0.6029 - val_accuracy: 0.7313\n",
      "Epoch 22/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4396 - accuracy: 0.8234 - val_loss: 0.5949 - val_accuracy: 0.7313\n",
      "Epoch 23/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4312 - accuracy: 0.8283 - val_loss: 0.5872 - val_accuracy: 0.7425\n",
      "Epoch 24/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4249 - accuracy: 0.8299 - val_loss: 0.5787 - val_accuracy: 0.7463\n",
      "Epoch 25/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4283 - accuracy: 0.8347 - val_loss: 0.5717 - val_accuracy: 0.7463\n",
      "Epoch 26/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4185 - accuracy: 0.8347 - val_loss: 0.5644 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4163 - accuracy: 0.8363 - val_loss: 0.5569 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4144 - accuracy: 0.8363 - val_loss: 0.5500 - val_accuracy: 0.7537\n",
      "Epoch 29/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4045 - accuracy: 0.8427 - val_loss: 0.5432 - val_accuracy: 0.7537\n",
      "Epoch 30/100\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.4040 - accuracy: 0.8411 - val_loss: 0.5365 - val_accuracy: 0.7612\n",
      "Epoch 31/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3963 - accuracy: 0.8475 - val_loss: 0.5305 - val_accuracy: 0.7687\n",
      "Epoch 32/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3979 - accuracy: 0.8411 - val_loss: 0.5246 - val_accuracy: 0.7836\n",
      "Epoch 33/100\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3942 - accuracy: 0.8491 - val_loss: 0.5191 - val_accuracy: 0.7873\n",
      "Epoch 34/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3877 - accuracy: 0.8555 - val_loss: 0.5139 - val_accuracy: 0.7873\n",
      "Epoch 35/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3854 - accuracy: 0.8539 - val_loss: 0.5090 - val_accuracy: 0.7836\n",
      "Epoch 36/100\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.3803 - accuracy: 0.8491 - val_loss: 0.5042 - val_accuracy: 0.7836\n",
      "Epoch 37/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3815 - accuracy: 0.8507 - val_loss: 0.4995 - val_accuracy: 0.7836\n",
      "Epoch 38/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3886 - accuracy: 0.8475 - val_loss: 0.4954 - val_accuracy: 0.7873\n",
      "Epoch 39/100\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3706 - accuracy: 0.8604 - val_loss: 0.4915 - val_accuracy: 0.7948\n",
      "Epoch 40/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3821 - accuracy: 0.8555 - val_loss: 0.4877 - val_accuracy: 0.8022\n",
      "Epoch 41/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3735 - accuracy: 0.8523 - val_loss: 0.4844 - val_accuracy: 0.8060\n",
      "Epoch 42/100\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3710 - accuracy: 0.8587 - val_loss: 0.4815 - val_accuracy: 0.8022\n",
      "Epoch 43/100\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3691 - accuracy: 0.8571 - val_loss: 0.4782 - val_accuracy: 0.8022\n",
      "Epoch 44/100\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.3731 - accuracy: 0.8459 - val_loss: 0.4756 - val_accuracy: 0.8060\n",
      "Epoch 45/100\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.3684 - accuracy: 0.8571 - val_loss: 0.4728 - val_accuracy: 0.8060\n",
      "Epoch 46/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3676 - accuracy: 0.8507 - val_loss: 0.4705 - val_accuracy: 0.8209\n",
      "Epoch 47/100\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3647 - accuracy: 0.8539 - val_loss: 0.4682 - val_accuracy: 0.8284\n",
      "Epoch 48/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3586 - accuracy: 0.8636 - val_loss: 0.4664 - val_accuracy: 0.8358\n",
      "Epoch 49/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3739 - accuracy: 0.8571 - val_loss: 0.4646 - val_accuracy: 0.8433\n",
      "Epoch 50/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3576 - accuracy: 0.8620 - val_loss: 0.4626 - val_accuracy: 0.8433\n",
      "Epoch 51/100\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3603 - accuracy: 0.8636 - val_loss: 0.4611 - val_accuracy: 0.8433\n",
      "Epoch 52/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3555 - accuracy: 0.8620 - val_loss: 0.4598 - val_accuracy: 0.8396\n",
      "Epoch 53/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3569 - accuracy: 0.8523 - val_loss: 0.4591 - val_accuracy: 0.8433\n",
      "Epoch 54/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3592 - accuracy: 0.8604 - val_loss: 0.4584 - val_accuracy: 0.8433\n",
      "Epoch 55/100\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3602 - accuracy: 0.8620 - val_loss: 0.4579 - val_accuracy: 0.8433\n",
      "Epoch 56/100\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3574 - accuracy: 0.8604 - val_loss: 0.4574 - val_accuracy: 0.8433\n",
      "Epoch 57/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3557 - accuracy: 0.8604 - val_loss: 0.4566 - val_accuracy: 0.8433\n",
      "Epoch 58/100\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3528 - accuracy: 0.8636 - val_loss: 0.4556 - val_accuracy: 0.8470\n",
      "Epoch 59/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3533 - accuracy: 0.8427 - val_loss: 0.4546 - val_accuracy: 0.8470\n",
      "Epoch 60/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3553 - accuracy: 0.8652 - val_loss: 0.4545 - val_accuracy: 0.8470\n",
      "Epoch 61/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3487 - accuracy: 0.8620 - val_loss: 0.4548 - val_accuracy: 0.8470\n",
      "Epoch 62/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3555 - accuracy: 0.8716 - val_loss: 0.4549 - val_accuracy: 0.8433\n",
      "Epoch 63/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3418 - accuracy: 0.8668 - val_loss: 0.4538 - val_accuracy: 0.8433\n",
      "Epoch 64/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3482 - accuracy: 0.8636 - val_loss: 0.4530 - val_accuracy: 0.8433\n",
      "Epoch 65/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3537 - accuracy: 0.8732 - val_loss: 0.4527 - val_accuracy: 0.8433\n",
      "Epoch 66/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3499 - accuracy: 0.8732 - val_loss: 0.4533 - val_accuracy: 0.8433\n",
      "Epoch 67/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3488 - accuracy: 0.8636 - val_loss: 0.4535 - val_accuracy: 0.8433\n",
      "Epoch 68/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3499 - accuracy: 0.8652 - val_loss: 0.4534 - val_accuracy: 0.8433\n",
      "Epoch 69/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3409 - accuracy: 0.8668 - val_loss: 0.4530 - val_accuracy: 0.8433\n",
      "Epoch 70/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3422 - accuracy: 0.8684 - val_loss: 0.4524 - val_accuracy: 0.8433\n",
      "Epoch 71/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3432 - accuracy: 0.8620 - val_loss: 0.4525 - val_accuracy: 0.8433\n",
      "Epoch 72/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3519 - accuracy: 0.8652 - val_loss: 0.4528 - val_accuracy: 0.8396\n",
      "Epoch 73/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3494 - accuracy: 0.8587 - val_loss: 0.4521 - val_accuracy: 0.8396\n",
      "Epoch 74/100\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3568 - accuracy: 0.8716 - val_loss: 0.4534 - val_accuracy: 0.8470\n",
      "Epoch 75/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3445 - accuracy: 0.8652 - val_loss: 0.4521 - val_accuracy: 0.8470\n",
      "Epoch 76/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3413 - accuracy: 0.8748 - val_loss: 0.4509 - val_accuracy: 0.8396\n",
      "Epoch 77/100\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3364 - accuracy: 0.8716 - val_loss: 0.4513 - val_accuracy: 0.8433\n",
      "Epoch 78/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3444 - accuracy: 0.8652 - val_loss: 0.4518 - val_accuracy: 0.8433\n",
      "Epoch 79/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3439 - accuracy: 0.8587 - val_loss: 0.4518 - val_accuracy: 0.8433\n",
      "Epoch 80/100\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3376 - accuracy: 0.8684 - val_loss: 0.4515 - val_accuracy: 0.8433\n",
      "Epoch 81/100\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3442 - accuracy: 0.8748 - val_loss: 0.4528 - val_accuracy: 0.8433\n"
     ]
    }
   ],
   "source": [
    "history_1 = model.fit(X_train, y_train, validation_data=(X_val, y_val),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history_1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6163724,\n",
       " 0.6260032,\n",
       " 0.6661316,\n",
       " 0.6613162,\n",
       " 0.6918138,\n",
       " 0.7255217,\n",
       " 0.7255217,\n",
       " 0.7399679,\n",
       " 0.74638844,\n",
       " 0.7672552,\n",
       " 0.76404494,\n",
       " 0.78651685,\n",
       " 0.78170145,\n",
       " 0.79614764,\n",
       " 0.7977528,\n",
       " 0.80898875,\n",
       " 0.80738366,\n",
       " 0.8057785,\n",
       " 0.82182986,\n",
       " 0.823435,\n",
       " 0.8250401,\n",
       " 0.823435,\n",
       " 0.8282504,\n",
       " 0.82985556,\n",
       " 0.83467096,\n",
       " 0.83467096,\n",
       " 0.83627605,\n",
       " 0.83627605,\n",
       " 0.8426966,\n",
       " 0.8410915,\n",
       " 0.84751207,\n",
       " 0.8410915,\n",
       " 0.84911716,\n",
       " 0.8555377,\n",
       " 0.85393256,\n",
       " 0.84911716,\n",
       " 0.8507223,\n",
       " 0.84751207,\n",
       " 0.8603531,\n",
       " 0.8555377,\n",
       " 0.85232747,\n",
       " 0.858748,\n",
       " 0.85714287,\n",
       " 0.8459069,\n",
       " 0.85714287,\n",
       " 0.8507223,\n",
       " 0.85393256,\n",
       " 0.8635634,\n",
       " 0.85714287,\n",
       " 0.86195827,\n",
       " 0.8635634,\n",
       " 0.86195827,\n",
       " 0.85232747,\n",
       " 0.8603531,\n",
       " 0.86195827,\n",
       " 0.8603531,\n",
       " 0.8603531,\n",
       " 0.8635634,\n",
       " 0.8426966,\n",
       " 0.8651685,\n",
       " 0.86195827,\n",
       " 0.87158906,\n",
       " 0.86677366,\n",
       " 0.8635634,\n",
       " 0.8731942,\n",
       " 0.8731942,\n",
       " 0.8635634,\n",
       " 0.8651685,\n",
       " 0.86677366,\n",
       " 0.8683788,\n",
       " 0.86195827,\n",
       " 0.8651685,\n",
       " 0.858748,\n",
       " 0.87158906,\n",
       " 0.8651685,\n",
       " 0.8747994,\n",
       " 0.87158906,\n",
       " 0.8651685,\n",
       " 0.858748,\n",
       " 0.8683788,\n",
       " 0.8747994]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = history_dict['accuracy']\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5485074520111084,\n",
       " 0.5671641826629639,\n",
       " 0.5820895433425903,\n",
       " 0.5783582329750061,\n",
       " 0.6156716346740723,\n",
       " 0.6194030046463013,\n",
       " 0.638059675693512,\n",
       " 0.6604477763175964,\n",
       " 0.6716417670249939,\n",
       " 0.7126865386962891,\n",
       " 0.7126865386962891,\n",
       " 0.7164179086685181,\n",
       " 0.7276119589805603,\n",
       " 0.7350746393203735,\n",
       " 0.7350746393203735,\n",
       " 0.7350746393203735,\n",
       " 0.7388059496879578,\n",
       " 0.7388059496879578,\n",
       " 0.7388059496879578,\n",
       " 0.7350746393203735,\n",
       " 0.7313432693481445,\n",
       " 0.7313432693481445,\n",
       " 0.7425373196601868,\n",
       " 0.746268630027771,\n",
       " 0.746268630027771,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.753731369972229,\n",
       " 0.753731369972229,\n",
       " 0.7611940503120422,\n",
       " 0.7686567306518555,\n",
       " 0.7835820913314819,\n",
       " 0.7873134613037109,\n",
       " 0.7873134613037109,\n",
       " 0.7835820913314819,\n",
       " 0.7835820913314819,\n",
       " 0.7835820913314819,\n",
       " 0.7873134613037109,\n",
       " 0.7947761416435242,\n",
       " 0.8022388219833374,\n",
       " 0.8059701323509216,\n",
       " 0.8022388219833374,\n",
       " 0.8022388219833374,\n",
       " 0.8059701323509216,\n",
       " 0.8059701323509216,\n",
       " 0.8208954930305481,\n",
       " 0.8283582329750061,\n",
       " 0.8358209133148193,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8395522236824036,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8470149040222168,\n",
       " 0.8470149040222168,\n",
       " 0.8470149040222168,\n",
       " 0.8470149040222168,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8395522236824036,\n",
       " 0.8395522236824036,\n",
       " 0.8470149040222168,\n",
       " 0.8470149040222168,\n",
       " 0.8395522236824036,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326,\n",
       " 0.8432835936546326]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc = history_dict['val_accuracy']\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history_dict['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## draw the accuracy graph\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc') \n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc') \n",
    "plt.title('Training and validation accuracy') \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 0s 96us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict on the test data\n",
    "\n",
    "X_test=df[891:]\n",
    "results=model.predict(X_test)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "for result in results:\n",
    "    if result >=0.5:\n",
    "        prediction.append(1) \n",
    "    else:\n",
    "        prediction.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       892\n",
       "1       893\n",
       "2       894\n",
       "3       895\n",
       "4       896\n",
       "       ... \n",
       "413    1305\n",
       "414    1306\n",
       "415    1307\n",
       "416    1308\n",
       "417    1309\n",
       "Name: PassengerId, Length: 418, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = data['PassengerId'][891:].reset_index(drop=True)\n",
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  0\n",
       "0            892  0\n",
       "1            893  1\n",
       "2            894  0\n",
       "3            895  0\n",
       "4            896  1\n",
       "..           ... ..\n",
       "413         1305  0\n",
       "414         1306  1\n",
       "415         1307  0\n",
       "416         1308  0\n",
       "417         1309  1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = pd.concat([test_id, df_prediction],axis=1)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "1            892         0\n",
       "2            893         1\n",
       "3            894         0\n",
       "4            895         0\n",
       "5            896         1\n",
       "..           ...       ...\n",
       "414         1305         0\n",
       "415         1306         1\n",
       "416         1307         0\n",
       "417         1308         0\n",
       "418         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert the dataframe to the kaggle format\n",
    "\n",
    "df_prediction.index = pd.RangeIndex(start=1, stop=419, step=1)\n",
    "df_prediction = df_prediction.rename(columns={0:'Survived'})\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv('E:/Coding/Projects/Titanic survive prediction/prediction.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
